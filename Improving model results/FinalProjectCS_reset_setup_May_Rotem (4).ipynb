{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNnA0Nxx4ghf"
      },
      "source": [
        "## Project Setup (Colab)\n",
        "\n",
        "Run these cells from top to bottom to build a stable, reproducible environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RWi7MCSN4ghg"
      },
      "outputs": [],
      "source": [
        "# # ======================================\n",
        "# # üîß INSTALL DEPENDENCIES (run once, then restart kernel if prompted)\n",
        "# # ======================================\n",
        "# %%capture\n",
        "# %pip install -q --force-reinstall     numpy==1.26.4     scipy==1.13.1     torch==2.4.1     torchaudio==2.4.1     coqui-tts==0.23.1     pandas==2.2.3     matplotlib==3.9.2     scikit-learn==1.5.2     tqdm==4.66.5\n",
        "\n",
        "# # After running this cell, restart the runtime by going to \"Runtime\" -> \"Restart session\" in the Colab menu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "u757FgZcRLNr"
      },
      "outputs": [],
      "source": [
        "# !pip uninstall -y numpy pandas scipy\n",
        "# !pip install --no-cache-dir --force-reinstall numpy==1.26.4 pandas==2.2.3 scipy==1.13.1\n",
        "# !pip install coqui-tts==0.23.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbjc4yul4ghh",
        "outputId": "615c35b5-e05e-443a-b6ee-4f1d7d35a88f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jieba/_compat.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n"
          ]
        }
      ],
      "source": [
        "# ======================================\n",
        "# üì¶ IMPORT LIBRARIES\n",
        "# ======================================\n",
        "import os, sys, glob, random, shutil, csv, itertools, threading, platform, importlib\n",
        "from pathlib import Path\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from collections import defaultdict\n",
        "\n",
        "# Core scientific stack\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Machine learning / audio\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Coqui Text-to-Speech\n",
        "from TTS.api import TTS\n",
        "\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4lUUUhj4ghh",
        "outputId": "7a7a8c44-dd0f-4b2d-ac76-9e20ae440e02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set to 42\n"
          ]
        }
      ],
      "source": [
        "# ======================================\n",
        "# üéØ REPRODUCIBILITY (Seed everything)\n",
        "# ======================================\n",
        "import random\n",
        "import numpy as _np\n",
        "import torch as _torch\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "_np.random.seed(SEED)\n",
        "_torch.manual_seed(SEED)\n",
        "if _torch.cuda.is_available():\n",
        "    _torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "print(f\"Seed set to {SEED}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vS6XSpNd4ghh",
        "outputId": "172f5bcd-40e3-420e-adba-def9fa08f7a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment is ready!\n",
            "Python: 3.12.12\n",
            "NumPy: 1.26.4 | SciPy: 1.13.1\n",
            "Torch: 2.4.1+cu121 | Torchaudio: 2.4.1+cu121\n",
            "Pandas: 2.2.3\n",
            "CUDA available: True\n",
            "CUDA device: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# ======================================\n",
        "# ‚úÖ ENVIRONMENT CHECK\n",
        "# ======================================\n",
        "import platform\n",
        "print(\"Environment is ready!\")\n",
        "print(f\"Python: {platform.python_version()}\")\n",
        "print(f\"NumPy: {np.__version__} | SciPy: {scipy.__version__}\")\n",
        "print(f\"Torch: {torch.__version__} | Torchaudio: {torchaudio.__version__}\")\n",
        "print(f\"Pandas: {pd.__version__}\")\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA device:\", torch.cuda.get_device_name(0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwvECPac4ghi",
        "outputId": "e96c4313-da48-4147-e4f6-0c780d78c526"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Saved lockfile to: /content/requirements_lock.txt\n",
            "Saved environment info to: /content/env_lock.json\n",
            "Also copied to Drive: /content/drive/MyDrive/ColabEnvLocks\n"
          ]
        }
      ],
      "source": [
        "# ======================================\n",
        "# üßä FREEZE ENVIRONMENT (lock file + system info)\n",
        "# ======================================\n",
        "import os, json, platform\n",
        "import numpy as _numpy\n",
        "import scipy as _scipy\n",
        "import torch as _torch\n",
        "import pandas as _pandas\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "LOCK_TXT = \"/content/requirements_lock.txt\"\n",
        "LOCK_JSON = \"/content/env_lock.json\"\n",
        "\n",
        "# Freeze exact package versions\n",
        "!pip freeze > \"$LOCK_TXT\"\n",
        "\n",
        "# Save system info + core libs versions\n",
        "env_info = {\n",
        "    \"python\": platform.python_version(),\n",
        "    \"platform\": platform.platform(),\n",
        "    \"cuda_available\": _torch.cuda.is_available(),\n",
        "    \"cuda_device\": (_torch.cuda.get_device_name(0) if _torch.cuda.is_available() else None),\n",
        "    \"versions\": {\n",
        "        \"numpy\": _numpy.__version__,\n",
        "        \"scipy\": _scipy.__version__,\n",
        "        \"torch\": _torch.__version__,\n",
        "        \"pandas\": _pandas.__version__,\n",
        "    }\n",
        "}\n",
        "with open(LOCK_JSON, \"w\") as f:\n",
        "    json.dump(env_info, f, indent=2)\n",
        "\n",
        "print(f\"Saved lockfile to: {LOCK_TXT}\")\n",
        "print(f\"Saved environment info to: {LOCK_JSON}\")\n",
        "\n",
        "# If Drive is mounted, also copy there for persistence\n",
        "drive_base = \"/content/drive/MyDrive/ColabEnvLocks\"\n",
        "if os.path.exists(\"/content/drive\"):\n",
        "    os.makedirs(drive_base, exist_ok=True)\n",
        "    !cp -f \"$LOCK_TXT\" \"$drive_base/requirements_lock.txt\"\n",
        "    !cp -f \"$LOCK_JSON\" \"$drive_base/env_lock.json\"\n",
        "    print(f\"Also copied to Drive: {drive_base}\")\n",
        "else:\n",
        "    print(\"Google Drive is not mounted; skipping Drive backup.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4Ep1xRDk4ghi"
      },
      "outputs": [],
      "source": [
        "# ======================================\n",
        "# üîÅ RESTORE ENV FROM LOCK (use on fresh runtimes)\n",
        "# ======================================\n",
        "%%capture\n",
        "# Prefer Drive lock if available, else local\n",
        "LOCK_TXT = \"/content/drive/MyDrive/ColabEnvLocks/requirements_lock.txt\"\n",
        "FALLBACK_LOCK = \"/content/requirements_lock.txt\"\n",
        "import os\n",
        "lock_to_use = LOCK_TXT if os.path.exists(LOCK_TXT) else FALLBACK_LOCK\n",
        "print(f\"Installing from lock: {lock_to_use}\")\n",
        "%pip install -q --no-deps -r \"$lock_to_use\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fq-YA5E4ghi",
        "outputId": "c60fb3e3-d863-4e3d-8797-6cf9e92d1037"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/TTS/api.py:71: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.\n",
            "  warnings.warn(\"`gpu` will be deprecated. Please use `tts.to(device)` instead.\")\n",
            "/usr/local/lib/python3.12/dist-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location=map_location, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model ready: tts_models/en/ljspeech/tacotron2-DDC\n",
            "Drive detected. Consider syncing ~/.local/share/tts to Drive for full persistence.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ======================================\n",
        "# ‚¨áÔ∏è OPTIONAL: PRE-DOWNLOAD TTS MODEL WEIGHTS (persist to Drive if mounted)\n",
        "# ======================================\n",
        "from TTS.api import TTS\n",
        "import os\n",
        "\n",
        "MODEL_NAME = \"tts_models/en/ljspeech/tacotron2-DDC\"  # change if you need a different model\n",
        "LOCAL_DIR = \"/content/models/tts\"\n",
        "os.makedirs(LOCAL_DIR, exist_ok=True)\n",
        "\n",
        "# Instantiate once to trigger download into cache; also synthesize a tiny file to ensure weights are present\n",
        "tts = TTS(model_name=MODEL_NAME, progress_bar=False, gpu=torch.cuda.is_available())\n",
        "tts.tts_to_file(text=\"setup\", file_path=f\"{LOCAL_DIR}/_warmup.wav\")\n",
        "print(\"Model ready:\", MODEL_NAME)\n",
        "\n",
        "# If Drive is mounted, copy cache for persistence\n",
        "if os.path.exists(\"/content/drive\"):\n",
        "    DRIVE_DIR = \"/content/drive/MyDrive/ColabModels/tts\"\n",
        "    os.makedirs(DRIVE_DIR, exist_ok=True)\n",
        "    print(\"Drive detected. Consider syncing ~/.local/share/tts to Drive for full persistence.\")\n",
        "else:\n",
        "    print(\"Drive not mounted ‚Äî model will be cached only in this runtime.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4MjHTZC4ghi",
        "outputId": "4a607757-0f72-4f85-b2bd-57328d87905f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done. Files in data dir:\n"
          ]
        }
      ],
      "source": [
        "# ======================================\n",
        "# üì¶ OPTIONAL: EXTRACT ALL ZIP DATASETS IN /content\n",
        "# ======================================\n",
        "import zipfile, glob, os\n",
        "DATA_DIR = \"/content/data\"\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "zips = glob.glob(\"/content/*.zip\")\n",
        "for z in zips:\n",
        "    print(\"Extracting:\", z)\n",
        "    with zipfile.ZipFile(z, 'r') as zip_ref:\n",
        "        zip_ref.extractall(DATA_DIR)\n",
        "\n",
        "print(\"Done. Files in data dir:\")\n",
        "for root, dirs, files in os.walk(DATA_DIR):\n",
        "    for f in files[:50]:\n",
        "        print(os.path.join(root, f))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeCXF8rG9JdE"
      },
      "source": [
        "## extract_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsB_qTqinrA3"
      },
      "outputs": [],
      "source": [
        "# import shutil\n",
        "# import os\n",
        "\n",
        "# # ◊î◊†◊™◊ô◊ë ◊ú◊™◊ô◊ß◊ô◊ô◊î ◊©◊†◊ï◊¶◊®◊î ◊ë◊î◊®◊¶◊î ◊î◊ß◊ï◊ì◊û◊™\n",
        "# destination_folder = \"/content/vctk_full\"\n",
        "\n",
        "# # ◊ë◊ì◊ô◊ß◊î ◊ê◊ù ◊î◊™◊ô◊ß◊ô◊ô◊î ◊ß◊ô◊ô◊û◊™, ◊ï◊ê◊ñ ◊û◊ó◊ô◊ß◊î\n",
        "# if os.path.exists(destination_folder):\n",
        "#     shutil.rmtree(destination_folder)\n",
        "#     print(f\" ◊î◊™◊ô◊ß◊ô◊ô◊î '{destination_folder}' ◊†◊û◊ó◊ß◊î ◊ë◊î◊¶◊ú◊ó◊î.\")\n",
        "# else:\n",
        "#     print(f\"‚Ñπ ◊î◊™◊ô◊ß◊ô◊ô◊î '{destination_folder}' ◊ú◊ê ◊ß◊ô◊ô◊û◊™, ◊ê◊ô◊ü ◊û◊î ◊ú◊û◊ó◊ï◊ß.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YxlgeQE9ufN",
        "outputId": "b41e1b32-46d0-4eea-cca3-b7c7e3bdd24a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Contents of 'My Drive': ['Colab Notebooks', 'Deep learning', 'ColabEnvLocks', 'ColabModels', 'Colab_Data']\n",
            "Contents of 'Colab Notebooks': ['archive.zip', 'fake_audio.zip', 'Copy of Welcome To Colab', 'Untitled0.ipynb', 'Untitled1.ipynb', 'Untitled2.ipynb', 'FinalProjectCS.ipynb', 'FinalProjectCS_reset_setup_May_Rotem.ipynb']\n",
            " ZIP file found: /content/drive/My Drive/Colab Notebooks/archive.zip\n",
            "\n",
            " Extraction complete: 2684 files were extracted.\n",
            " Extracted data is available in: /content/vctk_samples\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# List contents to verify paths (optional)\n",
        "root_path = '/content/drive/My Drive/'\n",
        "print(\"Contents of 'My Drive':\", os.listdir(root_path))\n",
        "\n",
        "subfolder_path = '/content/drive/My Drive/Colab Notebooks/'\n",
        "print(\"Contents of 'Colab Notebooks':\", os.listdir(subfolder_path))\n",
        "\n",
        "# Define paths\n",
        "zip_file = \"/content/drive/My Drive/Colab Notebooks/archive.zip\"  # Path to your ZIP file\n",
        "destination_folder = \"/content/vctk_samples\"  # Where to extract selected data\n",
        "wanted_speakers = [\"p225\", \"p226\", \"p227\", \"p228\"]  # Select specific speakers\n",
        "\n",
        "# Check if the ZIP file exists\n",
        "if os.path.isfile(zip_file):\n",
        "    print(\" ZIP file found:\", zip_file)\n",
        "else:\n",
        "    raise FileNotFoundError(f\" ZIP file not found: {zip_file}\")\n",
        "\n",
        "# Create destination folder if it doesn't exist\n",
        "os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "# Selectively extract only desired speaker folders from the ZIP\n",
        "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "    extracted_files = 0\n",
        "    for file in zip_ref.namelist():\n",
        "        if any(f\"VCTK-Corpus/wav48/{spk}/\" in file or f\"VCTK-Corpus/txt/{spk}/\" in file for spk in wanted_speakers):\n",
        "            # Ensure directory structure is preserved\n",
        "            target_path = os.path.join(destination_folder, file)\n",
        "            os.makedirs(os.path.dirname(target_path), exist_ok=True)\n",
        "            with zip_ref.open(file) as source, open(target_path, 'wb') as target:\n",
        "                shutil.copyfileobj(source, target)\n",
        "            extracted_files += 1\n",
        "\n",
        "print(f\"\\n Extraction complete: {extracted_files} files were extracted.\")\n",
        "print(f\" Extracted data is available in: {destination_folder}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB_QfTQcEA-G"
      },
      "source": [
        "## Installations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "id": "nymZzYIfrL7N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b431d06-99c4-4ec5-c474-377117e1613f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  espeak-ng-data libespeak-ng1 libpcaudio0 libsonic0\n",
            "The following NEW packages will be installed:\n",
            "  espeak-ng espeak-ng-data libespeak-ng1 libpcaudio0 libsonic0\n",
            "0 upgraded, 5 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 4,526 kB of archives.\n",
            "After this operation, 11.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libpcaudio0 amd64 1.1-6build2 [8,956 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsonic0 amd64 0.2.0-11build1 [10.3 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 espeak-ng-data amd64 1.50+dfsg-10ubuntu0.1 [3,956 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libespeak-ng1 amd64 1.50+dfsg-10ubuntu0.1 [207 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 espeak-ng amd64 1.50+dfsg-10ubuntu0.1 [343 kB]\n",
            "Fetched 4,526 kB in 2s (2,705 kB/s)\n",
            "Selecting previously unselected package libpcaudio0:amd64.\n",
            "(Reading database ... 125079 files and directories currently installed.)\n",
            "Preparing to unpack .../libpcaudio0_1.1-6build2_amd64.deb ...\n",
            "Unpacking libpcaudio0:amd64 (1.1-6build2) ...\n",
            "Selecting previously unselected package libsonic0:amd64.\n",
            "Preparing to unpack .../libsonic0_0.2.0-11build1_amd64.deb ...\n",
            "Unpacking libsonic0:amd64 (0.2.0-11build1) ...\n",
            "Selecting previously unselected package espeak-ng-data:amd64.\n",
            "Preparing to unpack .../espeak-ng-data_1.50+dfsg-10ubuntu0.1_amd64.deb ...\n",
            "Unpacking espeak-ng-data:amd64 (1.50+dfsg-10ubuntu0.1) ...\n",
            "Selecting previously unselected package libespeak-ng1:amd64.\n",
            "Preparing to unpack .../libespeak-ng1_1.50+dfsg-10ubuntu0.1_amd64.deb ...\n",
            "Unpacking libespeak-ng1:amd64 (1.50+dfsg-10ubuntu0.1) ...\n",
            "Selecting previously unselected package espeak-ng.\n",
            "Preparing to unpack .../espeak-ng_1.50+dfsg-10ubuntu0.1_amd64.deb ...\n",
            "Unpacking espeak-ng (1.50+dfsg-10ubuntu0.1) ...\n",
            "Setting up libpcaudio0:amd64 (1.1-6build2) ...\n",
            "Setting up libsonic0:amd64 (0.2.0-11build1) ...\n",
            "Setting up espeak-ng-data:amd64 (1.50+dfsg-10ubuntu0.1) ...\n",
            "Setting up libespeak-ng1:amd64 (1.50+dfsg-10ubuntu0.1) ...\n",
            "Setting up espeak-ng (1.50+dfsg-10ubuntu0.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y espeak-ng"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcjKFlnIKvFL"
      },
      "source": [
        "## Creating Fake Audio (No Need to run now)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJKIKc_hmeNU"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# from pathlib import Path\n",
        "# from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "# import threading\n",
        "# import torch\n",
        "\n",
        "# from TTS.api import TTS\n",
        "\n",
        "# # =========================\n",
        "# # CONFIG (VC Version)\n",
        "# # =========================\n",
        "# # 1) Input text files (one .txt per utterance - needed for content)\n",
        "# TEXT_ROOT = Path(\"/content/vctk_samples/VCTK-Corpus/VCTK-Corpus/txt\")\n",
        "\n",
        "# # 2) Real audio folder (source audio files to be converted)\n",
        "# REAL_AUDIO_ROOT = Path(\"/content/vctk_samples/VCTK-Corpus/VCTK-Corpus/wav48\")\n",
        "\n",
        "# # 3) <<< NEW >>> Output folder for the VOICE CONVERTED real audio\n",
        "# OUT_ROOT_VC = Path(\"/content/vctk_samples/VCTK-Corpus/VCTK-Corpus/vc_wav48_xtts\") # Changed path\n",
        "# OUT_ROOT_VC.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# # 4) Language to synthesize in\n",
        "# LANGUAGE = \"en\"\n",
        "\n",
        "# # 5) Concurrency settings\n",
        "# GPU_AVAILABLE = torch.cuda.is_available()\n",
        "# MAX_WORKERS = 1 if GPU_AVAILABLE else 4 # Keep 1 for GPU\n",
        "\n",
        "# # =========================\n",
        "# # MODEL LOADING (Only XTTS needed now)\n",
        "# # =========================\n",
        "# print(\"Loading XTTS v2 model...\")\n",
        "# tts_xtts = TTS(model_name=\"tts_models/multilingual/multi-dataset/xtts_v2\", progress_bar=True)\n",
        "# device = \"cuda\" if GPU_AVAILABLE else \"cpu\"\n",
        "# tts_xtts.to(device)\n",
        "# print(f\"XTTS is running on: {device}\")\n",
        "\n",
        "# # Mutex for model calls if needed (usually only needed if MAX_WORKERS > 1 on CPU)\n",
        "# synth_lock = threading.Lock() if MAX_WORKERS > 1 else None\n",
        "\n",
        "# # =========================\n",
        "# # HELPERS (find_matching_real_wav remains the same)\n",
        "# # =========================\n",
        "# def find_matching_real_wav(real_root: Path, subdir: str, txt_filename: str) -> Path | None:\n",
        "#     \"\"\"\n",
        "#     Try to find the real WAV that matches the text file stem.\n",
        "#     (Code remains exactly the same as before)\n",
        "#     \"\"\"\n",
        "#     stem = Path(txt_filename).stem\n",
        "#     parts = stem.split(\"_\")\n",
        "#     if parts and not parts[0].startswith(\"p\"):\n",
        "#         parts[0] = \"p\" + parts[0]\n",
        "#     norm_stem = \"_\".join(parts)\n",
        "\n",
        "#     cand1 = real_root / subdir / f\"{norm_stem}.wav\"\n",
        "#     if cand1.exists():\n",
        "#         return cand1\n",
        "#     cand2 = real_root / subdir / f\"{stem}.wav\"\n",
        "#     if cand2.exists():\n",
        "#         return cand2\n",
        "#     subdir_path = real_root / subdir\n",
        "#     if subdir_path.is_dir():\n",
        "#         for fn in os.listdir(subdir_path):\n",
        "#             if not fn.lower().endswith(\".wav\"): continue\n",
        "#             if norm_stem in fn or stem in fn:\n",
        "#                 return subdir_path / fn\n",
        "#     return None\n",
        "\n",
        "# def synth_xtts_vc(text: str, speaker_wav: Path, out_path: Path, language: str = \"en\"):\n",
        "#     \"\"\"\n",
        "#     Synthesize using XTTS v2, using the real wav as the speaker reference.\n",
        "#     (Function renamed slightly for clarity, code is the same synth_xtts)\n",
        "#     \"\"\"\n",
        "#     if synth_lock:\n",
        "#         with synth_lock:\n",
        "#             tts_xtts.tts_to_file(text=text, file_path=str(out_path), speaker_wav=str(speaker_wav), language=language)\n",
        "#     else:\n",
        "#         tts_xtts.tts_to_file(text=text, file_path=str(out_path), speaker_wav=str(speaker_wav), language=language)\n",
        "\n",
        "# # =========================\n",
        "# # <<< MODIFIED >>> Process Function\n",
        "# # =========================\n",
        "# def process_one_vc(text_path: Path, out_subdir: Path):\n",
        "#     \"\"\"\n",
        "#     Process a single text file to perform Voice Conversion on the corresponding real audio:\n",
        "#       - Read text\n",
        "#       - Find matching real WAV (THIS IS NOW THE SOURCE AUDIO *AND* VOICE REFERENCE)\n",
        "#       - Synthesize using XTTS with the text and real_wav\n",
        "#     \"\"\"\n",
        "#     text = text_path.read_text(encoding=\"utf-8\").strip()\n",
        "#     if not text:\n",
        "#         return f\"[SKIP VC] Empty text: {text_path.name}\"\n",
        "\n",
        "#     # Find the matching real wav in REAL_AUDIO_ROOT/<subdir>/\n",
        "#     subdir = text_path.parent.name # Assumes text files are organized like 'txt/p225/*.txt'\n",
        "#     real_wav = find_matching_real_wav(REAL_AUDIO_ROOT, subdir, text_path.name)\n",
        "\n",
        "#     # <<< CHANGED >>> If no real wav found, skip this file entirely\n",
        "#     if not real_wav or not real_wav.exists():\n",
        "#         return f\"[SKIP VC] No matching real WAV found for: {text_path.name} in {REAL_AUDIO_ROOT / subdir}\"\n",
        "\n",
        "#     # Build simple output path (just the original stem)\n",
        "#     out_name = f\"{text_path.stem}.wav\" # Simplified filename\n",
        "#     out_path = out_subdir / out_name\n",
        "\n",
        "#     # Synthesize using the text content and the real wav as speaker reference\n",
        "#     msg = f\"[VC XTTS] {text_path.name} (using text) + {real_wav.name} (as voice) -> {out_name}\"\n",
        "#     synth_xtts_vc(text=text, speaker_wav=real_wav, out_path=out_path, language=LANGUAGE)\n",
        "#     return msg\n",
        "\n",
        "# # =========================\n",
        "# # BUILD JOBS (Iterate through TEXT files to get utterance list and content)\n",
        "# # =========================\n",
        "# jobs_vc = []\n",
        "# # Ensure TEXT_ROOT points to the directory containing speaker subdirs like 'p225', 'p226', etc.\n",
        "# if not any(d.name.startswith('p') for d in TEXT_ROOT.iterdir() if d.is_dir()):\n",
        "#      print(f\"[WARNING] TEXT_ROOT ({TEXT_ROOT}) does not seem to contain speaker subdirectories (pXXX). Adjust if needed.\")\n",
        "#      # If text files are directly under TEXT_ROOT (no speaker subdirs):\n",
        "#      # out_subdir_vc = OUT_ROOT_VC # Single output dir\n",
        "#      # out_subdir_vc.mkdir(parents=True, exist_ok=True)\n",
        "#      # for fn in os.listdir(TEXT_ROOT):\n",
        "#      #    if fn.lower().endswith(\".txt\"):\n",
        "#      #       jobs_vc.append((TEXT_ROOT / fn, out_subdir_vc))\n",
        "# else:\n",
        "#     # Original logic assuming speaker subdirs under TEXT_ROOT\n",
        "#     for subdir in os.listdir(TEXT_ROOT):\n",
        "#         subdir_path = TEXT_ROOT / subdir\n",
        "#         if not subdir_path.is_dir():\n",
        "#             continue\n",
        "\n",
        "#         out_subdir_vc = OUT_ROOT_VC / subdir # Create matching speaker subdir in output\n",
        "#         out_subdir_vc.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "#         for fn in os.listdir(subdir_path):\n",
        "#             if not fn.lower().endswith(\".txt\"):\n",
        "#                 continue\n",
        "#             jobs_vc.append((subdir_path / fn, out_subdir_vc))\n",
        "\n",
        "\n",
        "# print(f\"Found {len(jobs_vc)} text files for VC processing.\")\n",
        "\n",
        "# # =========================\n",
        "# # RUN VC\n",
        "# # =========================\n",
        "# if not jobs_vc:\n",
        "#     print(\"No VC jobs found. Check TEXT_ROOT structure and content.\")\n",
        "# else:\n",
        "#     print(f\"Starting Voice Conversion synthesis with MAX_WORKERS={MAX_WORKERS} (device={device})\")\n",
        "#     with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
        "#         futs_vc = [ex.submit(process_one_vc, text_path, out_dir) for (text_path, out_dir) in jobs_vc]\n",
        "#         # Use tqdm for progress bar\n",
        "#         from tqdm import tqdm\n",
        "#         for fut in tqdm(as_completed(futs_vc), total=len(futs_vc)):\n",
        "#             try:\n",
        "#                 info = fut.result()\n",
        "#                 # Optionally print less info inside the loop for cleaner progress\n",
        "#                 # print(info)\n",
        "#             except Exception as e:\n",
        "#                 print(f\"\\n[ERROR VC] {repr(e)}\") # Add newline if tqdm is used\n",
        "\n",
        "# print(f\"\\nDone. Voice Converted ('real' with XTTS signature) audio saved under: {OUT_ROOT_VC}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hAhwx2F6Xu1"
      },
      "source": [
        "## Extracting the fake audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qzof7wJ8kHse",
        "outputId": "43307b00-d2ec-4427-feac-9d18c8c56fc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ZIP file found: /content/drive/My Drive/Colab Notebooks/fake_audio.zip\n",
            "Extracted 1342 files for speakers: ['p225', 'p226', 'p227', 'p228']\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# Define paths\n",
        "zip_file = \"/content/drive/My Drive/Colab Notebooks/fake_audio.zip\"  # Path to your ZIP file\n",
        "destination_folder = \"/content/vctk_samples/VCTK-Corpus/VCTK-Corpus/fake_audio\"  # Where to extract selected data\n",
        "\n",
        "# Example: define the speakers you want to extract\n",
        "wanted_speakers = [\"p225\", \"p226\",\"p227\",\"p228\"]  # change this list as needed\n",
        "\n",
        "# Check if the ZIP file exists\n",
        "if os.path.isfile(zip_file):\n",
        "\n",
        "    print(\" ZIP file found:\", zip_file)\n",
        "else:\n",
        "    raise FileNotFoundError(f\" ZIP file not found: {zip_file}\")\n",
        "\n",
        "# Create destination folder if it doesn't exist\n",
        "os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "# Selectively extract only desired speaker folders from the ZIP\n",
        "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "    extracted_files = 0\n",
        "    for file in zip_ref.namelist():\n",
        "        if any(f\"{spk}/\" in file for spk in wanted_speakers):\n",
        "            target_path = os.path.join(destination_folder, file)\n",
        "\n",
        "            # If this entry is a directory ‚Üí skip it\n",
        "            if file.endswith('/'):\n",
        "                os.makedirs(target_path, exist_ok=True)\n",
        "                continue\n",
        "\n",
        "            # Ensure directory structure is preserved\n",
        "            os.makedirs(os.path.dirname(target_path), exist_ok=True)\n",
        "\n",
        "            # Copy file content\n",
        "            with zip_ref.open(file) as source, open(target_path, 'wb') as target:\n",
        "                shutil.copyfileobj(source, target)\n",
        "            extracted_files += 1\n",
        "\n",
        "print(f\"Extracted {extracted_files} files for speakers: {wanted_speakers}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HloMV1V7yZ7i"
      },
      "source": [
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FU7_7Wq5uCOM",
        "outputId": "74524b81-7f49-4478-dc80-036ba6edd877"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-49ac0dd5-2f88-51b1-5635-5e7bcd2e0516)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L || echo \"No GPU\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YaBoZc46f0p_",
        "outputId": "ba5774f2-7dce-412f-bbbb-a3873bc5e6a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Updated CLAD/requirements.txt =====\n",
            "llvmlite==0.43.0\n",
            "numba==0.60.0\n",
            "librosa>=0.11.0\n",
            "matplotlib==3.8.4\n",
            "numpy==1.26.4\n",
            "primePy==1.3\n",
            "torchcontrib\n",
            "pytorch_model_summary\n",
            "torchinfoRequirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
            "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1.8/1.8 MB 33.0 MB/s eta 0:00:00\n",
            "Installing collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.3\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch==2.3.1\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.3.1%2Bcu121-cp312-cp312-linux_x86_64.whl (780.9 MB)\n",
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 780.9/780.9 MB 43.2 MB/s  0:00:10\n",
            "Collecting torchvision==0.18.1\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.18.1%2Bcu121-cp312-cp312-linux_x86_64.whl (7.0 MB)\n",
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 7.0/7.0 MB 127.7 MB/s  0:00:00\n",
            "Collecting torchaudio==2.3.1\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.3.1%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3.4/3.4 MB 70.7 MB/s  0:00:00\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (2.8.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (2025.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 731.7/731.7 MB 21.0 MB/s  0:00:17\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.18.1) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.18.1) (12.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1) (12.9.86)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.1) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.1) (1.3.0)\n",
            "Installing collected packages: nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
            "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.4.1\n",
            "    Uninstalling torch-2.4.1:\n",
            "      Successfully uninstalled torch-2.4.1\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.23.0+cu126\n",
            "    Uninstalling torchvision-0.23.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.23.0+cu126\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.4.1\n",
            "    Uninstalling torchaudio-2.4.1:\n",
            "      Successfully uninstalled torchaudio-2.4.1\n",
            "\n",
            "Successfully installed nvidia-cudnn-cu12-8.9.2.26 torch-2.3.1+cu121 torchaudio-2.3.1+cu121 torchvision-0.18.1+cu121\n",
            "Collecting llvmlite==0.43.0 (from -r CLAD/requirements.txt (line 1))\n",
            "  Downloading llvmlite-0.43.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting numba==0.60.0 (from -r CLAD/requirements.txt (line 2))\n",
            "  Downloading numba-0.60.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: librosa>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from -r CLAD/requirements.txt (line 3)) (0.11.0)\n",
            "Collecting matplotlib==3.8.4 (from -r CLAD/requirements.txt (line 4))\n",
            "  Downloading matplotlib-3.8.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.12/dist-packages (from -r CLAD/requirements.txt (line 5)) (1.26.4)\n",
            "Collecting primePy==1.3 (from -r CLAD/requirements.txt (line 6))\n",
            "  Downloading primePy-1.3-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting torchcontrib (from -r CLAD/requirements.txt (line 7))\n",
            "  Downloading torchcontrib-0.0.2.tar.gz (11 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting pytorch_model_summary (from -r CLAD/requirements.txt (line 8))\n",
            "  Downloading pytorch_model_summary-0.1.2-py3-none-any.whl.metadata (35 kB)\n",
            "Collecting torchinfo (from -r CLAD/requirements.txt (line 9))\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.8.4->-r CLAD/requirements.txt (line 4)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.8.4->-r CLAD/requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.8.4->-r CLAD/requirements.txt (line 4)) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.8.4->-r CLAD/requirements.txt (line 4)) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.8.4->-r CLAD/requirements.txt (line 4)) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.8.4->-r CLAD/requirements.txt (line 4)) (12.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.8.4->-r CLAD/requirements.txt (line 4)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.8.4->-r CLAD/requirements.txt (line 4)) (2.9.0.post0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (1.5.2)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (5.2.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (1.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (4.15.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (1.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (4.66.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (2.3.1+cu121)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (2.32.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib==3.8.4->-r CLAD/requirements.txt (line 4)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (2025.10.5)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (2.23)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (3.20.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (2.8.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (2025.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (12.9.86)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (1.3.0)\n",
            "Downloading llvmlite-0.43.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
            "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 43.9/43.9 MB 43.2 MB/s  0:00:01\n",
            "Downloading numba-0.60.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
            "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3.8/3.8 MB 105.8 MB/s  0:00:00\n",
            "Downloading matplotlib-3.8.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11.6/11.6 MB 130.5 MB/s  0:00:00\n",
            "Downloading primePy-1.3-py3-none-any.whl (4.0 kB)\n",
            "Downloading pytorch_model_summary-0.1.2-py3-none-any.whl (9.3 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: torchcontrib\n",
            "  Building wheel for torchcontrib (pyproject.toml): started\n",
            "  Building wheel for torchcontrib (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for torchcontrib: filename=torchcontrib-0.0.2-py3-none-any.whl size=7555 sha256=c6e0da72077e3a95923355ef9a92e25027e2046eb465812a7e3e04ad64ef6def\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/d1/1f/63f00ffea223db446943147a04ff035eb40d00cec3e87d63e5\n",
            "Successfully built torchcontrib\n",
            "Installing collected packages: torchcontrib, primePy, torchinfo, llvmlite, numba, matplotlib, pytorch_model_summary\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.45.1\n",
            "    Uninstalling llvmlite-0.45.1:\n",
            "      Successfully uninstalled llvmlite-0.45.1\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.62.1\n",
            "    Uninstalling numba-0.62.1:\n",
            "      Successfully uninstalled numba-0.62.1\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.9.2\n",
            "    Uninstalling matplotlib-3.9.2:\n",
            "      Successfully uninstalled matplotlib-3.9.2\n",
            "\n",
            "Successfully installed llvmlite-0.43.0 matplotlib-3.8.4 numba-0.60.0 primePy-1.3 pytorch_model_summary-0.1.2 torchcontrib-0.0.2 torchinfo-1.8.0\n",
            "Hit:1 https://cli.github.com/packages stable InRelease\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,412 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,288 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,135 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,479 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,820 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,838 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,594 kB]\n",
            "Fetched 29.0 MB in 3s (11.0 MB/s)\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "libsndfile1 is already the newest version (1.0.31-2ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 48 not upgraded.\n",
            "===== DONE: Environment pinned for Python 3.12 =====\n",
            "Python 3.12.12\n",
            "Python: 3.12.12\n",
            "NumPy: 1.26.4\n",
            "Numba: 0.60.0\n",
            "llvmlite: 0.43.0\n",
            "Matplotlib: 3.8.4\n",
            "torch: 2.3.1+cu121\n",
            "torchvision: 0.18.1+cu121\n",
            "torchaudio: 2.3.1+cu121\n",
            "librosa: 0.11.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning into 'CLAD'...\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 2.27.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "# --- Clone CLAD fresh (idempotent: remove existing dir if present) ---\n",
        "# remove previous clone to ensure a clean edit of requirements\n",
        "rm -rf CLAD\n",
        "git clone https://github.com/CLAD23/CLAD.git\n",
        "\n",
        "# --- Normalize requirements for Python 3.12 (single source of truth) ---\n",
        "cp CLAD/requirements.txt CLAD/requirements.bak\n",
        "\n",
        "# 1) Remove torch lines (Torch is installed manually for the correct CUDA wheel)\n",
        "sed -i '/^torch==/d; /^torchvision==/d; /^torchaudio==/d' CLAD/requirements.txt\n",
        "\n",
        "# 2) Core pins for Py3.12 + Numba 0.60.0 (compatible with llvmlite 0.43.0 and NumPy 1.26.4)\n",
        "#    These ensure no NumPy 2.x is pulled by accident.\n",
        "if grep -q '^numpy' CLAD/requirements.txt; then\n",
        "  sed -i 's/^numpy==.*/numpy==1.26.4/' CLAD/requirements.txt\n",
        "else\n",
        "  sed -i '1i numpy==1.26.4' CLAD/requirements.txt\n",
        "fi\n",
        "\n",
        "if grep -q '^numba' CLAD/requirements.txt; then\n",
        "  sed -i 's/^numba==.*/numba==0.60.0/' CLAD/requirements.txt\n",
        "else\n",
        "  sed -i '1i numba==0.60.0' CLAD/requirements.txt\n",
        "fi\n",
        "\n",
        "if grep -q '^llvmlite' CLAD/requirements.txt; then\n",
        "  sed -i 's/^llvmlite==.*/llvmlite==0.43.0/' CLAD/requirements.txt\n",
        "else\n",
        "  sed -i '1i llvmlite==0.43.0' CLAD/requirements.txt\n",
        "fi\n",
        "\n",
        "# 3) Stable Matplotlib on Py3.12\n",
        "if grep -q '^matplotlib' CLAD/requirements.txt; then\n",
        "  sed -i 's/^matplotlib==.*/matplotlib==3.8.4/' CLAD/requirements.txt\n",
        "else\n",
        "  sed -i '1i matplotlib==3.8.4' CLAD/requirements.txt\n",
        "fi\n",
        "\n",
        "# 4) Librosa must satisfy coqui-tts (>=0.11.0); keep it permissive to avoid conflicts\n",
        "if grep -q '^librosa' CLAD/requirements.txt; then\n",
        "  sed -i 's/^librosa.*/librosa>=0.11.0/' CLAD/requirements.txt\n",
        "else\n",
        "  sed -i '1i librosa>=0.11.0' CLAD/requirements.txt\n",
        "fi\n",
        "\n",
        "# 5) Pin OpenCV to builds compatible with NumPy 1.26.x (avoid NumPy 2.x constraint)\n",
        "#    Only modify if opencv lines exist (do not add if the project doesn't use it).\n",
        "grep -q '^opencv-python' CLAD/requirements.txt && sed -i 's/^opencv-python==.*/opencv-python==4.9.0.80/' CLAD/requirements.txt || true\n",
        "grep -q '^opencv-contrib-python' CLAD/requirements.txt && sed -i 's/^opencv-contrib-python==.*/opencv-contrib-python==4.9.0.80/' CLAD/requirements.txt || true\n",
        "\n",
        "# 6) Pin spaCy/Thinc to versions that work with NumPy 1.x (only if present)\n",
        "grep -q '^thinc' CLAD/requirements.txt && sed -i 's/^thinc==.*/thinc==8.2.2/' CLAD/requirements.txt || true\n",
        "grep -q '^spacy' CLAD/requirements.txt && sed -i 's/^spacy==.*/spacy==3.7.4/' CLAD/requirements.txt || true\n",
        "\n",
        "echo \"===== Updated CLAD/requirements.txt =====\"\n",
        "sed -n '1,250p' CLAD/requirements.txt\n",
        "\n",
        "# --- Upgrade pip to avoid resolver quirks ---\n",
        "python -m pip install -U pip\n",
        "\n",
        "# --- Install PyTorch 2.3.1 CUDA 12.1 (use CPU wheels by removing the index line if no GPU) ---\n",
        "python -m pip install --index-url https://download.pytorch.org/whl/cu121 \\\n",
        "  torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1\n",
        "\n",
        "# --- Install remaining CLAD dependencies from the single normalized requirements file ---\n",
        "python -m pip install -r CLAD/requirements.txt\n",
        "\n",
        "# --- System library for soundfile/librosa WAV I/O (safe to install always) ---\n",
        "apt-get update -y\n",
        "apt-get install -y libsndfile1\n",
        "\n",
        "echo \"===== DONE: Environment pinned for Python 3.12 =====\"\n",
        "python -V\n",
        "python - <<'PY'\n",
        "import sys, numpy, numba, llvmlite, matplotlib\n",
        "import importlib\n",
        "print(\"Python:\", sys.version.split()[0])\n",
        "print(\"NumPy:\", numpy.__version__)\n",
        "print(\"Numba:\", numba.__version__)\n",
        "print(\"llvmlite:\", llvmlite.__version__)\n",
        "print(\"Matplotlib:\", matplotlib.__version__)\n",
        "for m in (\"torch\",\"torchvision\",\"torchaudio\",\"librosa\"):\n",
        "    try:\n",
        "        mod = importlib.import_module(m)\n",
        "        print(f\"{m}:\", getattr(mod,\"__version__\", \"unknown\"))\n",
        "    except Exception as e:\n",
        "        print(f\"{m}: NOT INSTALLED ({e})\")\n",
        "PY\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JHih2ce7OlF"
      },
      "source": [
        "## Audio Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "FGDTDGCmYbTT"
      },
      "outputs": [],
      "source": [
        "# ◊ú◊û◊ó◊ï◊ß????\n",
        "# =========================================================================\n",
        "# # Cell 21 (MODIFIED): Prepare my_audio folder using VC-Real and Fake audio\n",
        "# # =========================================================================\n",
        "# import os, pathlib, shutil\n",
        "# from tqdm import tqdm # Import tqdm for progress indication\n",
        "\n",
        "# # <<< CHANGED >>> Destination base folders (Using vc_real for the 'real' class now)\n",
        "# REAL_DST = pathlib.Path(\"/content/my_audio/real\") # Keep destination name 'real' for consistency\n",
        "# TXT_DST  = pathlib.Path(\"/content/my_audio/txt\")\n",
        "# FAKE_DST = pathlib.Path(\"/content/my_audio/fake\")\n",
        "\n",
        "# # Delete existing destination folders to ensure a clean slate\n",
        "# if REAL_DST.exists(): shutil.rmtree(REAL_DST)\n",
        "# if TXT_DST.exists(): shutil.rmtree(TXT_DST)\n",
        "# if FAKE_DST.exists(): shutil.rmtree(FAKE_DST)\n",
        "\n",
        "# REAL_DST.mkdir(parents=True, exist_ok=True)\n",
        "# TXT_DST.mkdir(parents=True, exist_ok=True)\n",
        "# FAKE_DST.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# # <<< CHANGED >>> Source folders (Using the new VC folder for 'real' source)\n",
        "# FAKE_SRC = pathlib.Path(\"/content/vctk_samples/VCTK-Corpus/VCTK-Corpus/fake_audio\") # Original fake audio\n",
        "# TXT_SRC  = pathlib.Path(\"/content/vctk_samples/VCTK-Corpus/VCTK-Corpus/txt\")\n",
        "# REAL_SRC = pathlib.Path(\"/content/vctk_samples/VCTK-Corpus/VCTK-Corpus/vc_wav48_xtts\") # <<<--- Use the VC audio here\n",
        "\n",
        "# # Function to copy files with progress\n",
        "# def copy_with_progress(src_root, dst_root, pattern=\"*.wav\"):\n",
        "#     files_to_copy = []\n",
        "#     # Check if speaker subdirs exist in src_root\n",
        "#     speaker_subdirs_exist = any(d.name.startswith('p') for d in src_root.iterdir() if d.is_dir())\n",
        "\n",
        "#     if speaker_subdirs_exist:\n",
        "#         print(f\"Copying from speaker subdirectories in {src_root}...\")\n",
        "#         for folder in src_root.glob(\"p*\"): # Iterate through speaker folders like p225, p226...\n",
        "#             if not folder.is_dir(): continue\n",
        "#             speaker_dst = dst_root / folder.name\n",
        "#             speaker_dst.mkdir(parents=True, exist_ok=True)\n",
        "#             for file_path in folder.glob(pattern):\n",
        "#                 files_to_copy.append((file_path, speaker_dst / file_path.name))\n",
        "#     else:\n",
        "#         # If no speaker subdirs, copy files directly\n",
        "#         print(f\"Copying files directly from {src_root} (no speaker subdirs found)...\")\n",
        "#         dst_root.mkdir(parents=True, exist_ok=True) # Ensure main destination exists\n",
        "#         for file_path in src_root.glob(pattern):\n",
        "#              files_to_copy.append((file_path, dst_root / file_path.name))\n",
        "\n",
        "#     # Perform copy operation with tqdm progress bar\n",
        "#     copied_count = 0\n",
        "#     if files_to_copy:\n",
        "#          with tqdm(total=len(files_to_copy), desc=f\"Copying {src_root.name}\") as pbar:\n",
        "#             for src_file, dst_file in files_to_copy:\n",
        "#                 try:\n",
        "#                     if not dst_file.exists(): # Avoid re-copying if possible, though unlikely after rmtree\n",
        "#                         shutil.copy2(src_file, dst_file)\n",
        "#                         copied_count += 1\n",
        "#                 except Exception as e:\n",
        "#                     print(f\"\\n[ERROR] Failed to copy {src_file} to {dst_file}: {e}\")\n",
        "#                 pbar.update(1)\n",
        "#     else:\n",
        "#          print(f\"[WARN] No files matching '{pattern}' found in {src_root} or its speaker subdirectories.\")\n",
        "\n",
        "#     return copied_count\n",
        "\n",
        "# # --- Perform the copies ---\n",
        "\n",
        "# # Copy FAKE wavs (Original fake audio)\n",
        "# print(\"\\n--- Copying FAKE audio ---\")\n",
        "# if FAKE_SRC.exists():\n",
        "#     fake_copied = copy_with_progress(FAKE_SRC, FAKE_DST, \"*.wav\")\n",
        "#     print(f\"Copied {fake_copied} fake audio files.\")\n",
        "# else:\n",
        "#     print(f\"[ERROR] FAKE source directory not found: {FAKE_SRC}\")\n",
        "\n",
        "# # Copy REAL wavs (Voice Converted audio)\n",
        "# print(\"\\n--- Copying VC REAL audio ---\")\n",
        "# if REAL_SRC.exists():\n",
        "#     real_copied = copy_with_progress(REAL_SRC, REAL_DST, \"*.wav\") # Use the VC source path\n",
        "#     print(f\"Copied {real_copied} VC 'real' audio files.\")\n",
        "# else:\n",
        "#     print(f\"[ERROR] REAL (VC) source directory not found: {REAL_SRC}. Did Cell 17 run successfully?\")\n",
        "\n",
        "# # Copy TXT transcripts\n",
        "# print(\"\\n--- Copying TXT files ---\")\n",
        "# if TXT_SRC.exists():\n",
        "#     txt_copied = copy_with_progress(TXT_SRC, TXT_DST, \"*.txt\")\n",
        "#     print(f\"Copied {txt_copied} text files.\")\n",
        "# else:\n",
        "#      print(f\"[ERROR] TXT source directory not found: {TXT_SRC}\")\n",
        "\n",
        "# print(\"\\n------------------------------\")\n",
        "# print(\"‚úÖ File copying finished.\")\n",
        "# print(f\"  'Real' audio (now VC): {REAL_DST}\")\n",
        "# print(f\"  'Fake' audio (original TTS): {FAKE_DST}\")\n",
        "# print(f\"  Text files: {TXT_DST}\")\n",
        "# print(\"------------------------------\")\n",
        "\n",
        "# # Basic sanity check: count files in destination\n",
        "# real_count_dst = len(list(REAL_DST.rglob(\"*.wav\")))\n",
        "# fake_count_dst = len(list(FAKE_DST.rglob(\"*.wav\")))\n",
        "# print(f\"Verification: Found {real_count_dst} WAV files in {REAL_DST}\")\n",
        "# print(f\"Verification: Found {fake_count_dst} WAV files in {FAKE_DST}\")\n",
        "\n",
        "# if real_count_dst == 0 or fake_count_dst == 0:\n",
        "#      print(\"[WARNING] One or both destination folders (real/fake) are empty. Check source paths and Cell 17 output.\")\n",
        "# elif real_count_dst != fake_count_dst:\n",
        "#      print(f\"[WARNING] Mismatch in file counts: {real_count_dst} real vs {fake_count_dst} fake. This might be expected if Cell 17 skipped some files.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4\n",
        "#Creating a differnet folder called my_audio so we won't destroy the data created\n",
        "\n",
        "import os, pathlib, shutil\n",
        "\n",
        "# Destination base folders\n",
        "REAL_DST = pathlib.Path(\"/content/my_audio/real\")\n",
        "TXT_DST  = pathlib.Path(\"/content/my_audio/txt\")\n",
        "FAKE_DST = pathlib.Path(\"/content/my_audio/fake\")\n",
        "\n",
        "REAL_DST.mkdir(parents=True, exist_ok=True)\n",
        "TXT_DST.mkdir(parents=True, exist_ok=True)\n",
        "FAKE_DST.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Source folders\n",
        "FAKE_SRC = pathlib.Path(\"/content/vctk_samples/VCTK-Corpus/VCTK-Corpus/fake_audio\")\n",
        "TXT_SRC  = pathlib.Path(\"/content/vctk_samples/VCTK-Corpus/VCTK-Corpus/txt\")\n",
        "REAL_SRC = pathlib.Path(\"/content/vctk_samples/VCTK-Corpus/VCTK-Corpus/wav48\")\n",
        "\n",
        "# Copy FAKE wavs while keeping speaker folders\n",
        "for folder in FAKE_SRC.glob(\"p*\"):\n",
        "    speaker_dst = FAKE_DST / folder.name\n",
        "    speaker_dst.mkdir(parents=True, exist_ok=True)\n",
        "    for wav in folder.glob(\"*.wav\"):\n",
        "        shutil.copy(wav, speaker_dst / wav.name)\n",
        "\n",
        "# Copy REAL wavs while keeping speaker folders\n",
        "for folder in REAL_SRC.glob(\"p*\"):\n",
        "    speaker_dst = REAL_DST / folder.name\n",
        "    speaker_dst.mkdir(parents=True, exist_ok=True)\n",
        "    for wav in folder.glob(\"*.wav\"):\n",
        "        shutil.copy(wav, speaker_dst / wav.name)\n",
        "\n",
        "# Copy TXT transcripts (flat, no subfolders in original)\n",
        "for folder in TXT_SRC.glob(\"p*\"):\n",
        "    speaker_dst = TXT_DST / folder.name\n",
        "    speaker_dst.mkdir(parents=True, exist_ok=True)\n",
        "    for txt in TXT_SRC.glob(\"*.txt\"):\n",
        "        shutil.copy(txt, TXT_DST / txt.name)\n",
        "\n",
        "print(\"‚úÖ All files copied with speaker folder structure preserved!\")\n",
        "print(\"  Real :\", REAL_DST)\n",
        "print(\"  Fake :\", FAKE_DST)\n",
        "print(\"  Text :\", TXT_DST)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8206oHGXHr_j",
        "outputId": "68217eeb-a057-4e67-af18-181b805eb857"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All files copied with speaker folder structure preserved!\n",
            "  Real : /content/my_audio/real\n",
            "  Fake : /content/my_audio/fake\n",
            "  Text : /content/my_audio/txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHwvFTkYY4Ba",
        "outputId": "8dd0a4d7-979d-44d4-8225-2e7b9ed98796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eligible speakers: ['p225', 'p226', 'p227', 'p228']\n",
            "Chosen split (by speakers):\n",
            "  train: ['p225', 'p227']\n",
            "  val  : ['p226']\n",
            "  test : ['p228']\n",
            "By-file shares (train/val/test): 0.462 0.265 0.273\n",
            "\n",
            "Manifest: /content/my_audio_split/manifest.csv\n",
            "Counts per split/class:\n",
            "  train real: 620\n",
            "  train fake: 620\n",
            "  val   real: 356\n",
            "  val   fake: 356\n",
            "  test  real: 366\n",
            "  test  fake: 366\n",
            "\n",
            "Overlap checks (should be empty):\n",
            "  train ‚à© val : set()\n",
            "  train ‚à© test: set()\n",
            "  val   ‚à© test: set()\n"
          ]
        }
      ],
      "source": [
        "#7\n",
        "# Speaker-disjoint splitter with:\n",
        "# - guaranteed non-empty val\n",
        "# - easy \"switch speakers\" controls\n",
        "# - deletes old OUT folder before writing\n",
        "#\n",
        "# Works for both 4 speakers (auto 2/1/1) and 5+ speakers (targets 3/1/1 by speakers).\n",
        "\n",
        "import os, shutil, random, glob, csv, itertools\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "# ---------- CONFIG ----------\n",
        "ROOT = Path(\"/content/my_audio\")           # your current data root (real/fake/{speaker}/*.wav)\n",
        "OUT  = Path(\"/content/my_audio_split\")     # split will be (re)created here\n",
        "AUDIO_EXTS = {\".wav\", \".flac\", \".mp3\", \".m4a\", \".aac\", \".ogg\"}  # add if needed\n",
        "SEED = 42\n",
        "USE_SYMLINKS = True                        # False = copy files instead of symlink\n",
        "REQUIRE_BOTH_CLASSES = True                # speakers must exist under BOTH real/ and fake/\n",
        "# Desired speaker counts (train/val/test)\n",
        "DESIRED_311 = (3, 1, 1)                    # prefer 3/1/1 when you have ‚â•5 speakers\n",
        "FALLBACK_211 = (2, 1, 1)                   # for 4 speakers, this is the safe split\n",
        "# >>> Force specific speakers into splits (edit these to \"switch\")\n",
        "TRAIN_FORCE = set()                        # e.g., {\"p226\",\"p227\",\"p228\"}\n",
        "VAL_FORCE   = set()                        # e.g., {\"p225\"}\n",
        "TEST_FORCE  = set()                        # e.g., {\"p229\"}\n",
        "# --------------------------------------\n",
        "\n",
        "random.seed(SEED)\n",
        "\n",
        "def list_speakers(root, cls):\n",
        "    base = root/cls\n",
        "    if not base.exists(): return []\n",
        "    return sorted([d.name for d in base.iterdir() if d.is_dir() and d.name != \"txt\"])\n",
        "\n",
        "def list_audio(dirpath):\n",
        "    return sorted([p for p in dirpath.rglob(\"*\")\n",
        "                   if p.is_file() and p.suffix.lower() in AUDIO_EXTS])\n",
        "\n",
        "# 1) Find eligible speakers (present and non-empty under both classes if required)\n",
        "real_spk = set(list_speakers(ROOT, \"real\"))\n",
        "fake_spk = set(list_speakers(ROOT, \"fake\"))\n",
        "if REQUIRE_BOTH_CLASSES:\n",
        "    eligible = sorted(real_spk & fake_spk)\n",
        "else:\n",
        "    eligible = sorted(real_spk | fake_spk)\n",
        "\n",
        "def nonempty_both(s):\n",
        "    if not REQUIRE_BOTH_CLASSES:  # just need at least one side non-empty\n",
        "        return (len(list_audio(ROOT/\"real\"/s)) + len(list_audio(ROOT/\"fake\"/s))) > 0\n",
        "    return len(list_audio(ROOT/\"real\"/s)) > 0 and len(list_audio(ROOT/\"fake\"/s)) > 0\n",
        "\n",
        "eligible = [s for s in eligible if nonempty_both(s)]\n",
        "n_spk = len(eligible)\n",
        "if n_spk < 2:\n",
        "    raise RuntimeError(f\"Need ‚â•2 eligible speakers, found {n_spk}: {eligible}\")\n",
        "\n",
        "# 2) Choose target split sizes by number of speakers\n",
        "if n_spk >= sum(DESIRED_311):\n",
        "    N_TRAIN, N_VAL, N_TEST = DESIRED_311   # 3/1/1\n",
        "else:\n",
        "    # With 4 speakers, 2/1/1 is the right shape to keep val+test non-empty\n",
        "    N_TRAIN, N_VAL, N_TEST = FALLBACK_211  # 2/1/1\n",
        "\n",
        "# 3) Validate FORCE sets and fill remaining slots\n",
        "forced = TRAIN_FORCE | VAL_FORCE | TEST_FORCE\n",
        "if forced:\n",
        "    missing = forced - set(eligible)\n",
        "    if missing:\n",
        "        raise RuntimeError(f\"Forced speakers not found/eligible: {sorted(missing)}\")\n",
        "    overlap = (TRAIN_FORCE & VAL_FORCE) | (TRAIN_FORCE & TEST_FORCE) | (VAL_FORCE & TEST_FORCE)\n",
        "    if overlap:\n",
        "        raise RuntimeError(f\"Forced sets overlap: {sorted(overlap)}\")\n",
        "\n",
        "# file counts (use 'real' side as proxy for per-speaker volume)\n",
        "spk_counts = {s: len(list_audio(ROOT/\"real\"/s)) for s in eligible}\n",
        "total_files = sum(spk_counts.values())\n",
        "\n",
        "def pick_k_closest(candidates, k, target_share):\n",
        "    \"\"\"Pick k speakers whose file-count sum is closest to target_share (in files).\"\"\"\n",
        "    if k <= 0: return set()\n",
        "    if len(candidates) <= k: return set(candidates)\n",
        "    best, gap = None, float(\"inf\")\n",
        "    for combo in itertools.combinations(candidates, k):\n",
        "        share = sum(spk_counts[s] for s in combo)\n",
        "        g = abs(share - target_share)\n",
        "        if g < gap:\n",
        "            gap, best = g, set(combo)\n",
        "    return best\n",
        "\n",
        "# Start with forced\n",
        "train_set, val_set, test_set = set(TRAIN_FORCE), set(VAL_FORCE), set(TEST_FORCE)\n",
        "remaining = [s for s in eligible if s not in (train_set | val_set | test_set)]\n",
        "\n",
        "need_train = max(0, N_TRAIN - len(train_set))\n",
        "need_val   = max(0, N_VAL   - len(val_set))\n",
        "need_test  = max(0, N_TEST  - len(test_set))\n",
        "\n",
        "# Target train file share (rough guideline): ~60% if 3/1/1, ~50% if 2/1/1\n",
        "target_train_share = 0.60*total_files if (N_TRAIN, N_VAL, N_TEST) == DESIRED_311 else 0.50*total_files\n",
        "\n",
        "# Fill TRAIN first to hit the share as best as possible\n",
        "if need_train > 0:\n",
        "    add = pick_k_closest(remaining, need_train, target_train_share - sum(spk_counts[s] for s in train_set))\n",
        "    train_set |= add\n",
        "    remaining = [s for s in remaining if s not in add]\n",
        "\n",
        "# Fill VAL with lighter speakers (to keep val/test similar size)\n",
        "if need_val > 0:\n",
        "    remaining.sort(key=lambda s: spk_counts[s])  # lightest first\n",
        "    add = set(remaining[:need_val])\n",
        "    val_set |= add\n",
        "    remaining = remaining[need_val:]\n",
        "\n",
        "# Fill TEST with the rest needed\n",
        "if need_test > 0:\n",
        "    add = set(remaining[:need_test])\n",
        "    test_set |= add\n",
        "    remaining = remaining[need_test:]\n",
        "\n",
        "# Final sanity: exact sizes, disjointness\n",
        "if not (len(train_set) == N_TRAIN and len(val_set) == N_VAL and len(test_set) == N_TEST):\n",
        "    raise RuntimeError(f\"Final sizes must be {N_TRAIN}/{N_VAL}/{N_TEST}, got {len(train_set)}/{len(val_set)}/{len(test_set)}\")\n",
        "if not (train_set.isdisjoint(val_set) and train_set.isdisjoint(test_set) and val_set.isdisjoint(test_set)):\n",
        "    raise RuntimeError(\"Splits are not disjoint by speakers.\")\n",
        "\n",
        "print(\"Eligible speakers:\", eligible)\n",
        "print(\"Chosen split (by speakers):\")\n",
        "print(\"  train:\", sorted(train_set))\n",
        "print(\"  val  :\", sorted(val_set))\n",
        "print(\"  test :\", sorted(test_set))\n",
        "print(\"By-file shares (train/val/test):\",\n",
        "      round(sum(spk_counts[s] for s in train_set)/total_files, 3),\n",
        "      round(sum(spk_counts[s] for s in val_set)/total_files, 3),\n",
        "      round(sum(spk_counts[s] for s in test_set)/total_files, 3))\n",
        "\n",
        "# 4) DELETE OLD OUT (so the previous no-val split is removed), then rebuild\n",
        "if OUT.exists():\n",
        "    shutil.rmtree(OUT)\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    for cls in [\"real\", \"fake\"]:\n",
        "        (OUT/split/cls).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def which_split(speaker):\n",
        "    if speaker in train_set: return \"train\"\n",
        "    if speaker in val_set:   return \"val\"\n",
        "    return \"test\"\n",
        "\n",
        "# 5) Materialize split (symlink/copy) + manifest\n",
        "rows, counts = [], defaultdict(int)\n",
        "for cls in [\"real\", \"fake\"]:\n",
        "    base = ROOT/cls\n",
        "    for sp in (train_set | val_set | test_set):\n",
        "        src_dir = base/sp\n",
        "        dst_dir = OUT/which_split(sp)/cls/sp\n",
        "        dst_dir.mkdir(parents=True, exist_ok=True)\n",
        "        for src in list_audio(src_dir):\n",
        "            dst = dst_dir/src.name\n",
        "            if dst.exists():\n",
        "                try: dst.unlink()\n",
        "                except: pass\n",
        "            if USE_SYMLINKS:\n",
        "                try:\n",
        "                    os.symlink(src.resolve(), dst)\n",
        "                except FileExistsError:\n",
        "                    pass\n",
        "            else:\n",
        "                shutil.copy2(src, dst)\n",
        "            rows.append({\n",
        "                \"split\": which_split(sp),\n",
        "                \"speaker\": sp,\n",
        "                \"label\": 0 if cls==\"real\" else 1,\n",
        "                \"src_path\": str(src.resolve()),\n",
        "                \"dst_path\": str(dst.resolve())\n",
        "            })\n",
        "            counts[(which_split(sp), cls)] += 1\n",
        "\n",
        "manifest_csv = OUT/\"manifest.csv\"\n",
        "with open(manifest_csv, \"w\", newline=\"\") as f:\n",
        "    writer = csv.DictWriter(f, fieldnames=[\"split\",\"speaker\",\"label\",\"src_path\",\"dst_path\"])\n",
        "    writer.writeheader(); writer.writerows(rows)\n",
        "\n",
        "print(\"\\nManifest:\", manifest_csv)\n",
        "print(\"Counts per split/class:\")\n",
        "for split in [\"train\",\"val\",\"test\"]:\n",
        "    for cls in [\"real\",\"fake\"]:\n",
        "        print(f\"  {split:5s} {cls:4s}: {counts[(split, cls)]}\")\n",
        "\n",
        "# Extra safety: show speaker overlap (should be empty)\n",
        "print(\"\\nOverlap checks (should be empty):\")\n",
        "print(\"  train ‚à© val :\", train_set & val_set)\n",
        "print(\"  train ‚à© test:\", train_set & test_set)\n",
        "print(\"  val   ‚à© test:\", val_set & test_set)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "SQIRMktSh-TU"
      },
      "outputs": [],
      "source": [
        "#6\n",
        "# Choose ONE of the two options below:\n",
        "\n",
        "USE_LIBROSA = True   # set to False to use scipy.io.wavfile only\n",
        "\n",
        "if USE_LIBROSA:\n",
        "    # Librosa path: convenient resample-to-16k + mono in one call\n",
        "    !pip -q install librosa soundfile\n",
        "else:\n",
        "    # Scipy path: no extra system libs; we will do a small numpy resample\n",
        "    !pip -q install scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNTVqDPYiGZ3",
        "outputId": "7335aec8-2bee-4357-a7d2-2f7061a1f366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All audio preprocessed to 16kHz and padded/clipped to 64600 samples (torchaudio)\n"
          ]
        }
      ],
      "source": [
        "# =========================================\n",
        "# Preprocess audio with torchaudio: 16kHz mono + pad/trim to 64600\n",
        "# =========================================\n",
        "from pathlib import Path\n",
        "import torchaudio, torch, torch.nn.functional as F\n",
        "\n",
        "TARGET_SR = 16000\n",
        "TARGET_LEN = 64600  # ~4 seconds at 16kHz\n",
        "\n",
        "def preprocess_wav_torch(in_path: Path):\n",
        "    wav, sr = torchaudio.load(str(in_path))   # [C,T]\n",
        "    wav = wav.float()\n",
        "    if wav.shape[0] > 1:\n",
        "        wav = wav.mean(dim=0, keepdim=True)   # [1,T]\n",
        "    if sr != TARGET_SR:\n",
        "        res = torchaudio.transforms.Resample(orig_freq=sr, new_freq=TARGET_SR)\n",
        "        wav = res(wav)                         # [1,T']\n",
        "    T = wav.shape[-1]\n",
        "    if T < TARGET_LEN:\n",
        "        wav = F.pad(wav, (0, TARGET_LEN - T))\n",
        "    else:\n",
        "        wav = wav[..., :TARGET_LEN]\n",
        "    return wav.squeeze(0), TARGET_SR          # [T], 16000\n",
        "\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    split_dir = Path(\"/content/my_audio_split\") / split\n",
        "    for cls in [\"real\", \"fake\"]:\n",
        "        for wav_path in (split_dir/cls).rglob(\"*.wav\"):\n",
        "            wav, sr = preprocess_wav_torch(wav_path)\n",
        "            torchaudio.save(str(wav_path), wav.unsqueeze(0), sr)  # overwrite in place\n",
        "\n",
        "print(\"‚úÖ All audio preprocessed to 16kHz and padded/clipped to 64600 samples (torchaudio)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "L5yMnSA-DpFh"
      },
      "outputs": [],
      "source": [
        "# === Fast resampler ===\n",
        "import numpy as np\n",
        "from math import gcd\n",
        "\n",
        "try:\n",
        "    from scipy.signal import resample_poly\n",
        "    _HAVE_SCIPY = True\n",
        "except Exception:\n",
        "    _HAVE_SCIPY = False\n",
        "\n",
        "def fast_resample(x: np.ndarray, orig_sr: int, target_sr: int) -> np.ndarray:\n",
        "    \"\"\"Resample using scipy.signal.resample_poly; falls back to librosa if SciPy missing.\"\"\"\n",
        "    x = np.asarray(x, dtype=np.float32)\n",
        "    if orig_sr == target_sr:\n",
        "        return x\n",
        "    if _HAVE_SCIPY:\n",
        "        g = gcd(int(orig_sr), int(target_sr))\n",
        "        up = int(target_sr // g)\n",
        "        down = int(orig_sr // g)\n",
        "        y = resample_poly(x, up, down).astype(np.float32)\n",
        "        return y\n",
        "    else:\n",
        "        import librosa  # will need resampy if this path is used\n",
        "        return librosa.resample(x, orig_sr=orig_sr, target_sr=target_sr, res_type=\"kaiser_best\").astype(np.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ixmliIrEykcq"
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# Audio globals and basic utilities\n",
        "# ================================\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "TARGET_SR  = 16000\n",
        "TARGET_LEN = 64600  # ~4 seconds at 16 kHz\n",
        "EPS = 1e-9\n",
        "\n",
        "# Deterministic generator for reproducibility; adjust seed if needed\n",
        "_rng = np.random.default_rng(42)\n",
        "\n",
        "def pad_trim(wav: np.ndarray, target_len: int = TARGET_LEN) -> np.ndarray:\n",
        "    \"\"\"Pad with zeros or trim to exactly target_len samples.\"\"\"\n",
        "    if wav.shape[0] < target_len:\n",
        "        wav = np.pad(wav, (0, target_len - wav.shape[0]))\n",
        "    else:\n",
        "        wav = wav[:target_len]\n",
        "    return wav\n",
        "\n",
        "def resample_to(wav: np.ndarray, sr: int, target_sr: int = TARGET_SR) -> np.ndarray:\n",
        "    \"\"\"Resample to target_sr using high-quality Kaiser filter.\"\"\"\n",
        "    if sr == target_sr:\n",
        "        return wav\n",
        "    return librosa.resample(wav, orig_sr=sr, target_sr=target_sr, res_type=\"kaiser_best\")\n",
        "\n",
        "def post_fix(wav: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Return to the fixed format after any manipulation: length=64600 and clipped to [-1, 1].\"\"\"\n",
        "    wav = pad_trim(wav, TARGET_LEN)\n",
        "    wav = np.clip(wav, -1.0, 1.0)\n",
        "    return wav.astype(np.float32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcyj99GfwB5q"
      },
      "source": [
        "## Manipulations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuxyWsmfwGRD"
      },
      "outputs": [],
      "source": [
        "# === Manipulation Policy & Parameter Ranges (paper-aligned) ===\n",
        "# All ops assume mono float32 in [-1, 1] and return fixed-length 64600 samples.\n",
        "# Values are aligned with the paper's evaluation grid.\n",
        "\n",
        "# Volume Control factors\n",
        "VC_FACTORS = [0.5, 0.1]  # paper uses 0.5 and 0.1\n",
        "\n",
        "# White-Noise SNRs in dB\n",
        "WN_SNRS_DB = [15.0, 20.0, 25.0]  # paper: 15/20/25 dB\n",
        "\n",
        "# Environmental noise SNR (if provided)\n",
        "ENV_SNR_DB = 20.0  # paper uses 20 dB for ESC-50 env noises\n",
        "\n",
        "# Fade ratios and shapes (paper: linear at 0.1/0.3/0.5, plus multiple shapes at 0.5)\n",
        "FADE_RATIOS = [0.1, 0.3, 0.5]\n",
        "FADE_SHAPES = [\"linear\", \"half_sin\", \"quarter_sin\", \"raised_sin\", \"exp\"]  # keep 'linear' for default\n",
        "\n",
        "# Time-Stretch factors (paper: 0.9, 0.95, 1.05, 1.1)\n",
        "TS_FACTORS = [0.9, 0.95, 1.05, 1.1]\n",
        "\n",
        "# Resample offsets around 16kHz (paper: 15k, 15.5k, 16.5k, 17k ‚Üí -1000, -500, +500, +1000)\n",
        "RS_OFFSETS_HZ = [-1000, -500, +500, +1000]\n",
        "\n",
        "# Time-Shift (in samples) at 16kHz (paper: 1,600; 16,000; 32,000)\n",
        "SHIFT_SAMPLES = [1600, 16000, 32000]\n",
        "\n",
        "# Echo parameters (paper: delay 1000/2000; attenuation 0.2/0.5)\n",
        "ECHO_PARAMS = [(1000, 0.2), (1000, 0.5), (2000, 0.2), (2000, 0.5)]\n",
        "\n",
        "# Optional environmental noise clip (16k mono float32). Keep None unless you load one.\n",
        "ENV_NOISE = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkHILZA7wlSQ"
      },
      "outputs": [],
      "source": [
        "# === Core Manipulation Ops (waveform-in, waveform-out) ===\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "def change_volume(wav: np.ndarray, factor: float) -> np.ndarray:\n",
        "    \"\"\"Multiply amplitude by a gain factor, then post-fix.\"\"\"\n",
        "    out = wav * float(factor)\n",
        "    return post_fix(out)\n",
        "\n",
        "def add_white_noise_snr(wav: np.ndarray, snr_db: float) -> np.ndarray:\n",
        "    \"\"\"Add white noise at a target SNR (dB) relative to signal RMS.\"\"\"\n",
        "    sig_pow = max(float(np.mean(wav**2)), EPS)\n",
        "    snr_lin = 10.0 ** (float(snr_db) / 10.0)\n",
        "    noise_pow = sig_pow / snr_lin\n",
        "    noise = np.random.normal(0.0, np.sqrt(noise_pow), size=wav.shape).astype(np.float32)\n",
        "    return post_fix(wav + noise)\n",
        "\n",
        "def add_env_noise(wav: np.ndarray, env_noise: np.ndarray, snr_db: float) -> np.ndarray:\n",
        "    \"\"\"Mix an external environmental noise clip at target SNR (dB).\"\"\"\n",
        "    env = env_noise.astype(np.float32)\n",
        "    if env.shape[0] < wav.shape[0]:\n",
        "        reps = int(np.ceil(wav.shape[0] / env.shape[0]))\n",
        "        env = np.tile(env, reps)[:wav.shape[0]]\n",
        "    else:\n",
        "        env = env[:wav.shape[0]]\n",
        "    sig_pow = max(float(np.mean(wav**2)), EPS)\n",
        "    snr_lin = 10.0 ** (float(snr_db) / 10.0)\n",
        "    noise_pow = sig_pow / snr_lin\n",
        "    cur_pow = max(float(np.mean(env**2)), EPS)\n",
        "    env = env * np.sqrt(noise_pow / cur_pow)\n",
        "    return post_fix(wav + env)\n",
        "\n",
        "def apply_fade(wav: np.ndarray, ratio: float, shape: str = \"linear\") -> np.ndarray:\n",
        "    \"\"\"Apply fade-in/out over a ratio at both ends using the selected shape.\"\"\"\n",
        "    n = wav.shape[0]\n",
        "    k = int(min(0.5, max(0.0, float(ratio))) * n)\n",
        "    if k == 0:\n",
        "        return post_fix(wav)\n",
        "    if shape == \"half_sin\":\n",
        "        ramp = np.sin(np.linspace(0, np.pi/2, k, endpoint=True))**2\n",
        "    elif shape == \"quarter_sin\":\n",
        "        ramp = np.sin(np.linspace(0, np.pi/4, k, endpoint=True))**2\n",
        "    elif shape == \"raised_sin\":\n",
        "        ramp = (np.sin(np.linspace(0, np.pi/2, k, endpoint=True))**2) * 0.5 + 0.5\n",
        "    elif shape == \"exp\":\n",
        "        ramp = np.linspace(0, 1, k, endpoint=True)**2\n",
        "    else:  # linear\n",
        "        ramp = np.linspace(0, 1, k, endpoint=True)\n",
        "    mask = np.ones(n, dtype=np.float32)\n",
        "    mask[:k] *= ramp\n",
        "    mask[-k:] *= ramp[::-1]\n",
        "    return post_fix(wav * mask)\n",
        "\n",
        "def time_stretch_fixed(wav: np.ndarray, factor: float) -> np.ndarray:\n",
        "    \"\"\"Time-stretch while preserving pitch (librosa effects).\"\"\"\n",
        "    stretched = librosa.effects.time_stretch(wav.astype(np.float32), rate=float(factor))\n",
        "    return post_fix(stretched)\n",
        "\n",
        "def resample_variant(wav: np.ndarray, base_sr: int, offset_hz: int) -> np.ndarray:\n",
        "    \"\"\"Resample to base_sr+offset, then back to base_sr to simulate pitch/duration change.\"\"\"\n",
        "    target_sr = max(2000, int(base_sr) + int(offset_hz))\n",
        "    tmp = fast_resample(wav, orig_sr=base_sr, target_sr=target_sr)\n",
        "    back = fast_resample(tmp, orig_sr=target_sr, target_sr=base_sr)\n",
        "    return post_fix(back)\n",
        "\n",
        "def time_shift(wav: np.ndarray, shift_samples: int) -> np.ndarray:\n",
        "    \"\"\"Roll the waveform by +/- shift_samples.\"\"\"\n",
        "    s = int(shift_samples)\n",
        "    return post_fix(np.roll(wav, s))\n",
        "\n",
        "def add_echo(wav: np.ndarray, delay_samples: int, attenuation: float) -> np.ndarray:\n",
        "    \"\"\"Single-tap echo with given delay and attenuation.\"\"\"\n",
        "    delay = int(max(1, delay_samples))\n",
        "    att = float(attenuation)\n",
        "    out = wav.copy()\n",
        "    if delay < wav.shape[0]:\n",
        "        out[delay:] += att * wav[:-delay]\n",
        "    return post_fix(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cc57XfCkwoT6"
      },
      "outputs": [],
      "source": [
        "# === Manual Selection Utilities: print menu, read choice, and apply that op ===\n",
        "# Requires: constants from Cell 1, ops from Cell 2, plus pad_trim/post_fix/TARGET_SR/TARGET_LEN/EPS/_rng.\n",
        "\n",
        "OP_MENU = {\n",
        "    \"1\": (\"VC\",  \"Volume Control\"),\n",
        "    \"2\": (\"WN\",  \"White-Noise SNR\"),\n",
        "    \"3\": (\"ENV\", \"Environmental Noise (if ENV_NOISE is provided)\"),\n",
        "    \"4\": (\"FD\",  \"Fade In/Out\"),\n",
        "    \"5\": (\"TS\",  \"Time Stretch\"),\n",
        "    \"6\": (\"RS\",  \"Resample Variant\"),\n",
        "    \"7\": (\"SF\",  \"Time Shift\"),\n",
        "    \"8\": (\"EC\",  \"Echo\"),\n",
        "}\n",
        "\n",
        "def print_op_menu():\n",
        "    \"\"\"Print available single-op manipulations.\"\"\"\n",
        "    print(\"Choose one manipulation to apply (type the number):\")\n",
        "    for k, (code, label) in OP_MENU.items():\n",
        "        print(f\"  {k}) {label}  [{code}]\")\n",
        "    print()\n",
        "\n",
        "def apply_selected_manipulation(wav, op_code: str, env_noise=None):\n",
        "    \"\"\"Apply the selected manipulation by short code; returns (wav, op_code).\"\"\"\n",
        "    op_code = op_code.upper().strip()\n",
        "    if op_code == \"VC\":\n",
        "        return change_volume(wav, float(_rng.choice(VC_FACTORS))), \"VC\"\n",
        "    if op_code == \"WN\":\n",
        "        return add_white_noise_snr(wav, float(_rng.choice(WN_SNRS_DB))), \"WN\"\n",
        "    if op_code == \"ENV\":\n",
        "        if env_noise is None:\n",
        "            raise ValueError(\"ENV selected but ENV_NOISE is None.\")\n",
        "        return add_env_noise(wav, env_noise, snr_db=float(ENV_SNR_DB)), \"ENV\"\n",
        "    if op_code == \"FD\":\n",
        "        return apply_fade(wav, ratio=float(_rng.choice(FADE_RATIOS)),\n",
        "                          shape=str(_rng.choice(FADE_SHAPES))), \"FD\"\n",
        "    if op_code == \"TS\":\n",
        "        return time_stretch_fixed(wav, float(_rng.choice(TS_FACTORS))), \"TS\"\n",
        "    if op_code == \"RS\":\n",
        "        return resample_variant(wav, base_sr=TARGET_SR,\n",
        "                                offset_hz=int(_rng.choice(RS_OFFSETS_HZ))), \"RS\"\n",
        "    if op_code == \"SF\":\n",
        "        return time_shift(wav, int(_rng.choice(SHIFT_SAMPLES))), \"SF\"\n",
        "    if op_code == \"EC\":\n",
        "        delay, att = _rng.choice(ECHO_PARAMS)\n",
        "        return add_echo(wav, delay_samples=int(delay), attenuation=float(att)), \"EC\"\n",
        "    raise ValueError(f\"Unknown op_code: {op_code}\")\n",
        "\n",
        "def ask_and_apply_once(wav, env_noise=None):\n",
        "    \"\"\"Interactive path: print menu, read user choice, apply op; returns (wav, op_code).\"\"\"\n",
        "    print_op_menu()\n",
        "    choice = input(\"Enter number (1-8): \").strip()\n",
        "    if choice not in OP_MENU:\n",
        "        raise ValueError(f\"Invalid choice: {choice}. Expected one of {list(OP_MENU.keys())}.\")\n",
        "    op_code = OP_MENU[choice][0]\n",
        "    out, code = apply_selected_manipulation(wav, op_code, env_noise=env_noise)\n",
        "    print(f\"Applied: {OP_MENU[choice][1]} [{code}]\")\n",
        "    return out, code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OstCR4o0_cER",
        "outputId": "ef96663f-a0cc-4c6d-f087-4462bc00a7cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[READY] ENV_NOISE preset='traffic', length=2880000 samples @ 16000 Hz\n"
          ]
        }
      ],
      "source": [
        "# === Environmental Noise Presets: build ENV_NOISE (traffic / crowd / hvac / cafe) ===\n",
        "# Drop-in replacement for the previous \"ENV_NOISE loader\". Comments are English only.\n",
        "\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "# You can switch the preset below to: \"traffic\", \"crowd\", \"hvac\", or \"cafe\"\n",
        "ENV_PRESET   = \"traffic\"   # choose: \"traffic\" | \"crowd\" | \"hvac\" | \"cafe\"\n",
        "ENV_SECONDS  = 180         # duration to synthesize (seconds)\n",
        "ENV_SNR_DB   = 25.0        # keep this subtle (higher dB = softer noise when mixed later)\n",
        "\n",
        "def _fft_shape(x: np.ndarray, sr: int, shape_mag: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Apply magnitude shaping in the frequency domain and return time-domain signal.\"\"\"\n",
        "    n = x.size\n",
        "    X = np.fft.rfft(x.astype(np.float64), n=n)\n",
        "    # Ensure shape matches bins\n",
        "    if shape_mag.size != X.size:\n",
        "        raise ValueError(\"shape_mag size mismatch.\")\n",
        "    y = np.fft.irfft(X * shape_mag, n=n)\n",
        "    return y.astype(np.float32)\n",
        "\n",
        "def _make_shape(sr: int, n: int, preset: str) -> np.ndarray:\n",
        "    \"\"\"Construct a magnitude response per preset.\"\"\"\n",
        "    freqs = np.fft.rfftfreq(n, d=1.0/sr)\n",
        "    eps = 1e-9\n",
        "    # Start flat\n",
        "    mag = np.ones_like(freqs, dtype=np.float64)\n",
        "\n",
        "    if preset == \"traffic\":\n",
        "        # Emphasize 80‚Äì800 Hz (engine/road), roll-off above 3 kHz\n",
        "        low  = 1.0 / np.sqrt(np.maximum(freqs, 80.0))        # pink-ish\n",
        "        band = np.clip((freqs >= 80.0) & (freqs <= 800.0), 0, 1).astype(np.float64)\n",
        "        high_cut = 1.0 / (1.0 + (freqs/3000.0)**2)           # gentle low-pass ~3 kHz\n",
        "        mag = (0.6*low + 0.8*band + 0.2) * high_cut\n",
        "\n",
        "    elif preset == \"crowd\":\n",
        "        # Emphasize 200‚Äì2kHz (voices blur), attenuate <100 Hz and >4 kHz\n",
        "        band = np.clip((freqs >= 200.0) & (freqs <= 2000.0), 0, 1).astype(np.float64)\n",
        "        low_cut = (freqs / 100.0)\n",
        "        low_cut = np.clip(low_cut, 0.0, 1.0)\n",
        "        high_cut = 1.0 / (1.0 + (freqs/4000.0)**2)\n",
        "        mag = (0.5*band + 0.2) * low_cut * high_cut\n",
        "\n",
        "    elif preset == \"hvac\":\n",
        "        # Low hum (50‚Äì200 Hz) + broadband low-passed\n",
        "        low_bump = 1.0 / np.sqrt(np.maximum(freqs, 50.0))\n",
        "        low_pass = 1.0 / (1.0 + (freqs/1500.0)**2)\n",
        "        mag = 0.8*low_bump * low_pass\n",
        "\n",
        "    elif preset == \"cafe\":\n",
        "        # Mid-band babble + clatter hints, soft highs\n",
        "        band = np.clip((freqs >= 300.0) & (freqs <= 3000.0), 0, 1).astype(np.float64)\n",
        "        high_cut = 1.0 / (1.0 + (freqs/5000.0)**2)\n",
        "        mag = (0.6*band + 0.3) * high_cut\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown ENV_PRESET: {preset}\")\n",
        "\n",
        "    # Avoid DC explosion\n",
        "    mag[0] = mag[1] if mag.size > 1 else 1.0\n",
        "    # Smooth a little to avoid sharp edges\n",
        "    from scipy.ndimage import gaussian_filter1d  # available in Colab; if not, comment out smoothing\n",
        "    mag = gaussian_filter1d(mag, sigma=2.0)\n",
        "    return mag\n",
        "\n",
        "def _simple_reverb_ir(sr: int, rt60: float = 0.3) -> np.ndarray:\n",
        "    \"\"\"Make a short noise-based decay IR (very light reverb).\"\"\"\n",
        "    length = int(sr * rt60)\n",
        "    if length < 32:\n",
        "        length = 32\n",
        "    ir = np.random.normal(0.0, 1.0, size=length).astype(np.float32)\n",
        "    # Exponential decay envelope\n",
        "    t = np.linspace(0.0, 1.0, length, endpoint=False)\n",
        "    decay = np.exp(-4.0 * t)  # adjust factor for decay speed\n",
        "    ir *= decay\n",
        "    # Normalize IR energy\n",
        "    ir /= (np.sqrt(np.maximum(np.mean(ir**2), 1e-12)) + 1e-8)\n",
        "    return ir\n",
        "\n",
        "def _convolve(x: np.ndarray, h: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Fast convolution via FFT (same length as x).\"\"\"\n",
        "    n = x.size + h.size - 1\n",
        "    N = 1 << (n - 1).bit_length()  # next pow2\n",
        "    X = np.fft.rfft(x.astype(np.float64), n=N)\n",
        "    H = np.fft.rfft(h.astype(np.float64), n=N)\n",
        "    y = np.fft.irfft(X * H, n=N)\n",
        "    y = y[:x.size]\n",
        "    return y.astype(np.float32)\n",
        "\n",
        "def synth_env_noise(preset: str = \"traffic\", seconds: int = 180, sr: int = TARGET_SR) -> np.ndarray:\n",
        "    n = int(seconds * sr)\n",
        "    # Base: white noise\n",
        "    x = np.random.normal(0.0, 1.0, size=n).astype(np.float32)\n",
        "    # Spectral shaping\n",
        "    shape = _make_shape(sr, n, preset=preset)\n",
        "    y = _fft_shape(x, sr, shape_mag=shape)\n",
        "    # Distant/room feel: light low-pass already in shape; add mild reverb\n",
        "    ir = _simple_reverb_ir(sr, rt60=0.25 if preset in (\"traffic\", \"hvac\") else 0.35)\n",
        "    y = _convolve(y, ir)\n",
        "    # Normalize RMS\n",
        "    rms = np.sqrt(np.maximum(np.mean(y**2), 1e-12))\n",
        "    y = (y / (rms + 1e-8)).astype(np.float32)\n",
        "    return y\n",
        "\n",
        "# Build ENV_NOISE according to the chosen preset\n",
        "ENV_NOISE = synth_env_noise(ENV_PRESET, seconds=ENV_SECONDS, sr=TARGET_SR)\n",
        "print(f\"[READY] ENV_NOISE preset='{ENV_PRESET}', length={ENV_NOISE.shape[0]} samples @ {TARGET_SR} Hz\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4e2pp0VBm-s",
        "outputId": "b251429b-8763-4b7f-9ead-e686ebe79049"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "resampy installed.\n"
          ]
        }
      ],
      "source": [
        "# === Install resampy (required by librosa.resample) ===\n",
        "# Comments are in English only.\n",
        "import sys, subprocess\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"resampy==0.4.3\"])\n",
        "print(\"resampy installed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E1vvwTD_QXm"
      },
      "source": [
        "## Manipulation Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMdf_eJPwrxR",
        "outputId": "aa63c372-37f9-4f7b-c89b-47280d27385e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose one manipulation to apply (type the number):\n",
            "  1) Volume Control  [VC]\n",
            "  2) White-Noise SNR  [WN]\n",
            "  3) Environmental Noise (if ENV_NOISE is provided)  [ENV]\n",
            "  4) Fade In/Out  [FD]\n",
            "  5) Time Stretch  [TS]\n",
            "  6) Resample Variant  [RS]\n",
            "  7) Time Shift  [SF]\n",
            "  8) Echo  [EC]\n",
            "\n",
            "Enter number (1-8) to apply to ALL files in ALL splits/classes: 8\n",
            "[INFO] Applying [Echo | EC] to ALL files\n",
            "[CLEAN] Removing entire output root: /content/tmp/augmented\n",
            "[INFO] train/real/p225: processing 231 files\n",
            "[INFO] train/real/p227: processing 389 files\n",
            "[INFO] train/fake/p225: processing 231 files\n",
            "[INFO] train/fake/p227: processing 389 files\n",
            "[INFO] val/real/p226: processing 356 files\n",
            "[INFO] val/fake/p226: processing 356 files\n",
            "[INFO] test/real/p228: processing 366 files\n",
            "[INFO] test/fake/p228: processing 366 files\n",
            "\n",
            "[DONE] Full overwrite run completed.\n",
            "Total written: 2684 ‚Üí /content/tmp/augmented\n"
          ]
        }
      ],
      "source": [
        "# === Batch Runner (force full overwrite): choose once ‚Üí clean output ‚Üí process ALL files ===\n",
        "# Comments are in English only.\n",
        "\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "# ---- Expected from previous cells ----\n",
        "# print_op_menu(), OP_MENU, apply_selected_manipulation()\n",
        "# TARGET_SR, TARGET_LEN, pad_trim, ENV_NOISE\n",
        "\n",
        "# ---- Config ----\n",
        "BASE_DIR    = Path(\"/content/my_audio_split\")   # make sure this is the ORIGINAL dataset root\n",
        "SPLITS      = [\"train\", \"val\", \"test\"]\n",
        "CLASSES     = [\"real\", \"fake\"]\n",
        "AUDIO_EXTS  = (\".wav\", \".flac\", \".mp3\", \".m4a\", \".ogg\")\n",
        "\n",
        "OUTPUT_BASE = Path(\"/content/tmp/augmented\")\n",
        "\n",
        "# Behavior: force-clean and overwrite everything on each run\n",
        "CLEAN_WHOLE_OUTPUT_ROOT = True   # delete OUTPUT_BASE entirely before writing\n",
        "SKIP_INPUTS_WITH_DUNDER = False  # process inputs even if their name already contains \"__\"\n",
        "OVERWRITE_OUTPUT        = True   # if file exists (shouldn't after clean), overwrite anyway\n",
        "\n",
        "# ---- Helpers ----\n",
        "def safe_read_audio(path: Path):\n",
        "    \"\"\"Read audio as (waveform float32, sample_rate int).\"\"\"\n",
        "    try:\n",
        "        wav, sr = sf.read(str(path), always_2d=False)\n",
        "        wav = np.asarray(wav).squeeze()\n",
        "        return wav.astype(np.float32), int(sr)\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] soundfile failed on {path.name}: {e} ‚Üí falling back to librosa.load\")\n",
        "        wav, sr = librosa.load(str(path), sr=None, mono=False)\n",
        "        if np.ndim(wav) > 1:\n",
        "            wav = np.mean(wav, axis=0)\n",
        "        return wav.astype(np.float32), int(sr)\n",
        "\n",
        "def list_audio_recursive(folder: Path):\n",
        "    \"\"\"Return all audio files (matching AUDIO_EXTS) recursively under 'folder'.\"\"\"\n",
        "    return sorted([p for p in folder.rglob(\"*\") if p.is_file() and p.suffix.lower() in AUDIO_EXTS])\n",
        "\n",
        "# ---- Choose the manipulation once ----\n",
        "print_op_menu()\n",
        "choice = input(\"Enter number (1-8) to apply to ALL files in ALL splits/classes: \").strip()\n",
        "if choice not in OP_MENU:\n",
        "    raise ValueError(f\"Invalid choice: {choice}. Expected one of {list(OP_MENU.keys())}.\")\n",
        "OP_CODE = OP_MENU[choice][0]\n",
        "print(f\"[INFO] Applying [{OP_MENU[choice][1]} | {OP_CODE}] to ALL files\")\n",
        "\n",
        "# ---- Clean the entire output tree first ----\n",
        "if CLEAN_WHOLE_OUTPUT_ROOT and OUTPUT_BASE.exists():\n",
        "    print(f\"[CLEAN] Removing entire output root: {OUTPUT_BASE}\")\n",
        "    shutil.rmtree(OUTPUT_BASE)\n",
        "OUTPUT_BASE.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ---- Process everything ----\n",
        "total_written = 0\n",
        "for split in SPLITS:\n",
        "    for cls in CLASSES:\n",
        "        root_cls = BASE_DIR / split / cls\n",
        "        if not root_cls.exists():\n",
        "            print(f\"[WARN] Missing class folder: {root_cls} ‚Üí skipping\")\n",
        "            continue\n",
        "\n",
        "        p_folders = sorted([d for d in root_cls.iterdir() if d.is_dir() and d.name.startswith(\"p\")])\n",
        "        if not p_folders:\n",
        "            print(f\"[WARN] No p-folders under: {root_cls}\")\n",
        "            continue\n",
        "\n",
        "        for p_folder in p_folders:\n",
        "            files = list_audio_recursive(p_folder)\n",
        "            if not files:\n",
        "                print(f\"[WARN] {split}/{cls}/{p_folder.name}: 0 audio files ‚Üí skipped\")\n",
        "                continue\n",
        "\n",
        "            # Optional filtering (we do NOT skip dunder here)\n",
        "            to_process = files if not SKIP_INPUTS_WITH_DUNDER else [p for p in files if \"__\" not in p.stem]\n",
        "\n",
        "            out_p = OUTPUT_BASE / split / cls / p_folder.name\n",
        "            out_p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "            print(f\"[INFO] {split}/{cls}/{p_folder.name}: processing {len(to_process)} files\")\n",
        "\n",
        "            for path in to_process:\n",
        "                out_path = out_p / f\"{path.stem}__{OP_CODE}.wav\"\n",
        "                if out_path.exists() and not OVERWRITE_OUTPUT:\n",
        "                    continue  # not expected after clean, but kept for safety\n",
        "\n",
        "                wav, sr = safe_read_audio(path)\n",
        "                if np.ndim(wav) > 1:\n",
        "                    wav = np.mean(wav, axis=0)\n",
        "                if sr != TARGET_SR:\n",
        "                    wav = librosa.resample(wav, orig_sr=sr, target_sr=TARGET_SR)\n",
        "                wav = pad_trim(wav, TARGET_LEN)\n",
        "\n",
        "                aug_wav, _ = apply_selected_manipulation(wav, OP_CODE, env_noise=ENV_NOISE)\n",
        "                sf.write(str(out_path), aug_wav, TARGET_SR)\n",
        "                total_written += 1\n",
        "\n",
        "print(\"\\n[DONE] Full overwrite run completed.\")\n",
        "print(f\"Total written: {total_written} ‚Üí {OUTPUT_BASE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEAr77-cwv2v"
      },
      "outputs": [],
      "source": [
        "# === Dataset Fixed-Op Wrapper: force a specific manipulation for train only ===\n",
        "# Use this to train with ONE chosen manipulation applied to every training item.\n",
        "# It wraps your existing dataset without modifying it.\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ManualAugDataset(Dataset):\n",
        "    \"\"\"Wrap an existing dataset and apply a fixed op in __getitem__ for split=='train'.\"\"\"\n",
        "    def __init__(self, base_dataset: Dataset, fixed_op_code: str, env_noise=None):\n",
        "        super().__init__()\n",
        "        self.base = base_dataset\n",
        "        self.fixed_op_code = fixed_op_code.upper().strip()\n",
        "        self.env_noise = env_noise\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.base)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        out = self.base[idx]\n",
        "        # Expecting base to return (waveform_tensor, label, maybe_meta)\n",
        "        if isinstance(out, (list, tuple)) and len(out) >= 2:\n",
        "            wav_t, label = out[0], out[1]\n",
        "        else:\n",
        "            raise RuntimeError(\"Base dataset must return at least (waveform_tensor, label).\")\n",
        "\n",
        "        wav = wav_t.numpy().astype(np.float32)\n",
        "        wav = pad_trim(wav, TARGET_LEN)\n",
        "\n",
        "        wav_fixed, code = apply_selected_manipulation(wav, self.fixed_op_code, env_noise=self.env_noise)\n",
        "        return torch.from_numpy(wav_fixed).float(), label, code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1RDMw-EwDDY"
      },
      "source": [
        "## CHECKPOINT SETUP"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ◊ë◊ô◊ò◊ï◊ú ◊î◊ó◊™◊ô◊û◊î"
      ],
      "metadata": {
        "id": "3YhIIevfODb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Signature Neutralization for BOTH classes (real + fake)\n",
        "# - Input : /content/my_audio_split/{train,val,test}/{real,fake}/{speaker}/*.wav\n",
        "# - Output: /content/my_audio_equalized/{train,val,test}/{real,fake}/{speaker}/*.wav\n",
        "# Steps (for every file):\n",
        "#   1) Load -> mono\n",
        "#   2) Resample to 16kHz\n",
        "#   3) Peak-normalize (avoid clipping), fixed fade-in/out\n",
        "#   4) Pad/Trim to exactly 4 seconds (64600 samples)\n",
        "#   5) Codec round-trip (Opus 24k) to imprint the SAME processing signature\n",
        "#   6) Save as PCM16\n",
        "# ============================================================\n",
        "\n",
        "import os, subprocess, tempfile, shutil\n",
        "from pathlib import Path\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchaudio\n",
        "import soundfile as sf\n",
        "\n",
        "SRC_ROOT = Path(\"/content/my_audio_split\")\n",
        "DST_ROOT = Path(\"/content/my_audio_equalized\")\n",
        "SR       = 16000\n",
        "T_SAMPLES= 64600         # ~4.0375s to match your previous setting\n",
        "FADE_S   = 0.005         # 5 ms fade-in/out\n",
        "CODEC    = \"opus\"\n",
        "BITRATE  = \"24k\"\n",
        "MAX_WORKERS = 4\n",
        "\n",
        "def to_mono_resample(wav, sr):\n",
        "    \"\"\"Convert to mono and resample to SR.\"\"\"\n",
        "    wav = wav.float()\n",
        "    if wav.dim() == 2:  # [C,T]\n",
        "        if wav.size(0) > 1:\n",
        "            wav = wav.mean(dim=0, keepdim=True)\n",
        "    elif wav.dim() == 1:\n",
        "        wav = wav.unsqueeze(0)\n",
        "    else:\n",
        "        # Unexpected shape; flatten channels\n",
        "        wav = wav.reshape(1, -1)\n",
        "\n",
        "    if sr != SR:\n",
        "        wav = torchaudio.functional.resample(wav, sr, SR)\n",
        "        sr = SR\n",
        "    return wav, sr\n",
        "\n",
        "def peak_normalize(wav, peak=0.98):\n",
        "    \"\"\"Simple peak normalization to a fixed peak amplitude.\"\"\"\n",
        "    m = wav.abs().max()\n",
        "    if m > 0:\n",
        "        wav = wav * (peak / m)\n",
        "    return wav\n",
        "\n",
        "def fade_edges(wav, sr, fade_s=FADE_S):\n",
        "    \"\"\"Apply short linear fade-in/out to unify edges.\"\"\"\n",
        "    n = wav.shape[-1]\n",
        "    fade = int(fade_s * sr)\n",
        "    fade = max(0, min(fade, n // 20))  # guard\n",
        "    if fade > 0:\n",
        "        ramp_in  = torch.linspace(0, 1, steps=fade, dtype=wav.dtype, device=wav.device)\n",
        "        ramp_out = torch.linspace(1, 0, steps=fade, dtype=wav.dtype, device=wav.device)\n",
        "        wav[..., :fade]  *= ramp_in\n",
        "        wav[..., -fade:] *= ramp_out\n",
        "    return wav\n",
        "\n",
        "def pad_or_trim(wav, target_len=T_SAMPLES):\n",
        "    \"\"\"Pad with zeros or center-trim to exact length deterministically.\"\"\"\n",
        "    n = wav.shape[-1]\n",
        "    if n == target_len:\n",
        "        return wav\n",
        "    if n < target_len:\n",
        "        pad = target_len - n\n",
        "        return torch.nn.functional.pad(wav, (0, pad))\n",
        "    # n > target_len ‚Üí center crop (deterministic; change to random if you prefer)\n",
        "    start = (n - target_len) // 2\n",
        "    return wav[..., start:start+target_len]\n",
        "\n",
        "def codec_roundtrip_bytes(wav, sr, codec=CODEC, bitrate=BITRATE):\n",
        "    \"\"\"Encode‚Üídecode via ffmpeg to imprint SAME codec signature for all files.\"\"\"\n",
        "    wav_np = wav.squeeze(0).cpu().numpy()\n",
        "    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=True) as fin, \\\n",
        "         tempfile.NamedTemporaryFile(suffix=f\".{('ogg' if codec=='opus' else codec)}\", delete=True) as fenc, \\\n",
        "         tempfile.NamedTemporaryFile(suffix=\".wav\", delete=True) as fout:\n",
        "\n",
        "        # write temp input WAV (float32)\n",
        "        sf.write(fin.name, wav_np.astype(np.float32), sr)\n",
        "\n",
        "        # encode\n",
        "        enc_cmd = [\"ffmpeg\", \"-y\", \"-hide_banner\", \"-loglevel\", \"error\", \"-i\", fin.name]\n",
        "        if codec == \"opus\":\n",
        "            enc_cmd += [\"-c:a\",\"libopus\",\"-b:a\", bitrate, fenc.name]\n",
        "        elif codec == \"mp3\":\n",
        "            enc_cmd += [\"-c:a\",\"libmp3lame\",\"-b:a\", bitrate, fenc.name]\n",
        "        else:\n",
        "            enc_cmd += [\"-c:a\", codec, \"-b:a\", bitrate, fenc.name]\n",
        "        subprocess.run(enc_cmd, check=True)\n",
        "\n",
        "        # decode to linear PCM\n",
        "        subprocess.run([\"ffmpeg\",\"-y\",\"-hide_banner\",\"-loglevel\",\"error\",\n",
        "                        \"-i\", fenc.name, \"-c:a\", \"pcm_s16le\", fout.name], check=True)\n",
        "\n",
        "        wav2, sr2 = sf.read(fout.name, dtype=\"float32\", always_2d=False)\n",
        "        if sr2 != sr:\n",
        "            wav2 = torchaudio.functional.resample(torch.tensor(wav2).float().unsqueeze(0), sr2, sr).squeeze(0).numpy()\n",
        "    return torch.tensor(wav2).unsqueeze(0)\n",
        "\n",
        "def process_one(src: Path, dst: Path):\n",
        "    \"\"\"Full neutralization pipeline for one file.\"\"\"\n",
        "    try:\n",
        "        wav, sr = torchaudio.load(str(src))            # [C,T]\n",
        "        wav, sr = to_mono_resample(wav, sr)            # [1,T]\n",
        "        wav = peak_normalize(wav)                      # unify peak level\n",
        "        wav = fade_edges(wav, sr)                      # same edge shape\n",
        "        wav = pad_or_trim(wav, T_SAMPLES)              # exact length\n",
        "        wav = codec_roundtrip_bytes(wav, sr)           # SAME codec signature\n",
        "        wav = pad_or_trim(wav, T_SAMPLES)              # guard length again\n",
        "        # Save as PCM16\n",
        "        dst.parent.mkdir(parents=True, exist_ok=True)\n",
        "        sf.write(str(dst), wav.squeeze(0).cpu().numpy().astype(np.float32), sr, subtype=\"PCM_16\")\n",
        "        return True, str(src)\n",
        "    except Exception as e:\n",
        "        return False, f\"{src.name}: {repr(e)}\"\n",
        "\n",
        "def build_joblist():\n",
        "    jobs = []\n",
        "    for split in [\"train\", \"val\", \"test\"]:\n",
        "        for cls in [\"real\", \"fake\"]:\n",
        "            in_dir  = SRC_ROOT / split / cls\n",
        "            if not in_dir.exists():\n",
        "                continue\n",
        "            for sp_dir in in_dir.iterdir():\n",
        "                if sp_dir.is_dir():\n",
        "                    for src in sp_dir.rglob(\"*.wav\"):\n",
        "                        rel  = src.relative_to(SRC_ROOT)\n",
        "                        dst  = DST_ROOT / rel\n",
        "                        jobs.append((src, dst))\n",
        "    return jobs\n",
        "\n",
        "# Clean output and run\n",
        "if DST_ROOT.exists():\n",
        "    shutil.rmtree(DST_ROOT)\n",
        "DST_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "jobs = build_joblist()\n",
        "print(f\"[Neutralize] Found {len(jobs)} files to process.\")\n",
        "if not jobs:\n",
        "    print(\"No files found under /content/my_audio_split ‚Äî run your splitter first.\")\n",
        "else:\n",
        "    ok, fail = 0, 0\n",
        "    from tqdm import tqdm\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
        "        futs = [ex.submit(process_one, src, dst) for (src, dst) in jobs]\n",
        "        for fut in tqdm(as_completed(futs), total=len(futs)):\n",
        "            success, msg = fut.result()\n",
        "            if success: ok += 1\n",
        "            else:\n",
        "                fail += 1\n",
        "                print(\"[WARN]\", msg)\n",
        "    print(f\"[Neutralize] Done. OK={ok} | FAIL={fail}\")\n",
        "    print(f\"[Neutralize] Output root: {DST_ROOT}\")\n",
        "\n",
        "# >>> IMPORTANT: point your loaders to the equalized root:\n",
        "# train_ds = AudioDataset(\"/content/my_audio_equalized/train\")\n",
        "# val_ds   = AudioDataset(\"/content/my_audio_equalized/val\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erc5YWqROBwl",
        "outputId": "c8813ef8-78aa-4723-dc6e-6201a16ae013"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Neutralize] Found 2684 files to process.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2684/2684 [11:57<00:00,  3.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Neutralize] Done. OK=2684 | FAIL=0\n",
            "[Neutralize] Output root: /content/my_audio_equalized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Neutralize v2.1: Loudness (LUFS) + Gentle Dynamic Range + Low-pass\n",
        "# Input : /content/my_audio_equalized/{split}/{cls}/{spk}/*.wav\n",
        "# Output: /content/my_audio_equalized_lufs/{split}/{cls}/{spk}/*.wav\n",
        "# ============================================================\n",
        "\n",
        "import os, shutil, numpy as np\n",
        "from pathlib import Path\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "import torch, torchaudio, soundfile as sf\n",
        "!pip -q install pyloudnorm\n",
        "import pyloudnorm as pyln\n",
        "\n",
        "SRC = Path(\"/content/my_audio_equalized\")\n",
        "DST = Path(\"/content/my_audio_equalized_lufs\")\n",
        "\n",
        "SR        = 16000\n",
        "T_SAMPLES = 64600\n",
        "TARGET_LUFS = -23.0   # change to taste (-24 to -20 common)\n",
        "LP_CUTOFF   = 7200    # 7.2 kHz low-pass to reduce bandwidth differences\n",
        "MAX_WORKERS = 4\n",
        "\n",
        "def to_mono_resample(w, sr):\n",
        "    if w.dim()==2 and w.size(0)>1: w = w.mean(0, keepdim=True)\n",
        "    elif w.dim()==1:               w = w.unsqueeze(0)\n",
        "    elif w.dim()>2:                w = w.reshape(1, -1)\n",
        "    if sr != SR:\n",
        "        w = torchaudio.functional.resample(w, sr, SR)\n",
        "        sr = SR\n",
        "    return w, sr\n",
        "\n",
        "def pad_or_trim(w, tgt=T_SAMPLES):\n",
        "    n = w.shape[-1]\n",
        "    if n == tgt: return w\n",
        "    if n < tgt:  return torch.nn.functional.pad(w, (0, tgt-n))\n",
        "    start = (n - tgt)//2\n",
        "    return w[..., start:start+tgt]\n",
        "\n",
        "def peak_guard(w, peak=0.999):\n",
        "    m = w.abs().max()\n",
        "    if m > 0:\n",
        "        w = w * (peak / m)\n",
        "    return w\n",
        "\n",
        "def loudness_normalize(w, sr, target_lufs=TARGET_LUFS):\n",
        "    # pyloudnorm expects float64 numpy\n",
        "    x = w.squeeze(0).cpu().numpy().astype(np.float64)\n",
        "    meter = pyln.Meter(sr)\n",
        "    loud = meter.integrated_loudness(x)\n",
        "    y = pyln.normalize.loudness(x, loud, target_lufs)\n",
        "    return torch.tensor(y, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "def gentle_compressor(w, threshold_db=-18.0, ratio=2.0, makeup_db=0.0):\n",
        "    # simple static waveshaper in linear domain (approx), very gentle\n",
        "    x = w\n",
        "    thr = 10**(threshold_db/20.0)\n",
        "    over = (x.abs() > thr)\n",
        "    y = x.clone()\n",
        "    y[over] = torch.sign(x[over]) * (thr + (x[over].abs()-thr)/ratio)\n",
        "    # makeup gain\n",
        "    y = y * (10**(makeup_db/20.0))\n",
        "    return y\n",
        "\n",
        "def lowpass(w, sr, cutoff=LP_CUTOFF):\n",
        "    return torchaudio.functional.lowpass_biquad(w, sr, cutoff)\n",
        "\n",
        "def process_one(src: Path, dst: Path):\n",
        "    try:\n",
        "        w, sr = torchaudio.load(str(src))\n",
        "        w, sr = to_mono_resample(w, sr)\n",
        "        # LUFS normalization\n",
        "        w = loudness_normalize(w, sr, TARGET_LUFS)\n",
        "        # Gentle compressor to align dynamic range\n",
        "        w = gentle_compressor(w, threshold_db=-20.0, ratio=2.0, makeup_db=1.5)\n",
        "        # Low-pass to common bandwidth\n",
        "        w = lowpass(w, sr, LP_CUTOFF)\n",
        "        # Length + headroom guard\n",
        "        w = pad_or_trim(w, T_SAMPLES)\n",
        "        w = peak_guard(w, 0.98)\n",
        "        # Save PCM16\n",
        "        dst.parent.mkdir(parents=True, exist_ok=True)\n",
        "        sf.write(str(dst), w.squeeze(0).cpu().numpy().astype(np.float32), sr, subtype=\"PCM_16\")\n",
        "        return True, str(src)\n",
        "    except Exception as e:\n",
        "        return False, f\"{src}: {repr(e)}\"\n",
        "\n",
        "# Build jobs\n",
        "jobs = []\n",
        "for split in [\"train\",\"val\",\"test\"]:\n",
        "    for cls in [\"real\",\"fake\"]:\n",
        "        base = SRC/split/cls\n",
        "        if not base.exists(): continue\n",
        "        for sp_dir in base.iterdir():\n",
        "            if not sp_dir.is_dir(): continue\n",
        "            for wav in sp_dir.rglob(\"*.wav\"):\n",
        "                rel = wav.relative_to(SRC)\n",
        "                dst = DST/rel\n",
        "                jobs.append((wav, dst))\n",
        "\n",
        "# Run\n",
        "if DST.exists(): shutil.rmtree(DST)\n",
        "ok=fail=0\n",
        "from tqdm import tqdm\n",
        "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
        "    futs = [ex.submit(process_one, s, d) for (s,d) in jobs]\n",
        "    for fut in tqdm(as_completed(futs), total=len(futs)):\n",
        "        success, msg = fut.result()\n",
        "        ok += int(success); fail += int(not success)\n",
        "print(f\"[Neutralize v2.1] OK={ok} | FAIL={fail}  ‚Üí  {DST}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQyc7XqPbvlw",
        "outputId": "c3dba222-2bd2-4f0f-f61b-1a8e2afebbca"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 2/2684 [00:00<02:23, 18.68it/s]/usr/local/lib/python3.12/dist-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
            "  warnings.warn(\"Possible clipped samples in output.\")\n",
            "  2%|‚ñè         | 55/2684 [00:00<00:43, 59.79it/s]/usr/local/lib/python3.12/dist-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
            "  warnings.warn(\"Possible clipped samples in output.\")\n",
            "  3%|‚ñé         | 85/2684 [00:01<00:43, 59.11it/s]/usr/local/lib/python3.12/dist-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
            "  warnings.warn(\"Possible clipped samples in output.\")\n",
            "  6%|‚ñå         | 166/2684 [00:02<00:39, 63.33it/s]/usr/local/lib/python3.12/dist-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
            "  warnings.warn(\"Possible clipped samples in output.\")\n",
            "  8%|‚ñä         | 226/2684 [00:03<00:39, 62.48it/s]/usr/local/lib/python3.12/dist-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
            "  warnings.warn(\"Possible clipped samples in output.\")\n",
            "  9%|‚ñä         | 233/2684 [00:03<00:41, 59.77it/s]/usr/local/lib/python3.12/dist-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
            "  warnings.warn(\"Possible clipped samples in output.\")\n",
            " 11%|‚ñà         | 300/2684 [00:04<00:38, 61.71it/s]/usr/local/lib/python3.12/dist-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
            "  warnings.warn(\"Possible clipped samples in output.\")\n",
            "/usr/local/lib/python3.12/dist-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
            "  warnings.warn(\"Possible clipped samples in output.\")\n",
            " 12%|‚ñà‚ñè        | 322/2684 [00:05<00:41, 57.56it/s]/usr/local/lib/python3.12/dist-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
            "  warnings.warn(\"Possible clipped samples in output.\")\n",
            " 13%|‚ñà‚ñé        | 338/2684 [00:05<00:40, 58.32it/s]/usr/local/lib/python3.12/dist-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
            "  warnings.warn(\"Possible clipped samples in output.\")\n",
            " 13%|‚ñà‚ñé        | 360/2684 [00:05<00:38, 60.53it/s]/usr/local/lib/python3.12/dist-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
            "  warnings.warn(\"Possible clipped samples in output.\")\n",
            "/usr/local/lib/python3.12/dist-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
            "  warnings.warn(\"Possible clipped samples in output.\")\n",
            " 14%|‚ñà‚ñç        | 374/2684 [00:06<00:37, 61.15it/s]/usr/local/lib/python3.12/dist-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
            "  warnings.warn(\"Possible clipped samples in output.\")\n",
            " 14%|‚ñà‚ñç        | 381/2684 [00:06<00:39, 58.53it/s]/usr/local/lib/python3.12/dist-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
            "  warnings.warn(\"Possible clipped samples in output.\")\n",
            " 16%|‚ñà‚ñå        | 424/2684 [00:07<00:35, 63.27it/s]/usr/local/lib/python3.12/dist-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
            "  warnings.warn(\"Possible clipped samples in output.\")\n",
            " 18%|‚ñà‚ñä        | 491/2684 [00:08<00:37, 59.00it/s]/usr/local/lib/python3.12/dist-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
            "  warnings.warn(\"Possible clipped samples in output.\")\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2684/2684 [00:58<00:00, 45.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Neutralize v2.1] OK=2684 | FAIL=0  ‚Üí  /content/my_audio_equalized_lufs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# AudioDataset (anti-signature v3)\n",
        "# - Stronger but still mild, symmetric train-time perturbations\n",
        "# - Changes vs v2:\n",
        "#   * CODEC_P = 0.6 (train only), BITRATE = \"32k\"\n",
        "#   * Resample jitter ¬±3%\n",
        "#   * Gentle shelf-EQ tilt (low/high gain ¬±1.5 dB) - train only\n",
        "# - Always: DC removal, fade edges, z-score; val/test deterministic\n",
        "# ============================================================\n",
        "\n",
        "import os, tempfile, subprocess, numpy as np, torch, torchaudio, soundfile as sf\n",
        "from torch.utils.data import Dataset\n",
        "from pathlib import Path\n",
        "\n",
        "TARGET_SR    = 16000\n",
        "TARGET_LEN   = 64600       # ~4.04s\n",
        "FADE_S       = 0.005\n",
        "AMP_JITTER   = 0.05        # ¬±5% (train only)\n",
        "NOISE_SNR_DB = 40          # very small white noise (train only)\n",
        "CODEC_P      = 0.6         # ‚Üë probability for codec round-trip (train only)\n",
        "BITRATE      = \"32k\"       # a bit stronger than 48k, still quite transparent\n",
        "RS_JITTER    = 0.03        # ¬±3% resample jitter (train only)\n",
        "SHIFT_FRAC   = 0.01        # ¬±1% circular shift (train only)\n",
        "EQ_DB        = 1.5         # shelf tilt magnitude (¬±1.5 dB)\n",
        "\n",
        "LABELS = {\"real\": 0, \"fake\": 1}\n",
        "\n",
        "def _ensure_mono(w):\n",
        "    if w.dim() == 2 and w.size(0) > 1: w = w.mean(dim=0, keepdim=True)\n",
        "    elif w.dim() == 1:                 w = w.unsqueeze(0)\n",
        "    elif w.dim() > 2:                  w = w.reshape(1, -1)\n",
        "    return w\n",
        "\n",
        "def _remove_dc(w): return w - w.mean(dim=-1, keepdim=True)\n",
        "\n",
        "def _zscore(w, eps=1e-7):\n",
        "    std = w.std(dim=-1, keepdim=True)\n",
        "    return w / (std + eps)\n",
        "\n",
        "def _fade_edges(w, sr, fade_s=FADE_S):\n",
        "    n = w.shape[-1]\n",
        "    fade = int(fade_s * sr)\n",
        "    fade = max(0, min(fade, n // 20))\n",
        "    if fade > 0:\n",
        "        ramp_in  = torch.linspace(0, 1, steps=fade, dtype=w.dtype, device=w.device)\n",
        "        ramp_out = torch.linspace(1, 0, steps=fade, dtype=w.dtype, device=w.device)\n",
        "        w[..., :fade]  *= ramp_in\n",
        "        w[..., -fade:] *= ramp_out\n",
        "    return w\n",
        "\n",
        "def _center_crop(w, tgt=TARGET_LEN):\n",
        "    n = w.shape[-1]\n",
        "    if n == tgt: return w\n",
        "    if n < tgt:  return torch.nn.functional.pad(w, (0, tgt - n))\n",
        "    start = (n - tgt) // 2\n",
        "    return w[..., start:start+tgt]\n",
        "\n",
        "def _random_crop(w, tgt=TARGET_LEN):\n",
        "    n = w.shape[-1]\n",
        "    if n <= tgt: return torch.nn.functional.pad(w, (0, tgt - n))\n",
        "    start = torch.randint(0, n - tgt + 1, (1,)).item()\n",
        "    return w[..., start:start+tgt]\n",
        "\n",
        "def _time_shift(w, max_shift_frac=SHIFT_FRAC):\n",
        "    n = w.shape[-1]\n",
        "    if n < 10: return w\n",
        "    max_shift = max(1, int(n * max_shift_frac))\n",
        "    k = torch.randint(-max_shift, max_shift+1, (1,)).item()\n",
        "    if k == 0: return w\n",
        "    return torch.roll(w, shifts=k, dims=-1)\n",
        "\n",
        "def _resample_jitter(w, sr, jitter=RS_JITTER):\n",
        "    if jitter <= 0: return w\n",
        "    factor = float(np.random.uniform(1.0 - jitter, 1.0 + jitter))\n",
        "    new_sr = max(2000, min(int(sr * factor), 48000))\n",
        "    w2 = torchaudio.functional.resample(w, sr, new_sr)\n",
        "    w3 = torchaudio.functional.resample(w2, new_sr, sr)\n",
        "    return w3\n",
        "\n",
        "def _amp_jitter(w, mag=AMP_JITTER):\n",
        "    scale = 1.0 + float(np.random.uniform(-mag, mag))\n",
        "    return w * scale\n",
        "\n",
        "def _add_noise(w, snr_db=NOISE_SNR_DB):\n",
        "    p_sig = (w**2).mean().item() + 1e-12\n",
        "    p_noise = p_sig / (10**(snr_db/10.0))\n",
        "    noise = torch.randn_like(w) * np.sqrt(p_noise)\n",
        "    return w + noise\n",
        "\n",
        "def _codec_roundtrip(w, sr, bitrate=BITRATE):\n",
        "    x = w.squeeze(0).cpu().numpy()\n",
        "    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=True) as fin, \\\n",
        "         tempfile.NamedTemporaryFile(suffix=\".ogg\", delete=True) as fenc, \\\n",
        "         tempfile.NamedTemporaryFile(suffix=\".wav\", delete=True) as fout:\n",
        "        sf.write(fin.name, x.astype(np.float32), sr)\n",
        "        enc = [\"ffmpeg\",\"-y\",\"-hide_banner\",\"-loglevel\",\"error\",\"-i\",fin.name,\n",
        "               \"-c:a\",\"libopus\",\"-b:a\",bitrate, fenc.name]\n",
        "        subprocess.run(enc, check=True)\n",
        "        dec = [\"ffmpeg\",\"-y\",\"-hide_banner\",\"-loglevel\",\"error\",\"-i\",fenc.name,\n",
        "               \"-c:a\",\"pcm_s16le\",fout.name]\n",
        "        subprocess.run(dec, check=True)\n",
        "        y, sr2 = sf.read(fout.name, dtype=\"float32\", always_2d=False)\n",
        "        y = torch.tensor(y, dtype=torch.float32).unsqueeze(0)\n",
        "        if sr2 != sr:\n",
        "            y = torchaudio.functional.resample(y, sr2, sr)\n",
        "    return y\n",
        "\n",
        "def _shelf_tilt(w, sr, db=EQ_DB):\n",
        "    \"\"\"Gentle low-shelf and high-shelf combination (¬±db); train only.\"\"\"\n",
        "    # design two biquads with tiny gain; choose random polarity\n",
        "    sign = 1.0 if np.random.rand() < 0.5 else -1.0\n",
        "    # convert dB to linear for biquad 'gain' param (torchaudio uses amplitude)\n",
        "    gain_lin = 10**((sign*db)/20.0)\n",
        "    # low-shelf around 200Hz, high-shelf around 4kHz\n",
        "    w = torchaudio.functional.lowpass_biquad(w, sr, cutoff_freq=200) * gain_lin\n",
        "    w = torchaudio.functional.highpass_biquad(w, sr, cutoff_freq=4000) * (1.0/gain_lin)\n",
        "    return w\n",
        "\n",
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, root_dir: str, train_mode: bool):\n",
        "        self.root = Path(root_dir)\n",
        "        self.train_mode = train_mode\n",
        "        self.samples = []\n",
        "        for cls in (\"real\", \"fake\"):\n",
        "            base = self.root / cls\n",
        "            if not base.exists(): continue\n",
        "            for p in base.rglob(\"*.wav\"):\n",
        "                self.samples.append((p, LABELS[cls]))\n",
        "        if len(self.samples) == 0:\n",
        "            raise ValueError(f\"No .wav files under {root_dir}\")\n",
        "\n",
        "    def __len__(self): return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.samples[idx]\n",
        "        w, sr = torchaudio.load(str(path))\n",
        "        w = _ensure_mono(w)\n",
        "        if sr != TARGET_SR:\n",
        "            w = torchaudio.functional.resample(w, sr, TARGET_SR)\n",
        "            sr = TARGET_SR\n",
        "\n",
        "        w = _remove_dc(w)\n",
        "\n",
        "        if self.train_mode:\n",
        "            w = _random_crop(w, TARGET_LEN)\n",
        "            w = _time_shift(w)\n",
        "            if np.random.rand() < 0.5:\n",
        "                w = _resample_jitter(w, sr, RS_JITTER)\n",
        "            if np.random.rand() < CODEC_P:\n",
        "                w = _codec_roundtrip(w, sr, BITRATE)\n",
        "            # very gentle spectral tilt\n",
        "            if np.random.rand() < 0.5:\n",
        "                w = _shelf_tilt(w, sr, EQ_DB)\n",
        "            w = _amp_jitter(w)\n",
        "            w = _add_noise(w)\n",
        "        else:\n",
        "            w = _center_crop(w, TARGET_LEN)\n",
        "\n",
        "        w = _fade_edges(w, sr)\n",
        "        w = _zscore(w)\n",
        "\n",
        "        return w.squeeze(0), label\n"
      ],
      "metadata": {
        "id": "2tlk-k-VUivN"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KfMrNLgbP-x",
        "outputId": "4f00a7e2-049c-4862-e622-852d62e34a4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Dimension D inferred: 1024\n"
          ]
        }
      ],
      "source": [
        "# üõ†Ô∏è CHECKPOINT SETUP\n",
        "CHECKPOINT_PATH = \"/content/best_clad_model.pth\"\n",
        "best_val_acc = 0.0\n",
        "\n",
        "#1 =========================================================\n",
        "# Full End-to-End Fine-tuning of RawNet Encoder + Classifier\n",
        "# (Training from Scratch since checkpoint is incompatible)\n",
        "# =========================================================\n",
        "from pathlib import Path\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchaudio\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Change directory to CLAD to import modules\n",
        "os.chdir('/content/CLAD')\n",
        "\n",
        "# We only need the RawNet Encoder for classification.\n",
        "from Model import RawNetEncoderBaseline # Keep only the encoder import\n",
        "\n",
        "# --- ARCHITECTURE CONFIG (Matching the incompatible checkpoint's width) ---\n",
        "# This configuration is used for the RawNet model architecture.\n",
        "d_args = {\n",
        "    \"in_channels\": 1,\n",
        "    \"first_conv\": 251,\n",
        "    \"filts\": [\n",
        "        32,           # Narrower filter set to align with common RawNet variants\n",
        "        [32, 32],\n",
        "        [32, 64],\n",
        "        [64, 64]\n",
        "    ],\n",
        "    \"nb_fc_node\": 1024,\n",
        "    \"gru_node\": 1024,\n",
        "    \"nb_gru_layer\": 3,\n",
        "    \"nb_classes\": 2\n",
        "}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# --- MODEL INSTANTIATION ---\n",
        "# 1. Create a single RawNet encoder (no MoCo wrapper needed for classification)\n",
        "encoder = RawNetEncoderBaseline(d_args, device)\n",
        "encoder.to(device)\n",
        "\n",
        "# üõë NO CHECKPOINT LOADING: We are training from random initialization.\n",
        "\n",
        "# -------- Hyperparameters --------\n",
        "TARGET_SR  = 16000\n",
        "TARGET_LEN = 64600\n",
        "LABELS     = {\"real\": 0, \"fake\": 1}\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS     = 15 # Increased epochs slightly for training from scratch\n",
        "LR         = 5e-5 # Low learning rate for complex architecture training\n",
        "# ---------------------------------\n",
        "\n",
        "# -------- Dataset (No change to class definition is needed) --------\n",
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, root_dir: str):\n",
        "        self.samples = []\n",
        "        root = Path(root_dir)\n",
        "        for cls in (\"real\", \"fake\"):\n",
        "            base = root / cls\n",
        "            if not base.exists():\n",
        "                # Removed the raise to allow running if a folder is empty,\n",
        "                # though it should exist after split cell 17.\n",
        "                continue\n",
        "            for p in base.rglob(\"*.wav\"):\n",
        "                if p.is_file():\n",
        "                    self.samples.append((p, LABELS[cls]))\n",
        "        if len(self.samples) == 0:\n",
        "            raise ValueError(f\"No .wav files found under {root_dir}.\")\n",
        "        self._resamplers = {}\n",
        "\n",
        "    def __len__(self): return len(self.samples)\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.samples[idx]\n",
        "        # Since audio is preprocessed to 16kHz/64600 in cell 19,\n",
        "        # we can simplify this function to rely on that.\n",
        "        wav, sr = torchaudio.load(str(path)) # [C, T]\n",
        "        return wav.squeeze(0), label         # -> [T], label\n",
        "\n",
        "# -------- DataLoaders --------\n",
        "train_ds = AudioDataset(\"/content/my_audio_equalized_lufs/train\")\n",
        "val_ds   = AudioDataset(\"/content/my_audio_equalized_lufs/val\")\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
        "\n",
        "\n",
        "# --- Infer feature dimension D and define Classifier ---\n",
        "# Inference on one batch to set classifier dimension\n",
        "with torch.no_grad():\n",
        "    wavs0, _ = next(iter(train_loader))     # wavs0: [B, T]\n",
        "    x0 = wavs0.to(device).float()           # [B, T]\n",
        "    feat0 = encoder(x0)                     # RawNetEncoderBaseline(d_args) expects [B, T]\n",
        "\n",
        "    # Pool any extra time/freq dims\n",
        "    if feat0.dim() == 3:\n",
        "        feat0 = feat0.mean(dim=2)            # pool time -> [B, D]\n",
        "    elif feat0.dim() > 3:\n",
        "        feat0 = feat0.mean(dim=tuple(range(2, feat0.dim())))\n",
        "    D = feat0.shape[1] # D should be 1024\n",
        "\n",
        "print(f\"Feature Dimension D inferred: {D}\")\n",
        "# -----------------------------------------------------\n",
        "\n",
        "# -------- Classifier, Loss, Optimizer (Optimizing the whole system) --------\n",
        "classifier = nn.Sequential(\n",
        "    nn.Linear(D, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(64, 2)\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# üõë Optimize BOTH encoder and classifier\n",
        "optimizer = torch.optim.AdamW(\n",
        "    list(encoder.parameters()) + list(classifier.parameters()),\n",
        "    lr=LR,\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "\n",
        "# üõ†Ô∏è MISSING/FIXED: Define the Learning Rate Scheduler\n",
        "# T_max is the total number of updates (epochs * steps_per_epoch)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS * len(train_loader))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple-features baseline (RMS, ZCR, spectral rolloff)\n",
        "import numpy as np, librosa\n",
        "from pathlib import Path\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "\n",
        "def simple_feats(w, sr=16000):\n",
        "    rms  = np.mean(librosa.feature.rms(y=w, frame_length=512, hop_length=256))\n",
        "    zcr  = np.mean(librosa.feature.zero_crossing_rate(y=w))\n",
        "    S    = np.abs(librosa.stft(w, n_fft=512, hop_length=256))\n",
        "    roll = np.mean(librosa.feature.spectral_rolloff(S=S, sr=sr))\n",
        "    return np.array([rms, zcr, roll], dtype=np.float32)\n",
        "\n",
        "def load_xy(root):\n",
        "    X, y = [], []\n",
        "    for cls, lab in [(\"real\",0),(\"fake\",1)]:\n",
        "        for p in Path(root, cls).rglob(\"*.wav\"):\n",
        "            w, sr = librosa.load(p, sr=16000, mono=True)\n",
        "            X.append(simple_feats(w, sr)); y.append(lab)\n",
        "    return np.stack(X), np.array(y)\n",
        "\n",
        "Xtr, Ytr = load_xy(\"/content/my_audio_equalized/train\")\n",
        "Xva, Yva = load_xy(\"/content/my_audio_equalized/val\")\n",
        "\n",
        "clf = LogisticRegression(max_iter=200, class_weight=\"balanced\").fit(Xtr, Ytr)\n",
        "pva = clf.decision_function(Xva)\n",
        "print(\"Simple-features  Acc:\", accuracy_score(Yva, (pva>0)))\n",
        "print(\"Simple-features  AUC:\", roc_auc_score(Yva,  pva))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZ_g4Rjwba2e",
        "outputId": "1e4b0c21-bc7a-44c2-f23b-fd1f989e9d42"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simple-features  Acc: 0.8426966292134831\n",
            "Simple-features  AUC: 0.9589145941169044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# BENCHMARK (fits your setup: encoder -> embeddings, classifier -> logits)\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np, torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# sklearn (install if needed)\n",
        "try:\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.metrics import accuracy_score, roc_auc_score, average_precision_score, confusion_matrix\n",
        "except Exception:\n",
        "    !pip -q install scikit-learn\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.metrics import accuracy_score, roc_auc_score, average_precision_score, confusion_matrix\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# === Align with YOUR current labels ===\n",
        "CLASS_TO_ID = {'real': 0, 'fake': 1}\n",
        "REAL_CLASS_ID = CLASS_TO_ID['real']  # positive=real (0) in your mapping\n",
        "\n",
        "# --- Guards ---\n",
        "assert 'train_loader' in globals() and 'val_loader' in globals(), \"Need train_loader and val_loader.\"\n",
        "assert 'encoder' in globals() and 'classifier' in globals(), \"Need encoder and classifier defined.\"\n",
        "\n",
        "ENC = encoder.eval()\n",
        "CLS = classifier.eval()\n",
        "\n",
        "def ensure_b1t(x: torch.Tensor) -> torch.Tensor:\n",
        "    return x.unsqueeze(1) if x.ndim == 2 else x\n",
        "\n",
        "@torch.no_grad()\n",
        "def forward_embeddings(xb: torch.Tensor) -> torch.Tensor:\n",
        "    xb = xb.to(DEVICE, non_blocking=True).float()\n",
        "    # Your encoder expects [B,T]; we also try [B,1,T] just in case\n",
        "    try:\n",
        "        z = ENC(xb)\n",
        "    except Exception:\n",
        "        z = ENC(ensure_b1t(xb))\n",
        "    if isinstance(z, (tuple, list)):\n",
        "        z = z[0]\n",
        "    z = torch.as_tensor(z)\n",
        "    # Pool any extra dims ‚Üí [B,D]\n",
        "    if z.ndim > 2:\n",
        "        z = z.mean(dim=tuple(range(2, z.ndim)))\n",
        "    return z.detach()\n",
        "\n",
        "@torch.no_grad()\n",
        "def forward_logits(xb: torch.Tensor) -> torch.Tensor:\n",
        "    z = forward_embeddings(xb)    # [B,D]\n",
        "    lg = CLS(z)                   # [B,2]\n",
        "    if lg.ndim > 2:\n",
        "        lg = lg.flatten(1)\n",
        "    return lg.detach()\n",
        "\n",
        "def collect_split_embeddings(loader):\n",
        "    Z, Y = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            if len(batch) == 2:\n",
        "                xb, yb = batch\n",
        "            else:\n",
        "                xb, yb, _ = batch\n",
        "            z = forward_embeddings(xb)\n",
        "            Z.append(z.cpu().numpy())\n",
        "            Y.append(yb.cpu().numpy())\n",
        "    Z = np.concatenate(Z, 0) if Z else np.zeros((0,0), dtype=np.float32)\n",
        "    Y = np.concatenate(Y, 0) if Y else np.zeros((0,), dtype=np.int64)\n",
        "    return Z, Y\n",
        "\n",
        "def collect_split_logits(loader):\n",
        "    LG, Y = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            if len(batch) == 2:\n",
        "                xb, yb = batch\n",
        "            else:\n",
        "                xb, yb, _ = batch\n",
        "            lg = forward_logits(xb)\n",
        "            LG.append(lg.cpu().numpy())\n",
        "            Y.append(yb.cpu().numpy())\n",
        "    LG = np.concatenate(LG, 0) if LG else np.zeros((0,2), dtype=np.float32)\n",
        "    Y  = np.concatenate(Y, 0)  if Y  else np.zeros((0,), dtype=np.int64)\n",
        "    return LG, Y\n",
        "\n",
        "def metrics_from_logits(LG: np.ndarray, y_true: np.ndarray):\n",
        "    probs = torch.softmax(torch.tensor(LG), dim=1).numpy()\n",
        "    y_pred = probs.argmax(axis=1)\n",
        "    acc = float(accuracy_score(y_true, y_pred)) if len(y_true) else float('nan')\n",
        "\n",
        "    # We treat REAL as positive here to match REAL_CLASS_ID (which is 0 right now)\n",
        "    pos = REAL_CLASS_ID\n",
        "    try:\n",
        "        auc  = float(roc_auc_score((y_true == pos), probs[:, pos])) if len(y_true) else float('nan')\n",
        "    except Exception:\n",
        "        auc = float('nan')\n",
        "    try:\n",
        "        aupr = float(average_precision_score((y_true == pos), probs[:, pos])) if len(y_true) else float('nan')\n",
        "    except Exception:\n",
        "        aupr = float('nan')\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[CLASS_TO_ID['real'], CLASS_TO_ID['fake']]) if len(y_true) else np.zeros((2,2), dtype=int)\n",
        "    return acc, auc, aupr, cm, probs\n",
        "\n",
        "def print_metrics(title, acc, auc, aupr, cm, probs):\n",
        "    print(f\"\\n---- {title} ----\")\n",
        "    print(f\"Accuracy : {acc:.4f}\")\n",
        "    print(f\"ROC-AUC  : {auc:.4f}  (pos class = 'real' id={REAL_CLASS_ID})\")\n",
        "    print(f\"AUPRC    : {aupr:.4f}\")\n",
        "    print(\"Confusion [rows=true: (real, fake); cols=pred]:\")\n",
        "    print(cm)\n",
        "    if probs.size:\n",
        "        p_pos = probs[:, REAL_CLASS_ID]\n",
        "        print(f\"P(pos=real): mean={p_pos.mean():.3f} std={p_pos.std():.3f} min={p_pos.min():.3f} max={p_pos.max():.3f}\")\n",
        "        hi = (p_pos > 0.99).mean(); lo = (p_pos < 0.01).mean()\n",
        "        if hi > 0.5 or lo > 0.5:\n",
        "            print(\"‚ö†Ô∏è  Very peaky probabilities ‚Üí possible shortcut/signature leakage.\")\n",
        "\n",
        "print(\"=== BENCHMARK: Linear Probe on encoder embeddings ===\")\n",
        "Ztr, Ytr = collect_split_embeddings(train_loader)\n",
        "Zva, Yva = collect_split_embeddings(val_loader)\n",
        "print(f\"shapes: Ztr={Ztr.shape}, Zva={Zva.shape}\")\n",
        "\n",
        "if Ztr.size and Zva.size:\n",
        "    clf = LogisticRegression(max_iter=200, n_jobs=1, class_weight=\"balanced\")\n",
        "    clf.fit(Ztr, Ytr)\n",
        "    d_val = clf.decision_function(Zva)              # [N] for binary\n",
        "    LG_val = np.stack([-d_val, d_val], axis=1) if d_val.ndim == 1 else d_val\n",
        "    acc, auc, aupr, cm, probs = metrics_from_logits(LG_val, Yva)\n",
        "    print_metrics(\"VAL (Linear Probe)\", acc, auc, aupr, cm, probs)\n",
        "\n",
        "    d_tr = clf.decision_function(Ztr)\n",
        "    LG_tr = np.stack([-d_tr, d_tr], axis=1) if d_tr.ndim == 1 else d_tr\n",
        "    acc_tr, auc_tr, aupr_tr, cm_tr, probs_tr = metrics_from_logits(LG_tr, Ytr)\n",
        "    print_metrics(\"TRAIN (Linear Probe)\", acc_tr, auc_tr, aupr_tr, cm_tr, probs_tr)\n",
        "else:\n",
        "    print(\"Empty embeddings ‚Äî check loaders or encoder forward.\")\n",
        "\n",
        "print(\"\\n=== BENCHMARK: Direct logits via classifier ===\")\n",
        "LG_tr, Y_tr = collect_split_logits(train_loader)\n",
        "LG_va, Y_va = collect_split_logits(val_loader)\n",
        "if LG_va.size:\n",
        "    acc, auc, aupr, cm, probs = metrics_from_logits(LG_va, Y_va)\n",
        "    print_metrics(\"VAL (Direct logits)\", acc, auc, aupr, cm, probs)\n",
        "else:\n",
        "    print(\"Empty logits on val ‚Äî check classifier forward.\")\n",
        "\n",
        "print(\"\\n[Benchmark] Done.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF6AJiRyK6ak",
        "outputId": "44de54d9-eafb-4c93-fbf8-db19b8a84807"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== BENCHMARK: Linear Probe on encoder embeddings ===\n",
            "shapes: Ztr=(1216, 1024), Zva=(712, 1024)\n",
            "\n",
            "---- VAL (Linear Probe) ----\n",
            "Accuracy : 0.9663\n",
            "ROC-AUC  : 0.9982  (pos class = 'real' id=0)\n",
            "AUPRC    : 0.9983\n",
            "Confusion [rows=true: (real, fake); cols=pred]:\n",
            "[[332  24]\n",
            " [  0 356]]\n",
            "P(pos=real): mean=0.468 std=0.496 min=0.000 max=1.000\n",
            "‚ö†Ô∏è  Very peaky probabilities ‚Üí possible shortcut/signature leakage.\n",
            "\n",
            "---- TRAIN (Linear Probe) ----\n",
            "Accuracy : 0.9992\n",
            "ROC-AUC  : 0.9997  (pos class = 'real' id=0)\n",
            "AUPRC    : 0.9997\n",
            "Confusion [rows=true: (real, fake); cols=pred]:\n",
            "[[610   0]\n",
            " [  1 605]]\n",
            "P(pos=real): mean=0.502 std=0.500 min=0.000 max=1.000\n",
            "\n",
            "=== BENCHMARK: Direct logits via classifier ===\n",
            "\n",
            "---- VAL (Direct logits) ----\n",
            "Accuracy : 0.9719\n",
            "ROC-AUC  : 0.9983  (pos class = 'real' id=0)\n",
            "AUPRC    : 0.9984\n",
            "Confusion [rows=true: (real, fake); cols=pred]:\n",
            "[[337  19]\n",
            " [  1 355]]\n",
            "P(pos=real): mean=0.469 std=0.490 min=0.000 max=1.000\n",
            "\n",
            "[Benchmark] Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- Train + Validate --------\n",
        "print(f\"Starting End-to-End Training (Encoder + Classifier) for {EPOCHS} epochs.\")\n",
        "\n",
        "# A simple loop for demonstration (removed the single-batch overfit check to clean up)\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    # ---- Train ----\n",
        "    encoder.train()\n",
        "    classifier.train()\n",
        "    tr_loss = tr_correct = tr_total = 0.0\n",
        "\n",
        "    for wavs, labels in train_loader:\n",
        "        x = wavs.to(device).float()          # [B, T]\n",
        "        y = labels.to(device).long()         # 0=real, 1=fake\n",
        "\n",
        "        # Encoder forward (WITH grad)\n",
        "        f = encoder(x) # (B, D) or (B, D, T, ...)\n",
        "        if f.dim() == 3:\n",
        "            f = f.mean(dim=2)            # pool time -> (B, D)\n",
        "        elif f.dim() > 3:\n",
        "            f = f.mean(dim=tuple(range(2, f.dim())))\n",
        "\n",
        "        # Head forward\n",
        "        logits = classifier(f)\n",
        "        loss = criterion(logits, y)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        tr_loss   += loss.item() * x.size(0)\n",
        "        tr_correct += (logits.argmax(dim=1) == y).sum().item()\n",
        "        tr_total  += x.size(0)\n",
        "\n",
        "   # ---- Val ----\n",
        "    classifier.eval()\n",
        "    encoder.eval() # Ensure encoder is also in eval mode\n",
        "    va_loss, va_correct, va_total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "      # ... (Existing validation loop to calculate va_loss and va_correct/va_total) ...\n",
        "      for wavs, labels in val_loader:\n",
        "          x = wavs.to(device).float()\n",
        "          y = labels.to(device).long()\n",
        "\n",
        "          f = encoder(x)\n",
        "          if f.dim() == 3:\n",
        "              f = f.mean(dim=2)\n",
        "          elif f.dim() > 3:\n",
        "              f = f.mean(dim=tuple(range(2, f.dim())))\n",
        "\n",
        "          logits = classifier(f)\n",
        "          va_loss   += criterion(logits, y).item() * x.size(0)\n",
        "          va_correct += (logits.argmax(dim=1) == y).sum().item()\n",
        "          va_total  += x.size(0)\n",
        "\n",
        "    current_val_acc = va_correct / va_total\n",
        "\n",
        "    print(f\"Epoch {epoch}/{EPOCHS} | \"\n",
        "          f\"Train Loss: {tr_loss/tr_total:.4f}, Acc: {tr_correct/tr_total:.3f} | \"\n",
        "          f\"Val Loss: {va_loss/va_total:.4f}, Acc: {current_val_acc:.3f}\")\n",
        "\n",
        "    # üõ†Ô∏è CHECKPOINTING / EARLY STOPPING LOGIC\n",
        "    global best_val_acc\n",
        "\n",
        "    if current_val_acc > best_val_acc:\n",
        "        print(f\"  --> New best model found (Acc: {current_val_acc:.4f}). Saving checkpoint to {CHECKPOINT_PATH}\")\n",
        "        best_val_acc = current_val_acc\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'encoder_state_dict': encoder.state_dict(),\n",
        "            'classifier_state_dict': classifier.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'best_val_acc': best_val_acc,\n",
        "        }, CHECKPOINT_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nd34nl7K1zF",
        "outputId": "4b7f33ae-6d6a-4a39-af15-f5ba15229ca3"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting End-to-End Training (Encoder + Classifier) for 15 epochs.\n",
            "Epoch 1/15 | Train Loss: 0.4121, Acc: 0.767 | Val Loss: 3.1905, Acc: 0.500\n",
            "  --> New best model found (Acc: 0.5000). Saving checkpoint to /content/best_clad_model.pth\n",
            "Epoch 2/15 | Train Loss: 0.0817, Acc: 0.978 | Val Loss: 0.0827, Acc: 0.971\n",
            "  --> New best model found (Acc: 0.9705). Saving checkpoint to /content/best_clad_model.pth\n",
            "Epoch 3/15 | Train Loss: 0.0776, Acc: 0.975 | Val Loss: 0.0524, Acc: 0.985\n",
            "  --> New best model found (Acc: 0.9846). Saving checkpoint to /content/best_clad_model.pth\n",
            "Epoch 4/15 | Train Loss: 0.0592, Acc: 0.984 | Val Loss: 0.2449, Acc: 0.923\n",
            "Epoch 5/15 | Train Loss: 0.0576, Acc: 0.982 | Val Loss: 0.3006, Acc: 0.912\n",
            "Epoch 6/15 | Train Loss: 0.0293, Acc: 0.994 | Val Loss: 0.0626, Acc: 0.985\n",
            "Epoch 7/15 | Train Loss: 0.0274, Acc: 0.994 | Val Loss: 0.2412, Acc: 0.945\n",
            "Epoch 8/15 | Train Loss: 0.0336, Acc: 0.992 | Val Loss: 0.0668, Acc: 0.979\n",
            "Epoch 9/15 | Train Loss: 0.0192, Acc: 0.995 | Val Loss: 0.1226, Acc: 0.968\n",
            "Epoch 10/15 | Train Loss: 0.0247, Acc: 0.992 | Val Loss: 0.0937, Acc: 0.973\n",
            "Epoch 11/15 | Train Loss: 0.0156, Acc: 0.998 | Val Loss: 0.0821, Acc: 0.979\n",
            "Epoch 12/15 | Train Loss: 0.0182, Acc: 0.996 | Val Loss: 0.1530, Acc: 0.965\n",
            "Epoch 13/15 | Train Loss: 0.0152, Acc: 0.998 | Val Loss: 0.1287, Acc: 0.969\n",
            "Epoch 14/15 | Train Loss: 0.0128, Acc: 0.998 | Val Loss: 0.1124, Acc: 0.972\n",
            "Epoch 15/15 | Train Loss: 0.0150, Acc: 0.996 | Val Loss: 0.1223, Acc: 0.972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYNs_SB4L1b1",
        "outputId": "ee608da4-47c4-42ed-aa23-7ade81d386c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading best checkpoint from: /content/best_clad_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1531994329.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Successfully loaded model from Epoch 3 (Best Val Acc: 0.9846)\n"
          ]
        }
      ],
      "source": [
        "# ===============================================\n",
        "# üîÑ Load Best Model State from Checkpoint\n",
        "# ===============================================\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "CHECKPOINT_PATH = \"/content/best_clad_model.pth\"\n",
        "\n",
        "if Path(CHECKPOINT_PATH).exists():\n",
        "    print(f\"Loading best checkpoint from: {CHECKPOINT_PATH}\")\n",
        "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
        "\n",
        "    # Load state dictionaries into the previously defined models\n",
        "    encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
        "    classifier.load_state_dict(checkpoint['classifier_state_dict'])\n",
        "\n",
        "    # Restore optimizer state if needed for continued training (optional here)\n",
        "    # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "    print(f\"‚úÖ Successfully loaded model from Epoch {checkpoint['epoch']} (Best Val Acc: {checkpoint['best_val_acc']:.4f})\")\n",
        "\n",
        "    # Set models to evaluation mode before proceeding\n",
        "    encoder.eval()\n",
        "    classifier.eval()\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Checkpoint file not found. Proceeding with the final state of the training run.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjMcDM3hbTXb",
        "outputId": "a6d32824-3a1e-4534-b73f-911e2381c8ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== VAL RESULTS ===\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        real     1.0000    0.9691    0.9843       356\n",
            "        fake     0.9700    1.0000    0.9848       356\n",
            "\n",
            "    accuracy                         0.9846       712\n",
            "   macro avg     0.9850    0.9846    0.9845       712\n",
            "weighted avg     0.9850    0.9846    0.9845       712\n",
            "\n",
            "\n",
            "=== TEST RESULTS ===\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        real     0.7787    1.0000    0.8756       366\n",
            "        fake     1.0000    0.7158    0.8344       366\n",
            "\n",
            "    accuracy                         0.8579       732\n",
            "   macro avg     0.8894    0.8579    0.8550       732\n",
            "weighted avg     0.8894    0.8579    0.8550       732\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#2 =========================================\n",
        "# Evaluate model on validation/test sets\n",
        "# =========================================\n",
        "from sklearn.metrics import classification_report\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from torch.utils.data import DataLoader\n",
        "# Assuming AudioDataset is defined and model/classifier are trained from cell 21\n",
        "\n",
        "def evaluate(loader, split_name=\"val\", encoder=None, classifier=None, device=None):\n",
        "    if encoder is None or classifier is None or device is None:\n",
        "        raise ValueError(\"encoder, classifier, and device must be provided to evaluate function.\")\n",
        "\n",
        "    encoder.to(device).eval()\n",
        "    classifier.to(device).eval()\n",
        "\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for wavs, labels in loader:\n",
        "            wavs, labels = wavs.to(device).float(), labels.to(device).long()\n",
        "\n",
        "            # Use the single encoder\n",
        "            feats = encoder(wavs)\n",
        "            # Pool any extra time/freq dims so we have (B,D)\n",
        "            if feats.dim() == 3:\n",
        "                feats = feats.mean(dim=2)\n",
        "            elif feats.dim() > 3:\n",
        "                feats = feats.mean(dim=tuple(range(2, feats.dim())))\n",
        "\n",
        "            preds = classifier(feats)\n",
        "            all_preds.extend(torch.argmax(preds, dim=1).cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    print(f\"\\n=== {split_name.upper()} RESULTS ===\\n\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=[\"real\",\"fake\"], digits=4))\n",
        "\n",
        "# Define the test loader (ensure AudioDataset is defined in cell 21)\n",
        "test_ds = AudioDataset(\"/content/my_audio_split/test\")\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Run evaluation on Validation and Test sets\n",
        "evaluate(val_loader, \"val\", encoder=encoder, classifier=classifier, device=device)\n",
        "evaluate(test_loader, \"test\", encoder=encoder, classifier=classifier, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvNxJXpebWE5",
        "outputId": "8f810b91-0983-4710-95ae-1fa7497b5333"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1342 real and 1342 fake WAVs.\n",
            "Saved CSV: /content/my_audio_results/clad_results.csv\n"
          ]
        }
      ],
      "source": [
        "#13 =========================================\n",
        "# Prediction and Embedding Extraction\n",
        "# =========================================\n",
        "import torch\n",
        "from pathlib import Path\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'encoder', 'classifier', and 'device' are defined and trained\n",
        "if 'encoder' not in globals() or 'classifier' not in globals() or 'device' not in globals():\n",
        "     raise RuntimeError(\"Encoder, classifier, or device not found. Please run the training cells first.\")\n",
        "\n",
        "# Ensure encoder and classifier are on the correct device and in eval mode\n",
        "encoder.to(device).eval()\n",
        "classifier.to(device).eval()\n",
        "\n",
        "TARGET_SR  = 16000\n",
        "TARGET_LEN = 64600\n",
        "\n",
        "# Function to load audio as 16k mono and preprocess\n",
        "def load_and_preprocess_audio(path: Path):\n",
        "    \"\"\"Load an audio file, resample to 16kHz mono, pad/trim to TARGET_LEN.\"\"\"\n",
        "    # Since audio files are already preprocessed in cell 19, we load directly\n",
        "    wav, sr = torchaudio.load(str(path))   # [C,T]\n",
        "    return wav.squeeze(0) # -> [T]\n",
        "\n",
        "# Function to run prediction\n",
        "def predict_file(path: Path, encoder, classifier, device):\n",
        "    \"\"\"Run encoder + classifier on one WAV file. Returns (pred_label, fake_conf, real_conf, embedding).\"\"\"\n",
        "    try:\n",
        "        wav = load_and_preprocess_audio(path) # [T]\n",
        "        x = wav.unsqueeze(0).to(device).float()       # [B=1, T]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            feats = encoder(x) # RawNet expects [B, T]\n",
        "\n",
        "            # Pool any extra time/freq dims if necessary\n",
        "            if feats.dim() == 3:\n",
        "                feats = feats.mean(dim=2)\n",
        "            elif feats.dim() > 3:\n",
        "                 feats = feats.mean(dim=tuple(range(2, feats.dim())))\n",
        "\n",
        "            # Pass features through the classifier\n",
        "            logits = classifier(feats)        # [B=1, 2]\n",
        "            probs  = F.softmax(logits, dim=1)[0].detach().cpu().numpy()\n",
        "\n",
        "        label = \"fake\" if int(np.argmax(probs)) == 1 else \"real\"\n",
        "        fake_conf = float(probs[1])\n",
        "        real_conf = float(probs[0])\n",
        "        # Return the embedding from the encoder (for t-SNE)\n",
        "        return label, fake_conf, real_conf, feats.squeeze(0).cpu().numpy()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {path}: {e}\")\n",
        "        return \"error\", 0.0, 0.0, None # Return None for embedding on error\n",
        "\n",
        "\n",
        "REAL_DIR = Path(\"/content/my_audio/real\")\n",
        "FAKE_DIR = Path(\"/content/my_audio/fake\")\n",
        "OUT_DIR  = Path(\"/content/my_audio_results\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "real_files = sorted(REAL_DIR.rglob(\"*.wav\"))\n",
        "fake_files = sorted(FAKE_DIR.rglob(\"*.wav\"))\n",
        "\n",
        "print(f\"Found {len(real_files)} real and {len(fake_files)} fake WAVs.\")\n",
        "\n",
        "rows = []\n",
        "all_embeddings = [] # List to collect embeddings for t-SNE\n",
        "\n",
        "for f in real_files + fake_files:\n",
        "    p = Path(f)\n",
        "    pred, fake_conf, real_conf, emb = predict_file(p, encoder, classifier, device)\n",
        "\n",
        "    if emb is not None:\n",
        "        all_embeddings.append(emb)\n",
        "        emb_list = emb.tolist()\n",
        "        emb_dim = len(emb)\n",
        "    else:\n",
        "        emb_list = None\n",
        "        emb_dim = None\n",
        "\n",
        "    rows.append({\n",
        "        \"file\": str(p),\n",
        "        \"pred\": pred,\n",
        "        \"fake_conf\": fake_conf,\n",
        "        \"real_conf\": real_conf,\n",
        "        \"embedding_dim\": emb_dim,\n",
        "        \"embedding\": emb_list\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "csv_path = OUT_DIR / \"clad_results.csv\"\n",
        "df.to_csv(csv_path, index=False)\n",
        "print(\"Saved CSV:\", csv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "XS7d1xz3bYOt",
        "outputId": "7a44bb78-9df0-46fc-c427-519625f900dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running t-SNE with perplexity=30...\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#14 =========================================\n",
        "# t-SNE Visualization of Embeddings\n",
        "# =========================================\n",
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# The 'rows' list is assumed to be available from the previous cell's execution\n",
        "emb_rows = [r for r in rows if r[\"embedding\"] is not None]\n",
        "\n",
        "if len(emb_rows) >= 2:\n",
        "    # Separate embeddings and predicted labels\n",
        "    X = np.vstack([np.array(r[\"embedding\"], dtype=np.float32) for r in emb_rows])\n",
        "    y = np.array([r[\"pred\"] for r in emb_rows])\n",
        "\n",
        "    # Run t-SNE\n",
        "    # Perplexity should be < N_samples.\n",
        "    # Use 15 for your small dataset of ~2700 total samples (real+fake).\n",
        "    perp = min(30, len(emb_rows)-1)\n",
        "    print(f\"Running t-SNE with perplexity={perp}...\")\n",
        "\n",
        "    # Trigger image generation for better visualization\n",
        "\n",
        "    X2d = TSNE(n_components=2, random_state=0, perplexity=perp, init='random', learning_rate='auto').fit_transform(X)\n",
        "\n",
        "    plt.figure(figsize=(6,5))\n",
        "    for cls, marker, color in [(\"real\", \"o\", \"blue\"), (\"fake\", \"x\", \"red\")]:\n",
        "        mask = (y == cls)\n",
        "        plt.scatter(X2d[mask,0], X2d[mask,1], label=cls, marker=marker, alpha=0.85, color=color)\n",
        "\n",
        "    plt.title(\"CLAD Embeddings (t-SNE) - Classification by Model\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No embeddings available (encoder not exposed or too few samples).\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "cell_execution_strategy": "setup",
      "collapsed_sections": [
        "dcjKFlnIKvFL",
        "pcyj99GfwB5q",
        "3E1vvwTD_QXm"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}