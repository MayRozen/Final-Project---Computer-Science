{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "cell_execution_strategy": "setup"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNnA0Nxx4ghf"
      },
      "source": [
        "# Project Setup (Colab)\n",
        "\n",
        "Run these cells from top to bottom to build a stable, reproducible environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWi7MCSN4ghg"
      },
      "source": [
        "# ======================================\n",
        "# ğŸ”§ INSTALL DEPENDENCIES (run once, then restart kernel if prompted)\n",
        "# ======================================\n",
        "#%%capture\n",
        "#%pip install -q --force-reinstall     numpy==1.26.4     scipy==1.13.1     torch==2.4.1     torchaudio==2.4.1     coqui-tts==0.23.1     pandas==2.2.3     matplotlib==3.9.2     scikit-learn==1.5.2     tqdm==4.66.5\n",
        "\n",
        "# After running this cell, restart the runtime by going to \"Runtime\" -> \"Restart session\" in the Colab menu."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip uninstall -y numpy pandas scipy\n",
        "#!pip install --no-cache-dir --force-reinstall numpy==1.26.4 pandas==2.2.3 scipy==1.13.1"
      ],
      "metadata": {
        "id": "u757FgZcRLNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd, scipy\n",
        "print(\"NumPy:\", np.__version__)\n",
        "print(\"Pandas:\", pd.__version__)\n",
        "print(\"SciPy:\", scipy.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EKv6MvQQEKT",
        "outputId": "045f1169-0774-4df9-af40-3385e1b10552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy: 1.26.4\n",
            "Pandas: 2.2.3\n",
            "SciPy: 1.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbjc4yul4ghh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "694267f2-f59a-4cc0-de17-db1d46a64da8"
      },
      "source": [
        "# ======================================\n",
        "# ğŸ“¦ IMPORT LIBRARIES\n",
        "# ======================================\n",
        "import os, sys, glob, random, shutil, csv, itertools, threading, platform, importlib\n",
        "from pathlib import Path\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from collections import defaultdict\n",
        "\n",
        "# Core scientific stack\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Machine learning / audio\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Coqui Text-to-Speech\n",
        "from TTS.api import TTS\n",
        "\n",
        "%matplotlib inline\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'TTS'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2134805449.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Coqui Text-to-Speech\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mTTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'TTS'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4lUUUhj4ghh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d71265bc-2959-4932-a21c-9a801ee597a3"
      },
      "source": [
        "# ======================================\n",
        "# ğŸ¯ REPRODUCIBILITY (Seed everything)\n",
        "# ======================================\n",
        "import random\n",
        "import numpy as _np\n",
        "import torch as _torch\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "_np.random.seed(SEED)\n",
        "_torch.manual_seed(SEED)\n",
        "if _torch.cuda.is_available():\n",
        "    _torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "print(f\"Seed set to {SEED}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set to 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vS6XSpNd4ghh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8955b2e6-75ad-4c24-ab7b-1a2e41e1a65a"
      },
      "source": [
        "# ======================================\n",
        "# âœ… ENVIRONMENT CHECK\n",
        "# ======================================\n",
        "import platform\n",
        "print(\"Environment is ready!\")\n",
        "print(f\"Python: {platform.python_version()}\")\n",
        "print(f\"NumPy: {np.__version__} | SciPy: {scipy.__version__}\")\n",
        "print(f\"Torch: {torch.__version__} | Torchaudio: {torchaudio.__version__}\")\n",
        "print(f\"Pandas: {pd.__version__}\")\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA device:\", torch.cuda.get_device_name(0))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment is ready!\n",
            "Python: 3.12.12\n",
            "NumPy: 1.26.4 | SciPy: 1.13.1\n",
            "Torch: 2.8.0+cu126 | Torchaudio: 2.8.0+cu126\n",
            "Pandas: 2.2.3\n",
            "CUDA available: True\n",
            "CUDA device: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwvECPac4ghi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13a732e1-9916-4fc8-e508-18fe1a3930d0"
      },
      "source": [
        "# ======================================\n",
        "# ğŸ§Š FREEZE ENVIRONMENT (lock file + system info)\n",
        "# ======================================\n",
        "import os, json, platform\n",
        "import numpy as _numpy\n",
        "import scipy as _scipy\n",
        "import torch as _torch\n",
        "import pandas as _pandas\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "LOCK_TXT = \"/content/requirements_lock.txt\"\n",
        "LOCK_JSON = \"/content/env_lock.json\"\n",
        "\n",
        "# Freeze exact package versions\n",
        "!pip freeze > \"$LOCK_TXT\"\n",
        "\n",
        "# Save system info + core libs versions\n",
        "env_info = {\n",
        "    \"python\": platform.python_version(),\n",
        "    \"platform\": platform.platform(),\n",
        "    \"cuda_available\": _torch.cuda.is_available(),\n",
        "    \"cuda_device\": (_torch.cuda.get_device_name(0) if _torch.cuda.is_available() else None),\n",
        "    \"versions\": {\n",
        "        \"numpy\": _numpy.__version__,\n",
        "        \"scipy\": _scipy.__version__,\n",
        "        \"torch\": _torch.__version__,\n",
        "        \"pandas\": _pandas.__version__,\n",
        "    }\n",
        "}\n",
        "with open(LOCK_JSON, \"w\") as f:\n",
        "    json.dump(env_info, f, indent=2)\n",
        "\n",
        "print(f\"Saved lockfile to: {LOCK_TXT}\")\n",
        "print(f\"Saved environment info to: {LOCK_JSON}\")\n",
        "\n",
        "# If Drive is mounted, also copy there for persistence\n",
        "drive_base = \"/content/drive/MyDrive/ColabEnvLocks\"\n",
        "if os.path.exists(\"/content/drive\"):\n",
        "    os.makedirs(drive_base, exist_ok=True)\n",
        "    !cp -f \"$LOCK_TXT\" \"$drive_base/requirements_lock.txt\"\n",
        "    !cp -f \"$LOCK_JSON\" \"$drive_base/env_lock.json\"\n",
        "    print(f\"Also copied to Drive: {drive_base}\")\n",
        "else:\n",
        "    print(\"Google Drive is not mounted; skipping Drive backup.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Saved lockfile to: /content/requirements_lock.txt\n",
            "Saved environment info to: /content/env_lock.json\n",
            "Also copied to Drive: /content/drive/MyDrive/ColabEnvLocks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "429b28a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16dd59fb-311c-4394-b057-d276da624083",
        "collapsed": true
      },
      "source": [
        "!pip install coqui-tts==0.23.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting coqui-tts==0.23.1\n",
            "  Downloading coqui_tts-0.23.1-cp312-cp312-manylinux1_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from coqui-tts==0.23.1) (1.26.4)\n",
            "Requirement already satisfied: cython>=0.29.30 in /usr/local/lib/python3.12/dist-packages (from coqui-tts==0.23.1) (3.0.12)\n",
            "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.12/dist-packages (from coqui-tts==0.23.1) (1.13.1)\n",
            "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.12/dist-packages (from coqui-tts==0.23.1) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (from coqui-tts==0.23.1) (2.8.0+cu126)\n",
            "Requirement already satisfied: soundfile>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from coqui-tts==0.23.1) (0.13.1)\n",
            "Requirement already satisfied: librosa>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from coqui-tts==0.23.1) (0.11.0)\n",
            "Requirement already satisfied: inflect>=5.6.0 in /usr/local/lib/python3.12/dist-packages (from coqui-tts==0.23.1) (7.5.0)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.12/dist-packages (from coqui-tts==0.23.1) (4.67.1)\n",
            "Collecting anyascii>=0.3.0 (from coqui-tts==0.23.1)\n",
            "  Downloading anyascii-0.3.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.12/dist-packages (from coqui-tts==0.23.1) (6.0.3)\n",
            "Requirement already satisfied: fsspec>=2023.6.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2023.6.0->coqui-tts==0.23.1) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.12/dist-packages (from coqui-tts==0.23.1) (25.0)\n",
            "Collecting pysbd>=0.3.4 (from coqui-tts==0.23.1)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: umap-learn>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from coqui-tts==0.23.1) (0.5.9.post2)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from coqui-tts==0.23.1) (3.10.0)\n",
            "Collecting coqui-tts-trainer>=0.1 (from coqui-tts==0.23.1)\n",
            "  Downloading coqui_tts_trainer-0.3.1-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting coqpit>=0.0.16 (from coqui-tts==0.23.1)\n",
            "  Downloading coqpit-0.0.17-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.12/dist-packages (from coqui-tts==0.23.1) (0.42.1)\n",
            "Collecting pypinyin (from coqui-tts==0.23.1)\n",
            "  Downloading pypinyin-0.55.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting hangul-romanize (from coqui-tts==0.23.1)\n",
            "  Downloading hangul_romanize-0.1.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting gruut==2.2.3 (from gruut[de,es,fr]==2.2.3->coqui-tts==0.23.1)\n",
            "  Downloading gruut-2.2.3.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jamo (from coqui-tts==0.23.1)\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting g2pkk>=0.1.1 (from coqui-tts==0.23.1)\n",
            "  Downloading g2pkk-0.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting bangla (from coqui-tts==0.23.1)\n",
            "  Downloading bangla-0.0.5-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting bnnumerizer (from coqui-tts==0.23.1)\n",
            "  Downloading bnnumerizer-0.0.2.tar.gz (4.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bnunicodenormalizer (from coqui-tts==0.23.1)\n",
            "  Downloading bnunicodenormalizer-0.1.7-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from coqui-tts==0.23.1) (0.8.1)\n",
            "Requirement already satisfied: transformers>=4.33.0 in /usr/local/lib/python3.12/dist-packages (from coqui-tts==0.23.1) (4.57.1)\n",
            "Collecting encodec>=0.1.1 (from coqui-tts==0.23.1)\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting num2words (from coqui-tts==0.23.1)\n",
            "  Downloading num2words-0.5.14-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: spacy>=3 in /usr/local/lib/python3.12/dist-packages (from spacy[ja]>=3->coqui-tts==0.23.1) (3.8.7)\n",
            "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->coqui-tts==0.23.1) (2.17.0)\n",
            "Collecting dateparser~=1.1.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->coqui-tts==0.23.1)\n",
            "  Downloading dateparser-1.1.8-py2.py3-none-any.whl.metadata (27 kB)\n",
            "Collecting gruut-ipa<1.0,>=0.12.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->coqui-tts==0.23.1)\n",
            "  Downloading gruut-ipa-0.13.0.tar.gz (101 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_en~=2.0.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->coqui-tts==0.23.1)\n",
            "  Downloading gruut_lang_en-2.0.1.tar.gz (15.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m128.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jsonlines~=1.2.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->coqui-tts==0.23.1)\n",
            "  Downloading jsonlines-1.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting networkx<3.0.0,>=2.5.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->coqui-tts==0.23.1)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting python-crfsuite~=0.9.7 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->coqui-tts==0.23.1)\n",
            "  Downloading python_crfsuite-0.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting gruut_lang_de~=2.0.0 (from gruut[de,es,fr]==2.2.3->coqui-tts==0.23.1)\n",
            "  Downloading gruut_lang_de-2.0.1.tar.gz (18.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_es~=2.0.0 (from gruut[de,es,fr]==2.2.3->coqui-tts==0.23.1)\n",
            "  Downloading gruut_lang_es-2.0.1.tar.gz (31.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_fr~=2.0.0 (from gruut[de,es,fr]==2.2.3->coqui-tts==0.23.1)\n",
            "  Downloading gruut_lang_fr-2.0.2.tar.gz (10.9 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m119.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting coqpit-config<0.3.0,>=0.2.0 (from coqui-tts-trainer>=0.1->coqui-tts==0.23.1)\n",
            "  Downloading coqpit_config-0.2.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.12/dist-packages (from coqui-tts-trainer>=0.1->coqui-tts==0.23.1) (5.9.5)\n",
            "Requirement already satisfied: tensorboard>=2.17.0 in /usr/local/lib/python3.12/dist-packages (from coqui-tts-trainer>=0.1->coqui-tts==0.23.1) (2.19.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2023.6.0->coqui-tts==0.23.1) (3.13.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from g2pkk>=0.1.1->coqui-tts==0.23.1) (3.9.1)\n",
            "Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.12/dist-packages (from inflect>=5.6.0->coqui-tts==0.23.1) (10.8.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from inflect>=5.6.0->coqui-tts==0.23.1) (4.4.4)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->coqui-tts==0.23.1) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->coqui-tts==0.23.1) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->coqui-tts==0.23.1) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->coqui-tts==0.23.1) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->coqui-tts==0.23.1) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->coqui-tts==0.23.1) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->coqui-tts==0.23.1) (1.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->coqui-tts==0.23.1) (4.15.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->coqui-tts==0.23.1) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->coqui-tts==0.23.1) (1.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->coqui-tts==0.23.1) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->coqui-tts==0.23.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->coqui-tts==0.23.1) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->coqui-tts==0.23.1) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->coqui-tts==0.23.1) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->coqui-tts==0.23.1) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->coqui-tts==0.23.1) (2.9.0.post0)\n",
            "Collecting docopt>=0.6.2 (from num2words->coqui-tts==0.23.1)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.0->coqui-tts==0.23.1) (2.0.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (0.19.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (2.11.10)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (3.5.0)\n",
            "Collecting sudachipy!=0.6.1,>=0.5.2 (from spacy[ja]>=3->coqui-tts==0.23.1)\n",
            "  Downloading SudachiPy-0.6.10-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting sudachidict_core>=20211220 (from spacy[ja]>=3->coqui-tts==0.23.1)\n",
            "  Downloading sudachidict_core-20250825-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->coqui-tts==0.23.1) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->coqui-tts==0.23.1) (1.13.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->coqui-tts==0.23.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->coqui-tts==0.23.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->coqui-tts==0.23.1) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->coqui-tts==0.23.1) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->coqui-tts==0.23.1) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->coqui-tts==0.23.1) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->coqui-tts==0.23.1) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->coqui-tts==0.23.1) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->coqui-tts==0.23.1) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->coqui-tts==0.23.1) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->coqui-tts==0.23.1) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->coqui-tts==0.23.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->coqui-tts==0.23.1) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->coqui-tts==0.23.1) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->coqui-tts==0.23.1) (3.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.33.0->coqui-tts==0.23.1) (0.35.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.33.0->coqui-tts==0.23.1) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.33.0->coqui-tts==0.23.1) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.33.0->coqui-tts==0.23.1) (0.6.2)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.12/dist-packages (from umap-learn>=0.5.1->coqui-tts==0.23.1) (0.5.13)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2023.6.0->coqui-tts==0.23.1) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2023.6.0->coqui-tts==0.23.1) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2023.6.0->coqui-tts==0.23.1) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2023.6.0->coqui-tts==0.23.1) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2023.6.0->coqui-tts==0.23.1) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2023.6.0->coqui-tts==0.23.1) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2023.6.0->coqui-tts==0.23.1) (1.22.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.0->coqui-tts==0.23.1) (2.23)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from dateparser~=1.1.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->coqui-tts==0.23.1) (2025.2)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.12/dist-packages (from dateparser~=1.1.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->coqui-tts==0.23.1) (5.3.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.33.0->coqui-tts==0.23.1) (1.1.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from jsonlines~=1.2.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->coqui-tts==0.23.1) (1.17.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (1.3.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa>=0.10.1->coqui-tts==0.23.1) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa>=0.10.1->coqui-tts==0.23.1) (4.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (2025.10.5)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa>=0.10.1->coqui-tts==0.23.1) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.1->coqui-tts==0.23.1) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.17.0->coqui-tts-trainer>=0.1->coqui-tts==0.23.1) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.17.0->coqui-tts-trainer>=0.1->coqui-tts==0.23.1) (1.75.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.17.0->coqui-tts-trainer>=0.1->coqui-tts==0.23.1) (3.9)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.17.0->coqui-tts-trainer>=0.1->coqui-tts==0.23.1) (5.29.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.17.0->coqui-tts-trainer>=0.1->coqui-tts==0.23.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.17.0->coqui-tts-trainer>=0.1->coqui-tts==0.23.1) (3.1.3)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (0.1.5)\n",
            "INFO: pip is looking at multiple versions of thinc to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting thinc<8.4.0,>=8.3.4 (from spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1)\n",
            "  Downloading thinc-8.3.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1)\n",
            "  Downloading blis-1.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (7.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (3.0.3)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (1.3.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (1.17.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->coqui-tts==0.23.1) (0.1.2)\n",
            "Downloading coqui_tts-0.23.1-cp312-cp312-manylinux1_x86_64.whl (939 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m939.3/939.3 kB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anyascii-0.3.3-py3-none-any.whl (345 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m345.1/345.1 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coqpit-0.0.17-py3-none-any.whl (13 kB)\n",
            "Downloading coqui_tts_trainer-0.3.1-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.2/57.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading g2pkk-0.1.2-py3-none-any.whl (25 kB)\n",
            "Downloading num2words-0.5.14-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bangla-0.0.5-py3-none-any.whl (5.1 kB)\n",
            "Downloading bnunicodenormalizer-0.1.7-py3-none-any.whl (23 kB)\n",
            "Downloading hangul_romanize-0.1.0-py3-none-any.whl (4.6 kB)\n",
            "Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Downloading pypinyin-0.55.0-py2.py3-none-any.whl (840 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m840.2/840.2 kB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coqpit_config-0.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_crfsuite-0.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sudachidict_core-20250825-py3-none-any.whl (72.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.2/72.2 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SudachiPy-0.6.10-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thinc-8.3.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blis-1.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m118.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: gruut, encodec, bnnumerizer, docopt, gruut-ipa, gruut_lang_de, gruut_lang_en, gruut_lang_es, gruut_lang_fr\n",
            "  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut: filename=gruut-2.2.3-py3-none-any.whl size=75785 sha256=e14cc5cfb4b56f2ffefe631c1e207eba54073ea5a7c8a050c71dc46161dc074b\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/08/01/a80836c258b22fe3db037fba21e51ec327f74174838010d93b\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45759 sha256=daae9b706ca1404b708ddef0a668961af951bf9f1c322da316b8f763fb102308\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/eb/9f/e13610cc46ab39d3199fbabebd1c3e142d44b679526e0f228a\n",
            "  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bnnumerizer: filename=bnnumerizer-0.0.2-py3-none-any.whl size=5260 sha256=bf5d10e1f366d02ad0e6f62a87820ae211812e108d18177fdb4263d287112a34\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/a3/40/cc330c64cd0abbaf0e112d9a14ae0b835c74f560b493ecc1bb\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=4b15e00c6d09390a51df4479e16570bff8bfaebe4d0de7c57acb09c081db75d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/bf/a1/4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-ipa: filename=gruut_ipa-0.13.0-py3-none-any.whl size=104873 sha256=61352df182065d1d49b56d72396e4d46ff28623cc06413dcdbc9d320696f3c04\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/9d/d2/d6f6eb77784f063fcd497427fd93324cebf974247984bba85b\n",
            "  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_de: filename=gruut_lang_de-2.0.1-py3-none-any.whl size=18498314 sha256=561138c2f3ae8d5bff7ac9aa360f7f9d829912c67ca3c397a1d26f8be21ee030\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/75/26/e627d52dac0253ad7d11e5b9f74d51d82e040d07432f53ad9b\n",
            "  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_en: filename=gruut_lang_en-2.0.1-py3-none-any.whl size=15326858 sha256=f38fe2fe886675f33f9f8072402819d5c752339f7e45c413b96e1682b9b709dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/ca/a4/d1a6f20e47b857313689ca1f31684102ba67cecda2acae368d\n",
            "  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_es: filename=gruut_lang_es-2.0.1-py3-none-any.whl size=32173927 sha256=8e9bff3467c89a3b741899b63e39dc333255277d0ebea9731570965c26be4cce\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/19/79/0a65f77c4921ae0daa8d01e5b11502a909b55bd22fa188962d\n",
            "  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_fr: filename=gruut_lang_fr-2.0.2-py3-none-any.whl size=10968767 sha256=4868219254c819c4a1306eb8f34511e5859d8c769c5d4141db2f044ec99c2765\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/91/46/0ab326f9e46bc2cc2fe2f35b0e0e6f3b8284d78efd25192d96\n",
            "Successfully built gruut encodec bnnumerizer docopt gruut-ipa gruut_lang_de gruut_lang_en gruut_lang_es gruut_lang_fr\n",
            "Installing collected packages: sudachipy, jamo, hangul-romanize, gruut_lang_fr, gruut_lang_es, gruut_lang_en, gruut_lang_de, docopt, bnunicodenormalizer, bnnumerizer, bangla, sudachidict_core, python-crfsuite, pysbd, pypinyin, num2words, networkx, jsonlines, gruut-ipa, coqpit-config, coqpit, blis, anyascii, g2pkk, dateparser, gruut, thinc, coqui-tts-trainer, encodec, coqui-tts\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.5\n",
            "    Uninstalling networkx-3.5:\n",
            "      Successfully uninstalled networkx-3.5\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 1.3.0\n",
            "    Uninstalling blis-1.3.0:\n",
            "      Successfully uninstalled blis-1.3.0\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.3.6\n",
            "    Uninstalling thinc-8.3.6:\n",
            "      Successfully uninstalled thinc-8.3.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scikit-image 0.25.2 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\n",
            "nx-cugraph-cu12 25.6.0 requires networkx>=3.2, but you have networkx 2.8.8 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed anyascii-0.3.3 bangla-0.0.5 blis-1.2.1 bnnumerizer-0.0.2 bnunicodenormalizer-0.1.7 coqpit-0.0.17 coqpit-config-0.2.1 coqui-tts-0.23.1 coqui-tts-trainer-0.3.1 dateparser-1.1.8 docopt-0.6.2 encodec-0.1.1 g2pkk-0.1.2 gruut-2.2.3 gruut-ipa-0.13.0 gruut_lang_de-2.0.1 gruut_lang_en-2.0.1 gruut_lang_es-2.0.1 gruut_lang_fr-2.0.2 hangul-romanize-0.1.0 jamo-0.4.1 jsonlines-1.2.0 networkx-2.8.8 num2words-0.5.14 pypinyin-0.55.0 pysbd-0.3.4 python-crfsuite-0.9.11 sudachidict_core-20250825 sudachipy-0.6.10 thinc-8.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ep1xRDk4ghi"
      },
      "source": [
        "# ======================================\n",
        "# ğŸ” RESTORE ENV FROM LOCK (use on fresh runtimes)\n",
        "# ======================================\n",
        "%%capture\n",
        "# Prefer Drive lock if available, else local\n",
        "LOCK_TXT = \"/content/drive/MyDrive/ColabEnvLocks/requirements_lock.txt\"\n",
        "FALLBACK_LOCK = \"/content/requirements_lock.txt\"\n",
        "import os\n",
        "lock_to_use = LOCK_TXT if os.path.exists(LOCK_TXT) else FALLBACK_LOCK\n",
        "print(f\"Installing from lock: {lock_to_use}\")\n",
        "%pip install -q --no-deps -r \"$lock_to_use\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fq-YA5E4ghi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28d28ac9-d35e-4d51-b864-4c5809dcc59f",
        "collapsed": true
      },
      "source": [
        "\n",
        "# ======================================\n",
        "# â¬‡ï¸ OPTIONAL: PRE-DOWNLOAD TTS MODEL WEIGHTS (persist to Drive if mounted)\n",
        "# ======================================\n",
        "from TTS.api import TTS\n",
        "import os\n",
        "\n",
        "MODEL_NAME = \"tts_models/en/ljspeech/tacotron2-DDC\"  # change if you need a different model\n",
        "LOCAL_DIR = \"/content/models/tts\"\n",
        "os.makedirs(LOCAL_DIR, exist_ok=True)\n",
        "\n",
        "# Instantiate once to trigger download into cache; also synthesize a tiny file to ensure weights are present\n",
        "tts = TTS(model_name=MODEL_NAME, progress_bar=False, gpu=torch.cuda.is_available())\n",
        "tts.tts_to_file(text=\"setup\", file_path=f\"{LOCAL_DIR}/_warmup.wav\")\n",
        "print(\"Model ready:\", MODEL_NAME)\n",
        "\n",
        "# If Drive is mounted, copy cache for persistence\n",
        "if os.path.exists(\"/content/drive\"):\n",
        "    DRIVE_DIR = \"/content/drive/MyDrive/ColabModels/tts\"\n",
        "    os.makedirs(DRIVE_DIR, exist_ok=True)\n",
        "    print(\"Drive detected. Consider syncing ~/.local/share/tts to Drive for full persistence.\")\n",
        "else:\n",
        "    print(\"Drive not mounted â€” model will be cached only in this runtime.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jieba/__init__.py:44: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  re_han_default = re.compile(\"([\\u4E00-\\u9FD5a-zA-Z0-9+#&\\._%\\-]+)\", re.U)\n",
            "/usr/local/lib/python3.12/dist-packages/jieba/__init__.py:46: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  re_skip_default = re.compile(\"(\\r\\n|\\s)\", re.U)\n",
            "/usr/local/lib/python3.12/dist-packages/jieba/finalseg/__init__.py:78: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  re_skip = re.compile(\"([a-zA-Z0-9]+(?:\\.\\d+)?%?)\")\n",
            "/usr/local/lib/python3.12/dist-packages/TTS/api.py:71: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.\n",
            "  warnings.warn(\"`gpu` will be deprecated. Please use `tts.to(device)` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model ready: tts_models/en/ljspeech/tacotron2-DDC\n",
            "Drive detected. Consider syncing ~/.local/share/tts to Drive for full persistence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4MjHTZC4ghi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77090fee-25af-413e-e3f9-6edf7b550385"
      },
      "source": [
        "# ======================================\n",
        "# ğŸ“¦ OPTIONAL: EXTRACT ALL ZIP DATASETS IN /content\n",
        "# ======================================\n",
        "import zipfile, glob, os\n",
        "DATA_DIR = \"/content/data\"\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "zips = glob.glob(\"/content/*.zip\")\n",
        "for z in zips:\n",
        "    print(\"Extracting:\", z)\n",
        "    with zipfile.ZipFile(z, 'r') as zip_ref:\n",
        "        zip_ref.extractall(DATA_DIR)\n",
        "\n",
        "print(\"Done. Files in data dir:\")\n",
        "for root, dirs, files in os.walk(DATA_DIR):\n",
        "    for f in files[:50]:\n",
        "        print(os.path.join(root, f))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done. Files in data dir:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# extract_data\n"
      ],
      "metadata": {
        "id": "CeCXF8rG9JdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "# import os\n",
        "\n",
        "# # ×”× ×ª×™×‘ ×œ×ª×™×§×™×™×” ×©× ×•×¦×¨×” ×‘×”×¨×¦×” ×”×§×•×“××ª\n",
        "# destination_folder = \"/content/vctk_full\"\n",
        "\n",
        "# # ×‘×“×™×§×” ×× ×”×ª×™×§×™×™×” ×§×™×™××ª, ×•××– ××—×™×§×”\n",
        "# if os.path.exists(destination_folder):\n",
        "#     shutil.rmtree(destination_folder)\n",
        "#     print(f\" ×”×ª×™×§×™×™×” '{destination_folder}' × ××—×§×” ×‘×”×¦×œ×—×”.\")\n",
        "# else:\n",
        "#     print(f\"â„¹ ×”×ª×™×§×™×™×” '{destination_folder}' ×œ× ×§×™×™××ª, ××™×Ÿ ××” ×œ××—×•×§.\")\n"
      ],
      "metadata": {
        "id": "qsB_qTqinrA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# List contents to verify paths (optional)\n",
        "root_path = '/content/drive/My Drive/'\n",
        "print(\"Contents of 'My Drive':\", os.listdir(root_path))\n",
        "\n",
        "subfolder_path = '/content/drive/My Drive/Colab Notebooks/'\n",
        "print(\"Contents of 'Colab Notebooks':\", os.listdir(subfolder_path))\n",
        "\n",
        "# Define paths\n",
        "zip_file = \"/content/drive/My Drive/Colab Notebooks/archive.zip\"  # Path to your ZIP file\n",
        "destination_folder = \"/content/vctk_samples\"  # Where to extract selected data\n",
        "wanted_speakers = [\"p225\", \"p226\", \"p227\", \"p228\"]  # Select specific speakers\n",
        "\n",
        "# Check if the ZIP file exists\n",
        "if os.path.isfile(zip_file):\n",
        "    print(\" ZIP file found:\", zip_file)\n",
        "else:\n",
        "    raise FileNotFoundError(f\" ZIP file not found: {zip_file}\")\n",
        "\n",
        "# Create destination folder if it doesn't exist\n",
        "os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "# Selectively extract only desired speaker folders from the ZIP\n",
        "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "    extracted_files = 0\n",
        "    for file in zip_ref.namelist():\n",
        "        if any(f\"VCTK-Corpus/wav48/{spk}/\" in file or f\"VCTK-Corpus/txt/{spk}/\" in file for spk in wanted_speakers):\n",
        "            # Ensure directory structure is preserved\n",
        "            target_path = os.path.join(destination_folder, file)\n",
        "            os.makedirs(os.path.dirname(target_path), exist_ok=True)\n",
        "            with zip_ref.open(file) as source, open(target_path, 'wb') as target:\n",
        "                shutil.copyfileobj(source, target)\n",
        "            extracted_files += 1\n",
        "\n",
        "print(f\"\\n Extraction complete: {extracted_files} files were extracted.\")\n",
        "print(f\" Extracted data is available in: {destination_folder}\")\n"
      ],
      "metadata": {
        "id": "9YxlgeQE9ufN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b744aef-3de8-4f5e-d175-2cd9d6a1b351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Contents of 'My Drive': ['Colab Notebooks', 'Deep learning', 'ColabEnvLocks', 'ColabModels', 'Colab_Data']\n",
            "Contents of 'Colab Notebooks': ['archive.zip', 'fake_audio.zip', 'Copy of Welcome To Colab', 'Untitled0.ipynb', 'Untitled1.ipynb', 'FinalProjectCS.ipynb', 'FinalProjectCS_reset_setup.ipynb']\n",
            " ZIP file found: /content/drive/My Drive/Colab Notebooks/archive.zip\n",
            "\n",
            " Extraction complete: 2684 files were extracted.\n",
            " Extracted data is available in: /content/vctk_samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installations\n"
      ],
      "metadata": {
        "id": "zB_QfTQcEA-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y espeak-ng"
      ],
      "metadata": {
        "id": "nymZzYIfrL7N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "a9fcb4b4-477e-4788-dfa3-17b39af2660d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  espeak-ng-data libespeak-ng1 libpcaudio0 libsonic0\n",
            "The following NEW packages will be installed:\n",
            "  espeak-ng espeak-ng-data libespeak-ng1 libpcaudio0 libsonic0\n",
            "0 upgraded, 5 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 4,526 kB of archives.\n",
            "After this operation, 11.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libpcaudio0 amd64 1.1-6build2 [8,956 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsonic0 amd64 0.2.0-11build1 [10.3 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 espeak-ng-data amd64 1.50+dfsg-10ubuntu0.1 [3,956 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libespeak-ng1 amd64 1.50+dfsg-10ubuntu0.1 [207 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 espeak-ng amd64 1.50+dfsg-10ubuntu0.1 [343 kB]\n",
            "Fetched 4,526 kB in 2s (2,921 kB/s)\n",
            "Selecting previously unselected package libpcaudio0:amd64.\n",
            "(Reading database ... 126675 files and directories currently installed.)\n",
            "Preparing to unpack .../libpcaudio0_1.1-6build2_amd64.deb ...\n",
            "Unpacking libpcaudio0:amd64 (1.1-6build2) ...\n",
            "Selecting previously unselected package libsonic0:amd64.\n",
            "Preparing to unpack .../libsonic0_0.2.0-11build1_amd64.deb ...\n",
            "Unpacking libsonic0:amd64 (0.2.0-11build1) ...\n",
            "Selecting previously unselected package espeak-ng-data:amd64.\n",
            "Preparing to unpack .../espeak-ng-data_1.50+dfsg-10ubuntu0.1_amd64.deb ...\n",
            "Unpacking espeak-ng-data:amd64 (1.50+dfsg-10ubuntu0.1) ...\n",
            "Selecting previously unselected package libespeak-ng1:amd64.\n",
            "Preparing to unpack .../libespeak-ng1_1.50+dfsg-10ubuntu0.1_amd64.deb ...\n",
            "Unpacking libespeak-ng1:amd64 (1.50+dfsg-10ubuntu0.1) ...\n",
            "Selecting previously unselected package espeak-ng.\n",
            "Preparing to unpack .../espeak-ng_1.50+dfsg-10ubuntu0.1_amd64.deb ...\n",
            "Unpacking espeak-ng (1.50+dfsg-10ubuntu0.1) ...\n",
            "Setting up libpcaudio0:amd64 (1.1-6build2) ...\n",
            "Setting up libsonic0:amd64 (0.2.0-11build1) ...\n",
            "Setting up espeak-ng-data:amd64 (1.50+dfsg-10ubuntu0.1) ...\n",
            "Setting up libespeak-ng1:amd64 (1.50+dfsg-10ubuntu0.1) ...\n",
            "Setting up espeak-ng (1.50+dfsg-10ubuntu0.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deleting fake_wav48 if it exists"
      ],
      "metadata": {
        "id": "a4EjZRVMERfm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# generate_fake_data"
      ],
      "metadata": {
        "id": "3x2fEEe0oHhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# from TTS.api import TTS\n",
        "# import shutil\n",
        "\n",
        "# fake_audio_folder = \"/content/vctk_samples/VCTK-Corpus/VCTK-Corpus/fake_wav48\"\n",
        "# # ×¤×•× ×§×¦×™×” ×œ××—×™×§×ª ×›×œ ×§×‘×¦×™ ×”××•×“×™×• ×©× ×•×¦×¨×•\n",
        "# def clear_fake_audio_folder(fake_audio_folder):\n",
        "#     if os.path.exists(fake_audio_folder):\n",
        "#         shutil.rmtree(fake_audio_folder)  # ××•×—×§ ××ª ×›×œ ×”×ª×™×§×™×™×” ×›×•×œ×œ ×”×§×‘×¦×™× ×©×‘×”\n",
        "#         os.makedirs(fake_audio_folder, exist_ok=True)  # ×™×•×¦×¨ ××—×“×© ××ª ×”×ª×™×§×™×™×” ×”×¨×™×§×”\n",
        "#         print(f\" ×›×œ ×”×§×‘×¦×™× ×‘×ª×™×§×™×™×” '{fake_audio_folder}' × ××—×§×•!\")\n",
        "\n",
        "# clear_fake_audio_folder(fake_audio_folder)\n",
        "# quit()"
      ],
      "metadata": {
        "id": "bfJgcbcSqmrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Fake Audio (No Need to run now)"
      ],
      "metadata": {
        "id": "YqWhklMLEWba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import threading\n",
        "import torch\n",
        "\n",
        "from TTS.api import TTS\n",
        "\n",
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "# 1) Input text files (one .txt per utterance)\n",
        "TEXT_ROOT = Path(\"/content/vctk_samples/VCTK-Corpus/VCTK-Corpus/txt\")\n",
        "\n",
        "# 2) Real audio folder (matching real WAVs you want to clone the voice from)\n",
        "#    The script will try to find a matching WAV by the text filename stem inside the corresponding subfolder.\n",
        "#    Example: If text is \".../p228/p228_065.txt\", it will try \"/.../real_audio_folder/p228/p228_065.wav\"\n",
        "REAL_AUDIO_ROOT = Path(\"/content/vctk_samples/VCTK-Corpus/VCTK-Corpus/wav48\")  # <-- CHANGE if needed\n",
        "\n",
        "# 3) Output folder for fake audio\n",
        "OUT_ROOT = Path(\"/content/vctk_samples/VCTK-Corpus/VCTK-Corpus/fake_wav48_xtts\")\n",
        "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 4) Speaker metadata (for bookkeeping only; XTTS uses speaker_wav for actual voice)\n",
        "SPEAKER_INFO = {\n",
        "    \"p225\": (\"F\", \"22\", \"Southern England\"),\n",
        "    \"p226\": (\"M\", \"22\", \"Surrey\"),\n",
        "    \"p227\": (\"M\", \"38\", \"Cumbria\"),\n",
        "    \"p228\": (\"F\", \"22\", \"Southern England\"),\n",
        "}\n",
        "\n",
        "# 5) Language to synthesize in (VCTK is English)\n",
        "LANGUAGE = \"en\"\n",
        "\n",
        "# 6) Concurrency settings:\n",
        "#    On GPU, keep MAX_WORKERS=1 (XTTS is heavy and not thread-safe on CUDA).\n",
        "#    On CPU, you can increase to 4 (or more if your machine can handle it).\n",
        "GPU_AVAILABLE = torch.cuda.is_available()\n",
        "MAX_WORKERS = 1 if GPU_AVAILABLE else 4\n",
        "\n",
        "# =========================\n",
        "# MODEL LOADING\n",
        "# =========================\n",
        "# Use XTTS v2 for voice cloning with a reference WAV.\n",
        "# (We also lazy-load a VCTK-VITS fallback if a real WAV is missing.)\n",
        "print(\"Loading XTTS v2 model...\")\n",
        "tts_xtts = TTS(model_name=\"tts_models/multilingual/multi-dataset/xtts_v2\", progress_bar=True)\n",
        "device = \"cuda\" if GPU_AVAILABLE else \"cpu\"\n",
        "tts_xtts.to(device)\n",
        "print(f\"XTTS is running on: {device}\")\n",
        "\n",
        "# Fallback multi-speaker model (only used when no real WAV is found)\n",
        "print(\"Loading VCTK-VITS fallback model...\")\n",
        "tts_vctk = TTS(model_name=\"tts_models/en/vctk/vits\", progress_bar=False)\n",
        "tts_vctk.to(device)\n",
        "\n",
        "# Mutex for model calls if you insist on >1 threads on CPU (XTTS is heavy; serialize calls by default on GPU).\n",
        "synth_lock = threading.Lock() if MAX_WORKERS > 1 else None\n",
        "\n",
        "# =========================\n",
        "# HELPERS\n",
        "# =========================\n",
        "def to_vctk_id(s: str) -> str:\n",
        "    \"\"\"Convert '228' -> 'p228' for VCTK-style speaker IDs.\"\"\"\n",
        "    s = s.strip()\n",
        "    return s if s.startswith(\"p\") else f\"p{s}\"\n",
        "\n",
        "def find_matching_real_wav(real_root: Path, subdir: str, txt_filename: str) -> Path | None:\n",
        "    \"\"\"\n",
        "    Try to find the real WAV that matches the text file.\n",
        "    Strategy:\n",
        "      1) exact same stem under REAL_AUDIO_ROOT/subdir:  <stem>.wav\n",
        "      2) any .wav in subdir that contains the stem (fallback)\n",
        "      3) final fallback: None\n",
        "    \"\"\"\n",
        "    stem = Path(txt_filename).stem  # e.g., 'p228_065' or '228_065'\n",
        "    # Common VCTK stems look like 'p228_065'. If it's numeric-only, normalize:\n",
        "    parts = stem.split(\"_\")\n",
        "    if parts and not parts[0].startswith(\"p\"):\n",
        "        parts[0] = \"p\" + parts[0]\n",
        "    norm_stem = \"_\".join(parts)\n",
        "\n",
        "    cand1 = real_root / subdir / f\"{norm_stem}.wav\"\n",
        "    if cand1.exists():\n",
        "        return cand1\n",
        "\n",
        "    # Try exactly the original stem (if it already had 'p')\n",
        "    cand2 = real_root / subdir / f\"{stem}.wav\"\n",
        "    if cand2.exists():\n",
        "        return cand2\n",
        "\n",
        "    # Fallback: search within subdir for anything containing norm_stem or the raw stem\n",
        "    subdir_path = real_root / subdir\n",
        "    if subdir_path.is_dir():\n",
        "        for fn in os.listdir(subdir_path):\n",
        "            if not fn.lower().endswith(\".wav\"):\n",
        "                continue\n",
        "            if norm_stem in fn or stem in fn:\n",
        "                return subdir_path / fn\n",
        "\n",
        "    return None\n",
        "\n",
        "def synth_xtts(text: str, speaker_wav: Path, out_path: Path, language: str = \"en\"):\n",
        "    \"\"\"\n",
        "    Synthesize with XTTS v2 using a reference speaker WAV. This is the key for high voice similarity.\n",
        "    \"\"\"\n",
        "    # Serialize heavy GPU calls if needed\n",
        "    if synth_lock:\n",
        "        with synth_lock:\n",
        "            tts_xtts.tts_to_file(text=text, file_path=str(out_path), speaker_wav=str(speaker_wav), language=language)\n",
        "    else:\n",
        "        tts_xtts.tts_to_file(text=text, file_path=str(out_path), speaker_wav=str(speaker_wav), language=language)\n",
        "\n",
        "def synth_vctk(text: str, speaker_id: str, out_path: Path):\n",
        "    \"\"\"\n",
        "    Fallback synthesis with VCTK-VITS multi-speaker model (uses 'p###' speakers).\n",
        "    \"\"\"\n",
        "    if synth_lock:\n",
        "        with synth_lock:\n",
        "            tts_vctk.tts_to_file(text=text, speaker=speaker_id, file_path=str(out_path))\n",
        "    else:\n",
        "        tts_vctk.tts_to_file(text=text, speaker=speaker_id, file_path=str(out_path))\n",
        "\n",
        "def process_one(text_path: Path, out_subdir: Path):\n",
        "    \"\"\"\n",
        "    Process a single text file:\n",
        "      - Read text\n",
        "      - Resolve speaker_id from filename (for metadata/fallback)\n",
        "      - Find matching real WAV\n",
        "      - Prefer XTTS cloning; fallback to VCTK-VITS speaker if real WAV missing\n",
        "    \"\"\"\n",
        "    text = text_path.read_text(encoding=\"utf-8\").strip()\n",
        "    if not text:\n",
        "        return f\"[SKIP] Empty text: {text_path.name}\"\n",
        "\n",
        "    # Resolve speaker id from the filename (e.g., 'p228' from 'p228_065.txt')\n",
        "    raw_id = text_path.stem.split(\"_\")[0]          # 'p228' or '228'\n",
        "    speaker_id = to_vctk_id(raw_id)                # 'p228'\n",
        "\n",
        "    # Metadata (for filename only)\n",
        "    gender, age, accent = SPEAKER_INFO.get(speaker_id, (\"F\", \"22\", \"Southern England\"))\n",
        "\n",
        "    # Try to find the matching real wav in REAL_AUDIO_ROOT/<subdir>/\n",
        "    subdir = text_path.parent.name\n",
        "    real_wav = find_matching_real_wav(REAL_AUDIO_ROOT, subdir, text_path.name)\n",
        "\n",
        "    # Build output path (include metadata in filename)\n",
        "    out_name = f\"{text_path.stem}__{speaker_id}__{gender}_{age}_{accent}.wav\"\n",
        "    out_path = out_subdir / out_name\n",
        "\n",
        "    # Prefer XTTS cloning if real wav exists; otherwise fallback to VCTK-VITS speaker\n",
        "    if real_wav and real_wav.exists():\n",
        "        msg = f\"[XTTS] {text_path.name} -> clone from {real_wav.name} -> {out_name}\"\n",
        "        synth_xtts(text=text, speaker_wav=real_wav, out_path=out_path, language=LANGUAGE)\n",
        "        return msg\n",
        "    else:\n",
        "        msg = f\"[FALLBACK VCTK] {text_path.name} -> speaker={speaker_id} -> {out_name}\"\n",
        "        synth_vctk(text=text, speaker_id=speaker_id, out_path=out_path)\n",
        "        return msg\n",
        "\n",
        "# =========================\n",
        "# BUILD JOBS\n",
        "# =========================\n",
        "jobs = []\n",
        "for subdir in os.listdir(TEXT_ROOT):\n",
        "    subdir_path = TEXT_ROOT / subdir\n",
        "    if not subdir_path.is_dir():\n",
        "        continue\n",
        "\n",
        "    out_subdir = OUT_ROOT / subdir\n",
        "    out_subdir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for fn in os.listdir(subdir_path):\n",
        "        if not fn.lower().endswith(\".txt\"):\n",
        "            continue\n",
        "        jobs.append((subdir_path / fn, out_subdir))\n",
        "\n",
        "print(f\"Found {len(jobs)} text files.\")\n",
        "\n",
        "# =========================\n",
        "# RUN\n",
        "# =========================\n",
        "if not jobs:\n",
        "    print(\"No jobs found. Check TEXT_ROOT.\")\n",
        "else:\n",
        "    print(f\"Starting synthesis with MAX_WORKERS={MAX_WORKERS} (device={device})\")\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
        "        futs = [ex.submit(process_one, text_path, out_dir) for (text_path, out_dir) in jobs]\n",
        "        for fut in as_completed(futs):\n",
        "            try:\n",
        "                info = fut.result()\n",
        "                print(info)\n",
        "            except Exception as e:\n",
        "                print(\"[ERROR]\", repr(e))\n",
        "\n",
        "print(\"Done. Fake audio saved under:\", OUT_ROOT)\n"
      ],
      "metadata": {
        "id": "1ZDmhBIjEHQW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "outputId": "7b8cb2ca-f63f-42fa-c72a-4c54e182edbd",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jieba/__init__.py:44: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  re_han_default = re.compile(\"([\\u4E00-\\u9FD5a-zA-Z0-9+#&\\._%\\-]+)\", re.U)\n",
            "/usr/local/lib/python3.12/dist-packages/jieba/__init__.py:46: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  re_skip_default = re.compile(\"(\\r\\n|\\s)\", re.U)\n",
            "/usr/local/lib/python3.12/dist-packages/jieba/finalseg/__init__.py:78: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  re_skip = re.compile(\"([a-zA-Z0-9]+(?:\\.\\d+)?%?)\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading XTTS v2 model...\n",
            " > You must confirm the following:\n",
            " | > \"I have purchased a commercial license from Coqui: licensing@coqui.ai\"\n",
            " | > \"Otherwise, I agree to the terms of the non-commercial CPML: https://coqui.ai/cpml\" - [y/n]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2786429156.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# (We also lazy-load a VCTK-VITS fallback if a real WAV is missing.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading XTTS v2 model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mtts_xtts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTTS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tts_models/multilingual/multi-dataset/xtts_v2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mGPU_AVAILABLE\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mtts_xtts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/TTS/api.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name, model_path, config_path, vocoder_name, vocoder_path, vocoder_config_path, encoder_path, encoder_config_path, speakers_file_path, language_ids_file_path, progress_bar, gpu)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"tts_models\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_tts_model_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m\"voice_conversion_models\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_vc_model_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/TTS/api.py\u001b[0m in \u001b[0;36mload_tts_model_by_name\u001b[0;34m(self, model_name, vocoder_name, gpu)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         model_path, config_path, vocoder_path, vocoder_config_path, model_dir = self.download_model_by_name(\n\u001b[0m\u001b[1;32m    233\u001b[0m             \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocoder_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/TTS/api.py\u001b[0m in \u001b[0;36mdownload_model_by_name\u001b[0;34m(self, model_name, vocoder_name)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocoder_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     ) -> tuple[Path | None, Path | None, Path | None, Path | None, Path | None]:\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         if (\n\u001b[1;32m    168\u001b[0m             \u001b[0;34m\"fairseq\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/TTS/utils/manage.py\u001b[0m in \u001b[0;36mdownload_model\u001b[0;34m(self, model_name)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is already downloaded.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dir_and_download_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;31m# find downloaded files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/TTS/utils/manage.py\u001b[0m in \u001b[0;36mcreate_dir_and_download_model\u001b[0;34m(self, model_name, model_item, output_path)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;31m# handle TOS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtos_agreed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask_tos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m                 \u001b[0moutput_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" [!] You must agree to the terms of service to use this model.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/TTS/utils/manage.py\u001b[0m in \u001b[0;36mask_tos\u001b[0;34m(model_full_path)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' | > \"I have purchased a commercial license from Coqui: licensing@coqui.ai\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' | > \"Otherwise, I agree to the terms of the non-commercial CPML: https://coqui.ai/cpml\" - [y/n]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" | | > \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"y\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtos_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the fake audio"
      ],
      "metadata": {
        "id": "C1gzk4KwGIyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "# from google.colab import files\n",
        "\n",
        "# folder_path = \"/content/vctk_samples/VCTK-Corpus/VCTK-Corpus/fake_wav48_xtts\"\n",
        "# zip_path = \"/content/fake_audio.zip\"\n",
        "# shutil.make_archive(base_name=zip_path.replace(\".zip\", \"\"), format='zip', root_dir=folder_path)\n",
        "\n",
        "# files.download(zip_path)\n"
      ],
      "metadata": {
        "id": "ATqG7ZXl74D8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "8730374a-8303-435c-cd10-ae9ceef57af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8c6401dd-0cc1-4b42-8cfa-7a13e6288529\", \"fake_audio.zip\", 133268336)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting the fake audio"
      ],
      "metadata": {
        "id": "dcjKFlnIKvFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# Define paths\n",
        "zip_file = \"/content/drive/My Drive/Colab Notebooks/fake_audio.zip\"  # Path to your ZIP file\n",
        "destination_folder = \"/content/vctk_samples/VCTK-Corpus/VCTK-Corpus/fake_audio\"  # Where to extract selected data\n",
        "\n",
        "# Example: define the speakers you want to extract\n",
        "wanted_speakers = [\"p225\", \"p226\",\"p227\",\"p228\"]  # change this list as needed\n",
        "\n",
        "# Check if the ZIP file exists\n",
        "if os.path.isfile(zip_file):\n",
        "\n",
        "    print(\" ZIP file found:\", zip_file)\n",
        "else:\n",
        "    raise FileNotFoundError(f\" ZIP file not found: {zip_file}\")\n",
        "\n",
        "# Create destination folder if it doesn't exist\n",
        "os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "# Selectively extract only desired speaker folders from the ZIP\n",
        "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "    extracted_files = 0\n",
        "    for file in zip_ref.namelist():\n",
        "        if any(f\"{spk}/\" in file for spk in wanted_speakers):\n",
        "            target_path = os.path.join(destination_folder, file)\n",
        "\n",
        "            # If this entry is a directory â†’ skip it\n",
        "            if file.endswith('/'):\n",
        "                os.makedirs(target_path, exist_ok=True)\n",
        "                continue\n",
        "\n",
        "            # Ensure directory structure is preserved\n",
        "            os.makedirs(os.path.dirname(target_path), exist_ok=True)\n",
        "\n",
        "            # Copy file content\n",
        "            with zip_ref.open(file) as source, open(target_path, 'wb') as target:\n",
        "                shutil.copyfileobj(source, target)\n",
        "            extracted_files += 1\n",
        "\n",
        "print(f\"Extracted {extracted_files} files for speakers: {wanted_speakers}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qzof7wJ8kHse",
        "outputId": "305b2720-b84a-4950-8ecf-8cdf3d6ce3f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ZIP file found: /content/drive/My Drive/Colab Notebooks/fake_audio.zip\n",
            "Extracted 1342 files for speakers: ['p225', 'p226', 'p227', 'p228']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing libraries"
      ],
      "metadata": {
        "id": "HloMV1V7yZ7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L || echo \"No GPU\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FU7_7Wq5uCOM",
        "outputId": "6da7e7eb-b483-4ada-c0e3-caa2fcf56321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-b0b0d63e-a0d9-cbd7-cb0f-09877605c050)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "# --- Clone CLAD fresh (idempotent: remove existing dir if present) ---\n",
        "# remove previous clone to ensure a clean edit of requirements\n",
        "rm -rf CLAD\n",
        "git clone https://github.com/CLAD23/CLAD.git\n",
        "\n",
        "# --- Normalize requirements for Python 3.12 (single source of truth) ---\n",
        "cp CLAD/requirements.txt CLAD/requirements.bak\n",
        "\n",
        "# 1) Remove torch lines (Torch is installed manually for the correct CUDA wheel)\n",
        "sed -i '/^torch==/d; /^torchvision==/d; /^torchaudio==/d' CLAD/requirements.txt\n",
        "\n",
        "# 2) Core pins for Py3.12 + Numba 0.60.0 (compatible with llvmlite 0.43.0 and NumPy 1.26.4)\n",
        "#    These ensure no NumPy 2.x is pulled by accident.\n",
        "if grep -q '^numpy' CLAD/requirements.txt; then\n",
        "  sed -i 's/^numpy==.*/numpy==1.26.4/' CLAD/requirements.txt\n",
        "else\n",
        "  sed -i '1i numpy==1.26.4' CLAD/requirements.txt\n",
        "fi\n",
        "\n",
        "if grep -q '^numba' CLAD/requirements.txt; then\n",
        "  sed -i 's/^numba==.*/numba==0.60.0/' CLAD/requirements.txt\n",
        "else\n",
        "  sed -i '1i numba==0.60.0' CLAD/requirements.txt\n",
        "fi\n",
        "\n",
        "if grep -q '^llvmlite' CLAD/requirements.txt; then\n",
        "  sed -i 's/^llvmlite==.*/llvmlite==0.43.0/' CLAD/requirements.txt\n",
        "else\n",
        "  sed -i '1i llvmlite==0.43.0' CLAD/requirements.txt\n",
        "fi\n",
        "\n",
        "# 3) Stable Matplotlib on Py3.12\n",
        "if grep -q '^matplotlib' CLAD/requirements.txt; then\n",
        "  sed -i 's/^matplotlib==.*/matplotlib==3.8.4/' CLAD/requirements.txt\n",
        "else\n",
        "  sed -i '1i matplotlib==3.8.4' CLAD/requirements.txt\n",
        "fi\n",
        "\n",
        "# 4) Librosa must satisfy coqui-tts (>=0.11.0); keep it permissive to avoid conflicts\n",
        "if grep -q '^librosa' CLAD/requirements.txt; then\n",
        "  sed -i 's/^librosa.*/librosa>=0.11.0/' CLAD/requirements.txt\n",
        "else\n",
        "  sed -i '1i librosa>=0.11.0' CLAD/requirements.txt\n",
        "fi\n",
        "\n",
        "# 5) Pin OpenCV to builds compatible with NumPy 1.26.x (avoid NumPy 2.x constraint)\n",
        "#    Only modify if opencv lines exist (do not add if the project doesn't use it).\n",
        "grep -q '^opencv-python' CLAD/requirements.txt && sed -i 's/^opencv-python==.*/opencv-python==4.9.0.80/' CLAD/requirements.txt || true\n",
        "grep -q '^opencv-contrib-python' CLAD/requirements.txt && sed -i 's/^opencv-contrib-python==.*/opencv-contrib-python==4.9.0.80/' CLAD/requirements.txt || true\n",
        "\n",
        "# 6) Pin spaCy/Thinc to versions that work with NumPy 1.x (only if present)\n",
        "grep -q '^thinc' CLAD/requirements.txt && sed -i 's/^thinc==.*/thinc==8.2.2/' CLAD/requirements.txt || true\n",
        "grep -q '^spacy' CLAD/requirements.txt && sed -i 's/^spacy==.*/spacy==3.7.4/' CLAD/requirements.txt || true\n",
        "\n",
        "echo \"===== Updated CLAD/requirements.txt =====\"\n",
        "sed -n '1,250p' CLAD/requirements.txt\n",
        "\n",
        "# --- Upgrade pip to avoid resolver quirks ---\n",
        "python -m pip install -U pip\n",
        "\n",
        "# --- Install PyTorch 2.3.1 CUDA 12.1 (use CPU wheels by removing the index line if no GPU) ---\n",
        "python -m pip install --index-url https://download.pytorch.org/whl/cu121 \\\n",
        "  torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1\n",
        "\n",
        "# --- Install remaining CLAD dependencies from the single normalized requirements file ---\n",
        "python -m pip install -r CLAD/requirements.txt\n",
        "\n",
        "# --- System library for soundfile/librosa WAV I/O (safe to install always) ---\n",
        "apt-get update -y\n",
        "apt-get install -y libsndfile1\n",
        "\n",
        "echo \"===== DONE: Environment pinned for Python 3.12 =====\"\n",
        "python -V\n",
        "python - <<'PY'\n",
        "import sys, numpy, numba, llvmlite, matplotlib\n",
        "import importlib\n",
        "print(\"Python:\", sys.version.split()[0])\n",
        "print(\"NumPy:\", numpy.__version__)\n",
        "print(\"Numba:\", numba.__version__)\n",
        "print(\"llvmlite:\", llvmlite.__version__)\n",
        "print(\"Matplotlib:\", matplotlib.__version__)\n",
        "for m in (\"torch\",\"torchvision\",\"torchaudio\",\"librosa\"):\n",
        "    try:\n",
        "        mod = importlib.import_module(m)\n",
        "        print(f\"{m}:\", getattr(mod,\"__version__\", \"unknown\"))\n",
        "    except Exception as e:\n",
        "        print(f\"{m}: NOT INSTALLED ({e})\")\n",
        "PY\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaBoZc46f0p_",
        "outputId": "3cfafda8-b491-4a6c-d0a4-eb8c05a3e541",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Updated CLAD/requirements.txt =====\n",
            "llvmlite==0.43.0\n",
            "numba==0.60.0\n",
            "librosa>=0.11.0\n",
            "matplotlib==3.8.4\n",
            "numpy==1.26.4\n",
            "primePy==1.3\n",
            "torchcontrib\n",
            "pytorch_model_summary\n",
            "torchinfoRequirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.8/1.8 MB 32.5 MB/s eta 0:00:00\n",
            "Installing collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.2\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch==2.3.1\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.3.1%2Bcu121-cp312-cp312-linux_x86_64.whl (780.9 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 780.9/780.9 MB 25.7 MB/s  0:00:14\n",
            "Collecting torchvision==0.18.1\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.18.1%2Bcu121-cp312-cp312-linux_x86_64.whl (7.0 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7.0/7.0 MB 96.2 MB/s  0:00:00\n",
            "Collecting torchaudio==2.3.1\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.3.1%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.4/3.4 MB 110.8 MB/s  0:00:00\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (2.8.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 23.7/23.7 MB 178.7 MB/s  0:00:00\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 823.6/823.6 kB 48.2 MB/s  0:00:00\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 14.1/14.1 MB 189.5 MB/s  0:00:00\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 731.7/731.7 MB 11.4 MB/s  0:00:29\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 410.6/410.6 MB 25.0 MB/s  0:00:12\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 121.6/121.6 MB 71.2 MB/s  0:00:01\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 56.5/56.5 MB 70.9 MB/s  0:00:00\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 124.2/124.2 MB 71.7 MB/s  0:00:01\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 196.0/196.0 MB 25.4 MB/s  0:00:07\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 176.2/176.2 MB 10.1 MB/s  0:00:17\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.18.1) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.18.1) (11.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.1) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.1) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0+cu126\n",
            "    Uninstalling torch-2.8.0+cu126:\n",
            "      Successfully uninstalled torch-2.8.0+cu126\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.23.0+cu126\n",
            "    Uninstalling torchvision-0.23.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.23.0+cu126\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.8.0+cu126\n",
            "    Uninstalling torchaudio-2.8.0+cu126:\n",
            "      Successfully uninstalled torchaudio-2.8.0+cu126\n",
            "\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.3.1+cu121 torchaudio-2.3.1+cu121 torchvision-0.18.1+cu121\n",
            "Requirement already satisfied: llvmlite==0.43.0 in /usr/local/lib/python3.12/dist-packages (from -r CLAD/requirements.txt (line 1)) (0.43.0)\n",
            "Requirement already satisfied: numba==0.60.0 in /usr/local/lib/python3.12/dist-packages (from -r CLAD/requirements.txt (line 2)) (0.60.0)\n",
            "Requirement already satisfied: librosa>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from -r CLAD/requirements.txt (line 3)) (0.11.0)\n",
            "Collecting matplotlib==3.8.4 (from -r CLAD/requirements.txt (line 4))\n",
            "  Downloading matplotlib-3.8.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.12/dist-packages (from -r CLAD/requirements.txt (line 5)) (1.26.4)\n",
            "Collecting primePy==1.3 (from -r CLAD/requirements.txt (line 6))\n",
            "  Downloading primePy-1.3-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting torchcontrib (from -r CLAD/requirements.txt (line 7))\n",
            "  Downloading torchcontrib-0.0.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting pytorch_model_summary (from -r CLAD/requirements.txt (line 8))\n",
            "  Downloading pytorch_model_summary-0.1.2-py3-none-any.whl.metadata (35 kB)\n",
            "Collecting torchinfo (from -r CLAD/requirements.txt (line 9))\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.8.4->-r CLAD/requirements.txt (line 4)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.8.4->-r CLAD/requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.8.4->-r CLAD/requirements.txt (line 4)) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.8.4->-r CLAD/requirements.txt (line 4)) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.8.4->-r CLAD/requirements.txt (line 4)) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.8.4->-r CLAD/requirements.txt (line 4)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.8.4->-r CLAD/requirements.txt (line 4)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.8.4->-r CLAD/requirements.txt (line 4)) (2.9.0.post0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (1.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (4.15.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (1.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (2.3.1+cu121)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (2.32.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib==3.8.4->-r CLAD/requirements.txt (line 4)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (2025.10.5)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa>=0.11.0->-r CLAD/requirements.txt (line 3)) (2.23)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (3.20.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (2.8.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch->pytorch_model_summary->-r CLAD/requirements.txt (line 8)) (1.3.0)\n",
            "Downloading matplotlib-3.8.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 11.6/11.6 MB 26.0 MB/s  0:00:00\n",
            "Downloading primePy-1.3-py3-none-any.whl (4.0 kB)\n",
            "Downloading pytorch_model_summary-0.1.2-py3-none-any.whl (9.3 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: torchcontrib\n",
            "  Building wheel for torchcontrib (setup.py): started\n",
            "  Building wheel for torchcontrib (setup.py): finished with status 'done'\n",
            "  Created wheel for torchcontrib: filename=torchcontrib-0.0.2-py3-none-any.whl size=7516 sha256=774766d9e21d8ee7859ee4969dcd149a807a472b3a48c732f45c7f91c337a05a\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/d1/1f/63f00ffea223db446943147a04ff035eb40d00cec3e87d63e5\n",
            "Successfully built torchcontrib\n",
            "Installing collected packages: torchcontrib, primePy, torchinfo, matplotlib, pytorch_model_summary\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "\n",
            "Successfully installed matplotlib-3.8.4 primePy-1.3 pytorch_model_summary-0.1.2 torchcontrib-0.0.2 torchinfo-1.8.0\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:2 https://cli.github.com/packages stable InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,812 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,287 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,374 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,594 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,988 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,778 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [69.2 kB]\n",
            "Fetched 25.3 MB in 3s (9,741 kB/s)\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "libsndfile1 is already the newest version (1.0.31-2ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
            "===== DONE: Environment pinned for Python 3.12 =====\n",
            "Python 3.12.12\n",
            "Python: 3.12.12\n",
            "NumPy: 1.26.4\n",
            "Numba: 0.60.0\n",
            "llvmlite: 0.43.0\n",
            "Matplotlib: 3.8.4\n",
            "torch: 2.3.1+cu121\n",
            "torchvision: 0.18.1+cu121\n",
            "torchaudio: 2.3.1+cu121\n",
            "librosa: 0.11.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning into 'CLAD'...\n",
            "  DEPRECATION: Building 'torchcontrib' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'torchcontrib'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4\n",
        "#Creating a differnet folder called my_audio so we won't destroy the data created\n",
        "\n",
        "import os, pathlib, shutil\n",
        "\n",
        "# Destination base folders\n",
        "REAL_DST = pathlib.Path(\"/content/my_audio/real\")\n",
        "TXT_DST  = pathlib.Path(\"/content/my_audio/txt\")\n",
        "FAKE_DST = pathlib.Path(\"/content/my_audio/fake\")\n",
        "\n",
        "REAL_DST.mkdir(parents=True, exist_ok=True)\n",
        "TXT_DST.mkdir(parents=True, exist_ok=True)\n",
        "FAKE_DST.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Source folders\n",
        "FAKE_SRC = pathlib.Path(\"/content/vctk_samples/VCTK-Corpus/VCTK-Corpus/fake_audio\")\n",
        "TXT_SRC  = pathlib.Path(\"/content/vctk_samples/VCTK-Corpus/VCTK-Corpus/txt\")\n",
        "REAL_SRC = pathlib.Path(\"/content/vctk_samples/VCTK-Corpus/VCTK-Corpus/wav48\")\n",
        "\n",
        "# Copy FAKE wavs while keeping speaker folders\n",
        "for folder in FAKE_SRC.glob(\"p*\"):\n",
        "    speaker_dst = FAKE_DST / folder.name\n",
        "    speaker_dst.mkdir(parents=True, exist_ok=True)\n",
        "    for wav in folder.glob(\"*.wav\"):\n",
        "        shutil.copy(wav, speaker_dst / wav.name)\n",
        "\n",
        "# Copy REAL wavs while keeping speaker folders\n",
        "for folder in REAL_SRC.glob(\"p*\"):\n",
        "    speaker_dst = REAL_DST / folder.name\n",
        "    speaker_dst.mkdir(parents=True, exist_ok=True)\n",
        "    for wav in folder.glob(\"*.wav\"):\n",
        "        shutil.copy(wav, speaker_dst / wav.name)\n",
        "\n",
        "# Copy TXT transcripts (flat, no subfolders in original)\n",
        "for folder in TXT_SRC.glob(\"p*\"):\n",
        "    speaker_dst = TXT_DST / folder.name\n",
        "    speaker_dst.mkdir(parents=True, exist_ok=True)\n",
        "    for txt in TXT_SRC.glob(\"*.txt\"):\n",
        "        shutil.copy(txt, TXT_DST / txt.name)\n",
        "\n",
        "print(\"âœ… All files copied with speaker folder structure preserved!\")\n",
        "print(\"  Real :\", REAL_DST)\n",
        "print(\"  Fake :\", FAKE_DST)\n",
        "print(\"  Text :\", TXT_DST)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGDTDGCmYbTT",
        "outputId": "3c3bddf5-434c-43ed-f717-1815e29e1e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… All files copied with speaker folder structure preserved!\n",
            "  Real : /content/my_audio/real\n",
            "  Fake : /content/my_audio/fake\n",
            "  Text : /content/my_audio/txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#7\n",
        "# Speaker-disjoint splitter with:\n",
        "# - guaranteed non-empty val\n",
        "# - easy \"switch speakers\" controls\n",
        "# - deletes old OUT folder before writing\n",
        "#\n",
        "# Works for both 4 speakers (auto 2/1/1) and 5+ speakers (targets 3/1/1 by speakers).\n",
        "\n",
        "import os, shutil, random, glob, csv, itertools\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "# ---------- CONFIG ----------\n",
        "ROOT = Path(\"/content/my_audio\")           # your current data root (real/fake/{speaker}/*.wav)\n",
        "OUT  = Path(\"/content/my_audio_split\")     # split will be (re)created here\n",
        "AUDIO_EXTS = {\".wav\", \".flac\", \".mp3\", \".m4a\", \".aac\", \".ogg\"}  # add if needed\n",
        "SEED = 42\n",
        "USE_SYMLINKS = True                        # False = copy files instead of symlink\n",
        "REQUIRE_BOTH_CLASSES = True                # speakers must exist under BOTH real/ and fake/\n",
        "# Desired speaker counts (train/val/test)\n",
        "DESIRED_311 = (3, 1, 1)                    # prefer 3/1/1 when you have â‰¥5 speakers\n",
        "FALLBACK_211 = (2, 1, 1)                   # for 4 speakers, this is the safe split\n",
        "# >>> Force specific speakers into splits (edit these to \"switch\")\n",
        "TRAIN_FORCE = set()                        # e.g., {\"p226\",\"p227\",\"p228\"}\n",
        "VAL_FORCE   = set()                        # e.g., {\"p225\"}\n",
        "TEST_FORCE  = set()                        # e.g., {\"p229\"}\n",
        "# --------------------------------------\n",
        "\n",
        "random.seed(SEED)\n",
        "\n",
        "def list_speakers(root, cls):\n",
        "    base = root/cls\n",
        "    if not base.exists(): return []\n",
        "    return sorted([d.name for d in base.iterdir() if d.is_dir() and d.name != \"txt\"])\n",
        "\n",
        "def list_audio(dirpath):\n",
        "    return sorted([p for p in dirpath.rglob(\"*\")\n",
        "                   if p.is_file() and p.suffix.lower() in AUDIO_EXTS])\n",
        "\n",
        "# 1) Find eligible speakers (present and non-empty under both classes if required)\n",
        "real_spk = set(list_speakers(ROOT, \"real\"))\n",
        "fake_spk = set(list_speakers(ROOT, \"fake\"))\n",
        "if REQUIRE_BOTH_CLASSES:\n",
        "    eligible = sorted(real_spk & fake_spk)\n",
        "else:\n",
        "    eligible = sorted(real_spk | fake_spk)\n",
        "\n",
        "def nonempty_both(s):\n",
        "    if not REQUIRE_BOTH_CLASSES:  # just need at least one side non-empty\n",
        "        return (len(list_audio(ROOT/\"real\"/s)) + len(list_audio(ROOT/\"fake\"/s))) > 0\n",
        "    return len(list_audio(ROOT/\"real\"/s)) > 0 and len(list_audio(ROOT/\"fake\"/s)) > 0\n",
        "\n",
        "eligible = [s for s in eligible if nonempty_both(s)]\n",
        "n_spk = len(eligible)\n",
        "if n_spk < 2:\n",
        "    raise RuntimeError(f\"Need â‰¥2 eligible speakers, found {n_spk}: {eligible}\")\n",
        "\n",
        "# 2) Choose target split sizes by number of speakers\n",
        "if n_spk >= sum(DESIRED_311):\n",
        "    N_TRAIN, N_VAL, N_TEST = DESIRED_311   # 3/1/1\n",
        "else:\n",
        "    # With 4 speakers, 2/1/1 is the right shape to keep val+test non-empty\n",
        "    N_TRAIN, N_VAL, N_TEST = FALLBACK_211  # 2/1/1\n",
        "\n",
        "# 3) Validate FORCE sets and fill remaining slots\n",
        "forced = TRAIN_FORCE | VAL_FORCE | TEST_FORCE\n",
        "if forced:\n",
        "    missing = forced - set(eligible)\n",
        "    if missing:\n",
        "        raise RuntimeError(f\"Forced speakers not found/eligible: {sorted(missing)}\")\n",
        "    overlap = (TRAIN_FORCE & VAL_FORCE) | (TRAIN_FORCE & TEST_FORCE) | (VAL_FORCE & TEST_FORCE)\n",
        "    if overlap:\n",
        "        raise RuntimeError(f\"Forced sets overlap: {sorted(overlap)}\")\n",
        "\n",
        "# file counts (use 'real' side as proxy for per-speaker volume)\n",
        "spk_counts = {s: len(list_audio(ROOT/\"real\"/s)) for s in eligible}\n",
        "total_files = sum(spk_counts.values())\n",
        "\n",
        "def pick_k_closest(candidates, k, target_share):\n",
        "    \"\"\"Pick k speakers whose file-count sum is closest to target_share (in files).\"\"\"\n",
        "    if k <= 0: return set()\n",
        "    if len(candidates) <= k: return set(candidates)\n",
        "    best, gap = None, float(\"inf\")\n",
        "    for combo in itertools.combinations(candidates, k):\n",
        "        share = sum(spk_counts[s] for s in combo)\n",
        "        g = abs(share - target_share)\n",
        "        if g < gap:\n",
        "            gap, best = g, set(combo)\n",
        "    return best\n",
        "\n",
        "# Start with forced\n",
        "train_set, val_set, test_set = set(TRAIN_FORCE), set(VAL_FORCE), set(TEST_FORCE)\n",
        "remaining = [s for s in eligible if s not in (train_set | val_set | test_set)]\n",
        "\n",
        "need_train = max(0, N_TRAIN - len(train_set))\n",
        "need_val   = max(0, N_VAL   - len(val_set))\n",
        "need_test  = max(0, N_TEST  - len(test_set))\n",
        "\n",
        "# Target train file share (rough guideline): ~60% if 3/1/1, ~50% if 2/1/1\n",
        "target_train_share = 0.60*total_files if (N_TRAIN, N_VAL, N_TEST) == DESIRED_311 else 0.50*total_files\n",
        "\n",
        "# Fill TRAIN first to hit the share as best as possible\n",
        "if need_train > 0:\n",
        "    add = pick_k_closest(remaining, need_train, target_train_share - sum(spk_counts[s] for s in train_set))\n",
        "    train_set |= add\n",
        "    remaining = [s for s in remaining if s not in add]\n",
        "\n",
        "# Fill VAL with lighter speakers (to keep val/test similar size)\n",
        "if need_val > 0:\n",
        "    remaining.sort(key=lambda s: spk_counts[s])  # lightest first\n",
        "    add = set(remaining[:need_val])\n",
        "    val_set |= add\n",
        "    remaining = remaining[need_val:]\n",
        "\n",
        "# Fill TEST with the rest needed\n",
        "if need_test > 0:\n",
        "    add = set(remaining[:need_test])\n",
        "    test_set |= add\n",
        "    remaining = remaining[need_test:]\n",
        "\n",
        "# Final sanity: exact sizes, disjointness\n",
        "if not (len(train_set) == N_TRAIN and len(val_set) == N_VAL and len(test_set) == N_TEST):\n",
        "    raise RuntimeError(f\"Final sizes must be {N_TRAIN}/{N_VAL}/{N_TEST}, got {len(train_set)}/{len(val_set)}/{len(test_set)}\")\n",
        "if not (train_set.isdisjoint(val_set) and train_set.isdisjoint(test_set) and val_set.isdisjoint(test_set)):\n",
        "    raise RuntimeError(\"Splits are not disjoint by speakers.\")\n",
        "\n",
        "print(\"Eligible speakers:\", eligible)\n",
        "print(\"Chosen split (by speakers):\")\n",
        "print(\"  train:\", sorted(train_set))\n",
        "print(\"  val  :\", sorted(val_set))\n",
        "print(\"  test :\", sorted(test_set))\n",
        "print(\"By-file shares (train/val/test):\",\n",
        "      round(sum(spk_counts[s] for s in train_set)/total_files, 3),\n",
        "      round(sum(spk_counts[s] for s in val_set)/total_files, 3),\n",
        "      round(sum(spk_counts[s] for s in test_set)/total_files, 3))\n",
        "\n",
        "# 4) DELETE OLD OUT (so the previous no-val split is removed), then rebuild\n",
        "if OUT.exists():\n",
        "    shutil.rmtree(OUT)\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    for cls in [\"real\", \"fake\"]:\n",
        "        (OUT/split/cls).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def which_split(speaker):\n",
        "    if speaker in train_set: return \"train\"\n",
        "    if speaker in val_set:   return \"val\"\n",
        "    return \"test\"\n",
        "\n",
        "# 5) Materialize split (symlink/copy) + manifest\n",
        "rows, counts = [], defaultdict(int)\n",
        "for cls in [\"real\", \"fake\"]:\n",
        "    base = ROOT/cls\n",
        "    for sp in (train_set | val_set | test_set):\n",
        "        src_dir = base/sp\n",
        "        dst_dir = OUT/which_split(sp)/cls/sp\n",
        "        dst_dir.mkdir(parents=True, exist_ok=True)\n",
        "        for src in list_audio(src_dir):\n",
        "            dst = dst_dir/src.name\n",
        "            if dst.exists():\n",
        "                try: dst.unlink()\n",
        "                except: pass\n",
        "            if USE_SYMLINKS:\n",
        "                try:\n",
        "                    os.symlink(src.resolve(), dst)\n",
        "                except FileExistsError:\n",
        "                    pass\n",
        "            else:\n",
        "                shutil.copy2(src, dst)\n",
        "            rows.append({\n",
        "                \"split\": which_split(sp),\n",
        "                \"speaker\": sp,\n",
        "                \"label\": 0 if cls==\"real\" else 1,\n",
        "                \"src_path\": str(src.resolve()),\n",
        "                \"dst_path\": str(dst.resolve())\n",
        "            })\n",
        "            counts[(which_split(sp), cls)] += 1\n",
        "\n",
        "manifest_csv = OUT/\"manifest.csv\"\n",
        "with open(manifest_csv, \"w\", newline=\"\") as f:\n",
        "    writer = csv.DictWriter(f, fieldnames=[\"split\",\"speaker\",\"label\",\"src_path\",\"dst_path\"])\n",
        "    writer.writeheader(); writer.writerows(rows)\n",
        "\n",
        "print(\"\\nManifest:\", manifest_csv)\n",
        "print(\"Counts per split/class:\")\n",
        "for split in [\"train\",\"val\",\"test\"]:\n",
        "    for cls in [\"real\",\"fake\"]:\n",
        "        print(f\"  {split:5s} {cls:4s}: {counts[(split, cls)]}\")\n",
        "\n",
        "# Extra safety: show speaker overlap (should be empty)\n",
        "print(\"\\nOverlap checks (should be empty):\")\n",
        "print(\"  train âˆ© val :\", train_set & val_set)\n",
        "print(\"  train âˆ© test:\", train_set & test_set)\n",
        "print(\"  val   âˆ© test:\", val_set & test_set)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHwvFTkYY4Ba",
        "outputId": "4baaf4ec-cab7-49ac-b59e-3c309584497e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eligible speakers: ['p225', 'p226', 'p227', 'p228']\n",
            "Chosen split (by speakers):\n",
            "  train: ['p225', 'p227']\n",
            "  val  : ['p226']\n",
            "  test : ['p228']\n",
            "By-file shares (train/val/test): 0.462 0.265 0.273\n",
            "\n",
            "Manifest: /content/my_audio_split/manifest.csv\n",
            "Counts per split/class:\n",
            "  train real: 620\n",
            "  train fake: 620\n",
            "  val   real: 356\n",
            "  val   fake: 356\n",
            "  test  real: 366\n",
            "  test  fake: 366\n",
            "\n",
            "Overlap checks (should be empty):\n",
            "  train âˆ© val : set()\n",
            "  train âˆ© test: set()\n",
            "  val   âˆ© test: set()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#6\n",
        "# Choose ONE of the two options below:\n",
        "\n",
        "USE_LIBROSA = True   # set to False to use scipy.io.wavfile only\n",
        "\n",
        "if USE_LIBROSA:\n",
        "    # Librosa path: convenient resample-to-16k + mono in one call\n",
        "    !pip -q install librosa soundfile\n",
        "else:\n",
        "    # Scipy path: no extra system libs; we will do a small numpy resample\n",
        "    !pip -q install scipy"
      ],
      "metadata": {
        "id": "SQIRMktSh-TU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# Preprocess audio with torchaudio: 16kHz mono + pad/trim to 64600\n",
        "# =========================================\n",
        "from pathlib import Path\n",
        "import torchaudio, torch, torch.nn.functional as F\n",
        "\n",
        "TARGET_SR = 16000\n",
        "TARGET_LEN = 64600  # ~4 seconds at 16kHz\n",
        "\n",
        "def preprocess_wav_torch(in_path: Path):\n",
        "    wav, sr = torchaudio.load(str(in_path))   # [C,T]\n",
        "    wav = wav.float()\n",
        "    if wav.shape[0] > 1:\n",
        "        wav = wav.mean(dim=0, keepdim=True)   # [1,T]\n",
        "    if sr != TARGET_SR:\n",
        "        res = torchaudio.transforms.Resample(orig_freq=sr, new_freq=TARGET_SR)\n",
        "        wav = res(wav)                         # [1,T']\n",
        "    T = wav.shape[-1]\n",
        "    if T < TARGET_LEN:\n",
        "        wav = F.pad(wav, (0, TARGET_LEN - T))\n",
        "    else:\n",
        "        wav = wav[..., :TARGET_LEN]\n",
        "    return wav.squeeze(0), TARGET_SR          # [T], 16000\n",
        "\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    split_dir = Path(\"/content/my_audio_split\") / split\n",
        "    for cls in [\"real\", \"fake\"]:\n",
        "        for wav_path in (split_dir/cls).rglob(\"*.wav\"):\n",
        "            wav, sr = preprocess_wav_torch(wav_path)\n",
        "            torchaudio.save(str(wav_path), wav.unsqueeze(0), sr)  # overwrite in place\n",
        "\n",
        "print(\"âœ… All audio preprocessed to 16kHz and padded/clipped to 64600 samples (torchaudio)\")\n"
      ],
      "metadata": {
        "id": "wNTVqDPYiGZ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f6e6e9b-6a0d-431f-fdc3-59503a0a5be6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  def dispatcher(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:247: UserWarning: torio.io._streaming_media_encoder.StreamingMediaEncoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamWriter(uri, format=muxer, buffer_size=buffer_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… All audio preprocessed to 16kHz and padded/clipped to 64600 samples (torchaudio)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === DIAG A: ×‘×“×™×§×ª ×¡×‘×™×‘×” ×‘×¡×™×¡×™×ª ===\n",
        "import numpy as np, scipy, torch, torchaudio, platform\n",
        "print(\"python:\", platform.python_version())\n",
        "print(\"numpy :\", np.__version__)\n",
        "print(\"scipy :\", scipy.__version__)\n",
        "print(\"torch :\", torch.__version__)\n",
        "print(\"torchaudio:\", torchaudio.__version__)\n",
        "\n",
        "# ××‘×—×Ÿ ABI ×œ-numpy.random (×× ×–×” × ×•×¤×œ -> ABI ×©×‘×•×¨)\n",
        "from numpy.random import RandomState\n",
        "_ = RandomState(0)\n",
        "print(\"âœ… numpy.random ABI OK\")\n"
      ],
      "metadata": {
        "id": "LfspLOTwmK8g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ed46790-36fe-4d12-ee6f-aafe2ac4b504"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python: 3.12.12\n",
            "numpy : 1.26.4\n",
            "scipy : 1.13.1\n",
            "torch : 2.8.0+cu126\n",
            "torchaudio: 2.8.0+cu126\n",
            "âœ… numpy.random ABI OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8\n",
        "import torch\n",
        "from pathlib import Path\n",
        "import os\n",
        "os.chdir('/content/CLAD')\n",
        "\n",
        "from Model import MoCo_v2, RawNetEncoderBaseline\n",
        "\n",
        "# Step 1: Define the RawNet encoder configuration\n",
        "d_args = {\n",
        "    \"in_channels\": 1,\n",
        "    \"first_conv\": 251,\n",
        "    \"filts\": [\n",
        "        128,  # output channels for sinc conv\n",
        "        [128, 128],  # block0 and block1\n",
        "        [128, 256],  # block2\n",
        "        [256, 256]   # block3-5\n",
        "    ],\n",
        "    \"nb_fc_node\": 1024,\n",
        "    \"gru_node\": 1024,\n",
        "    \"nb_gru_layer\": 3,\n",
        "    \"nb_classes\": 2\n",
        "}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Step 2: Create both encoders\n",
        "encoder_q = RawNetEncoderBaseline(d_args, device)\n",
        "encoder_k = RawNetEncoderBaseline(d_args, device)\n",
        "\n",
        "# Step 3: Create the MoCo_v2 model\n",
        "model = MoCo_v2(\n",
        "    encoder_q=encoder_q,\n",
        "    encoder_k=encoder_k,\n",
        "    queue_feature_dim=1024,  # matches encoder output\n",
        "    mlp=True,\n",
        "    return_q=True\n",
        ")\n",
        "\n",
        "# Step 4: Load pretrained weights\n",
        "ckpt_path = Path(\"pretrained_models/CLAD_150_10_2310.pth.tar\")\n",
        "if not ckpt_path.exists():\n",
        "    raise FileNotFoundError(f\"Checkpoint not found: {ckpt_path}\")\n",
        "\n",
        "ckpt = torch.load(ckpt_path, map_location='cpu')\n",
        "state_dict = ckpt.get(\"state_dict\", ckpt)\n",
        "\n",
        "missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
        "print(\"Missing keys:\", missing_keys)\n",
        "print(\"Unexpected keys:\", unexpected_keys)\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(\"CLAD model loaded and ready.\")\n",
        "\n",
        "SR = 16000\n",
        "CLIP_SECONDS = 4.0\n",
        "N_SAMPLES = int(SR * CLIP_SECONDS)  # = 64000\n",
        "\n",
        "with torch.no_grad():\n",
        "    dummy = torch.randn(2, N_SAMPLES, device=device)  # (B,T)\n",
        "    try:\n",
        "        f = encoder_q(dummy)              # try (B,T)\n",
        "    except Exception:\n",
        "        f = encoder_q(dummy.unsqueeze(1)) # fallback (B,1,T)\n",
        "\n",
        "    # Pool any extra time/freq dims so we have (B,D)\n",
        "    if f.dim() == 3:\n",
        "        f = f.mean(dim=2)                 # (B,D)\n",
        "    elif f.dim() > 3:\n",
        "        f = f.mean(dim=tuple(range(2, f.dim())))  # reduce to (B,D)\n",
        "\n",
        "    print(\"Encoder output shape:\", tuple(f.shape))\n",
        "    D = f.shape[1]\n",
        "    print(\"Probed feature dim D =\", D)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TaUUxo-Ym-bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03d3d2bd-0d3d-41bb-af08-601ede5e4d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing keys: ['encoder_q.first_bn.weight', 'encoder_q.first_bn.bias', 'encoder_q.first_bn.running_mean', 'encoder_q.first_bn.running_var', 'encoder_q.block0.0.conv1.weight', 'encoder_q.block0.0.conv1.bias', 'encoder_q.block0.0.bn2.weight', 'encoder_q.block0.0.bn2.bias', 'encoder_q.block0.0.bn2.running_mean', 'encoder_q.block0.0.bn2.running_var', 'encoder_q.block0.0.conv2.weight', 'encoder_q.block0.0.conv2.bias', 'encoder_q.block1.0.bn1.weight', 'encoder_q.block1.0.bn1.bias', 'encoder_q.block1.0.bn1.running_mean', 'encoder_q.block1.0.bn1.running_var', 'encoder_q.block1.0.conv1.weight', 'encoder_q.block1.0.conv1.bias', 'encoder_q.block1.0.bn2.weight', 'encoder_q.block1.0.bn2.bias', 'encoder_q.block1.0.bn2.running_mean', 'encoder_q.block1.0.bn2.running_var', 'encoder_q.block1.0.conv2.weight', 'encoder_q.block1.0.conv2.bias', 'encoder_q.block2.0.bn1.weight', 'encoder_q.block2.0.bn1.bias', 'encoder_q.block2.0.bn1.running_mean', 'encoder_q.block2.0.bn1.running_var', 'encoder_q.block2.0.conv1.weight', 'encoder_q.block2.0.conv1.bias', 'encoder_q.block2.0.bn2.weight', 'encoder_q.block2.0.bn2.bias', 'encoder_q.block2.0.bn2.running_mean', 'encoder_q.block2.0.bn2.running_var', 'encoder_q.block2.0.conv2.weight', 'encoder_q.block2.0.conv2.bias', 'encoder_q.block2.0.conv_downsample.weight', 'encoder_q.block2.0.conv_downsample.bias', 'encoder_q.block3.0.bn1.weight', 'encoder_q.block3.0.bn1.bias', 'encoder_q.block3.0.bn1.running_mean', 'encoder_q.block3.0.bn1.running_var', 'encoder_q.block3.0.conv1.weight', 'encoder_q.block3.0.conv1.bias', 'encoder_q.block3.0.bn2.weight', 'encoder_q.block3.0.bn2.bias', 'encoder_q.block3.0.bn2.running_mean', 'encoder_q.block3.0.bn2.running_var', 'encoder_q.block3.0.conv2.weight', 'encoder_q.block3.0.conv2.bias', 'encoder_q.block4.0.bn1.weight', 'encoder_q.block4.0.bn1.bias', 'encoder_q.block4.0.bn1.running_mean', 'encoder_q.block4.0.bn1.running_var', 'encoder_q.block4.0.conv1.weight', 'encoder_q.block4.0.conv1.bias', 'encoder_q.block4.0.bn2.weight', 'encoder_q.block4.0.bn2.bias', 'encoder_q.block4.0.bn2.running_mean', 'encoder_q.block4.0.bn2.running_var', 'encoder_q.block4.0.conv2.weight', 'encoder_q.block4.0.conv2.bias', 'encoder_q.block5.0.bn1.weight', 'encoder_q.block5.0.bn1.bias', 'encoder_q.block5.0.bn1.running_mean', 'encoder_q.block5.0.bn1.running_var', 'encoder_q.block5.0.conv1.weight', 'encoder_q.block5.0.conv1.bias', 'encoder_q.block5.0.bn2.weight', 'encoder_q.block5.0.bn2.bias', 'encoder_q.block5.0.bn2.running_mean', 'encoder_q.block5.0.bn2.running_var', 'encoder_q.block5.0.conv2.weight', 'encoder_q.block5.0.conv2.bias', 'encoder_q.fc_attention0.0.weight', 'encoder_q.fc_attention0.0.bias', 'encoder_q.fc_attention1.0.weight', 'encoder_q.fc_attention1.0.bias', 'encoder_q.fc_attention2.0.weight', 'encoder_q.fc_attention2.0.bias', 'encoder_q.fc_attention3.0.weight', 'encoder_q.fc_attention3.0.bias', 'encoder_q.fc_attention4.0.weight', 'encoder_q.fc_attention4.0.bias', 'encoder_q.fc_attention5.0.weight', 'encoder_q.fc_attention5.0.bias', 'encoder_q.bn_before_gru.weight', 'encoder_q.bn_before_gru.bias', 'encoder_q.bn_before_gru.running_mean', 'encoder_q.bn_before_gru.running_var', 'encoder_q.gru.weight_ih_l0', 'encoder_q.gru.weight_hh_l0', 'encoder_q.gru.bias_ih_l0', 'encoder_q.gru.bias_hh_l0', 'encoder_q.gru.weight_ih_l1', 'encoder_q.gru.weight_hh_l1', 'encoder_q.gru.bias_ih_l1', 'encoder_q.gru.bias_hh_l1', 'encoder_q.gru.weight_ih_l2', 'encoder_q.gru.weight_hh_l2', 'encoder_q.gru.bias_ih_l2', 'encoder_q.gru.bias_hh_l2', 'encoder_q.fc1_gru.weight', 'encoder_q.fc1_gru.bias', 'encoder_q.fc2_gru.weight', 'encoder_q.fc2_gru.bias', 'encoder_k.first_bn.weight', 'encoder_k.first_bn.bias', 'encoder_k.first_bn.running_mean', 'encoder_k.first_bn.running_var', 'encoder_k.block0.0.conv1.weight', 'encoder_k.block0.0.conv1.bias', 'encoder_k.block0.0.bn2.weight', 'encoder_k.block0.0.bn2.bias', 'encoder_k.block0.0.bn2.running_mean', 'encoder_k.block0.0.bn2.running_var', 'encoder_k.block0.0.conv2.weight', 'encoder_k.block0.0.conv2.bias', 'encoder_k.block1.0.bn1.weight', 'encoder_k.block1.0.bn1.bias', 'encoder_k.block1.0.bn1.running_mean', 'encoder_k.block1.0.bn1.running_var', 'encoder_k.block1.0.conv1.weight', 'encoder_k.block1.0.conv1.bias', 'encoder_k.block1.0.bn2.weight', 'encoder_k.block1.0.bn2.bias', 'encoder_k.block1.0.bn2.running_mean', 'encoder_k.block1.0.bn2.running_var', 'encoder_k.block1.0.conv2.weight', 'encoder_k.block1.0.conv2.bias', 'encoder_k.block2.0.bn1.weight', 'encoder_k.block2.0.bn1.bias', 'encoder_k.block2.0.bn1.running_mean', 'encoder_k.block2.0.bn1.running_var', 'encoder_k.block2.0.conv1.weight', 'encoder_k.block2.0.conv1.bias', 'encoder_k.block2.0.bn2.weight', 'encoder_k.block2.0.bn2.bias', 'encoder_k.block2.0.bn2.running_mean', 'encoder_k.block2.0.bn2.running_var', 'encoder_k.block2.0.conv2.weight', 'encoder_k.block2.0.conv2.bias', 'encoder_k.block2.0.conv_downsample.weight', 'encoder_k.block2.0.conv_downsample.bias', 'encoder_k.block3.0.bn1.weight', 'encoder_k.block3.0.bn1.bias', 'encoder_k.block3.0.bn1.running_mean', 'encoder_k.block3.0.bn1.running_var', 'encoder_k.block3.0.conv1.weight', 'encoder_k.block3.0.conv1.bias', 'encoder_k.block3.0.bn2.weight', 'encoder_k.block3.0.bn2.bias', 'encoder_k.block3.0.bn2.running_mean', 'encoder_k.block3.0.bn2.running_var', 'encoder_k.block3.0.conv2.weight', 'encoder_k.block3.0.conv2.bias', 'encoder_k.block4.0.bn1.weight', 'encoder_k.block4.0.bn1.bias', 'encoder_k.block4.0.bn1.running_mean', 'encoder_k.block4.0.bn1.running_var', 'encoder_k.block4.0.conv1.weight', 'encoder_k.block4.0.conv1.bias', 'encoder_k.block4.0.bn2.weight', 'encoder_k.block4.0.bn2.bias', 'encoder_k.block4.0.bn2.running_mean', 'encoder_k.block4.0.bn2.running_var', 'encoder_k.block4.0.conv2.weight', 'encoder_k.block4.0.conv2.bias', 'encoder_k.block5.0.bn1.weight', 'encoder_k.block5.0.bn1.bias', 'encoder_k.block5.0.bn1.running_mean', 'encoder_k.block5.0.bn1.running_var', 'encoder_k.block5.0.conv1.weight', 'encoder_k.block5.0.conv1.bias', 'encoder_k.block5.0.bn2.weight', 'encoder_k.block5.0.bn2.bias', 'encoder_k.block5.0.bn2.running_mean', 'encoder_k.block5.0.bn2.running_var', 'encoder_k.block5.0.conv2.weight', 'encoder_k.block5.0.conv2.bias', 'encoder_k.fc_attention0.0.weight', 'encoder_k.fc_attention0.0.bias', 'encoder_k.fc_attention1.0.weight', 'encoder_k.fc_attention1.0.bias', 'encoder_k.fc_attention2.0.weight', 'encoder_k.fc_attention2.0.bias', 'encoder_k.fc_attention3.0.weight', 'encoder_k.fc_attention3.0.bias', 'encoder_k.fc_attention4.0.weight', 'encoder_k.fc_attention4.0.bias', 'encoder_k.fc_attention5.0.weight', 'encoder_k.fc_attention5.0.bias', 'encoder_k.bn_before_gru.weight', 'encoder_k.bn_before_gru.bias', 'encoder_k.bn_before_gru.running_mean', 'encoder_k.bn_before_gru.running_var', 'encoder_k.gru.weight_ih_l0', 'encoder_k.gru.weight_hh_l0', 'encoder_k.gru.bias_ih_l0', 'encoder_k.gru.bias_hh_l0', 'encoder_k.gru.weight_ih_l1', 'encoder_k.gru.weight_hh_l1', 'encoder_k.gru.bias_ih_l1', 'encoder_k.gru.bias_hh_l1', 'encoder_k.gru.weight_ih_l2', 'encoder_k.gru.weight_hh_l2', 'encoder_k.gru.bias_ih_l2', 'encoder_k.gru.bias_hh_l2', 'encoder_k.fc1_gru.weight', 'encoder_k.fc1_gru.bias', 'encoder_k.fc2_gru.weight', 'encoder_k.fc2_gru.bias', 'projection_head_q.0.weight', 'projection_head_q.0.bias', 'projection_head_q.2.weight', 'projection_head_q.2.bias', 'projection_head_k.0.weight', 'projection_head_k.0.bias', 'projection_head_k.2.weight', 'projection_head_k.2.bias']\n",
            "Unexpected keys: ['encoder.pos_S', 'encoder.master1', 'encoder.master2', 'encoder.first_bn.weight', 'encoder.first_bn.bias', 'encoder.first_bn.running_mean', 'encoder.first_bn.running_var', 'encoder.first_bn.num_batches_tracked', 'encoder.encoder.0.0.conv1.weight', 'encoder.encoder.0.0.conv1.bias', 'encoder.encoder.0.0.bn2.weight', 'encoder.encoder.0.0.bn2.bias', 'encoder.encoder.0.0.bn2.running_mean', 'encoder.encoder.0.0.bn2.running_var', 'encoder.encoder.0.0.bn2.num_batches_tracked', 'encoder.encoder.0.0.conv2.weight', 'encoder.encoder.0.0.conv2.bias', 'encoder.encoder.0.0.conv_downsample.weight', 'encoder.encoder.0.0.conv_downsample.bias', 'encoder.encoder.1.0.bn1.weight', 'encoder.encoder.1.0.bn1.bias', 'encoder.encoder.1.0.bn1.running_mean', 'encoder.encoder.1.0.bn1.running_var', 'encoder.encoder.1.0.bn1.num_batches_tracked', 'encoder.encoder.1.0.conv1.weight', 'encoder.encoder.1.0.conv1.bias', 'encoder.encoder.1.0.bn2.weight', 'encoder.encoder.1.0.bn2.bias', 'encoder.encoder.1.0.bn2.running_mean', 'encoder.encoder.1.0.bn2.running_var', 'encoder.encoder.1.0.bn2.num_batches_tracked', 'encoder.encoder.1.0.conv2.weight', 'encoder.encoder.1.0.conv2.bias', 'encoder.encoder.2.0.bn1.weight', 'encoder.encoder.2.0.bn1.bias', 'encoder.encoder.2.0.bn1.running_mean', 'encoder.encoder.2.0.bn1.running_var', 'encoder.encoder.2.0.bn1.num_batches_tracked', 'encoder.encoder.2.0.conv1.weight', 'encoder.encoder.2.0.conv1.bias', 'encoder.encoder.2.0.bn2.weight', 'encoder.encoder.2.0.bn2.bias', 'encoder.encoder.2.0.bn2.running_mean', 'encoder.encoder.2.0.bn2.running_var', 'encoder.encoder.2.0.bn2.num_batches_tracked', 'encoder.encoder.2.0.conv2.weight', 'encoder.encoder.2.0.conv2.bias', 'encoder.encoder.2.0.conv_downsample.weight', 'encoder.encoder.2.0.conv_downsample.bias', 'encoder.encoder.3.0.bn1.weight', 'encoder.encoder.3.0.bn1.bias', 'encoder.encoder.3.0.bn1.running_mean', 'encoder.encoder.3.0.bn1.running_var', 'encoder.encoder.3.0.bn1.num_batches_tracked', 'encoder.encoder.3.0.conv1.weight', 'encoder.encoder.3.0.conv1.bias', 'encoder.encoder.3.0.bn2.weight', 'encoder.encoder.3.0.bn2.bias', 'encoder.encoder.3.0.bn2.running_mean', 'encoder.encoder.3.0.bn2.running_var', 'encoder.encoder.3.0.bn2.num_batches_tracked', 'encoder.encoder.3.0.conv2.weight', 'encoder.encoder.3.0.conv2.bias', 'encoder.encoder.4.0.bn1.weight', 'encoder.encoder.4.0.bn1.bias', 'encoder.encoder.4.0.bn1.running_mean', 'encoder.encoder.4.0.bn1.running_var', 'encoder.encoder.4.0.bn1.num_batches_tracked', 'encoder.encoder.4.0.conv1.weight', 'encoder.encoder.4.0.conv1.bias', 'encoder.encoder.4.0.bn2.weight', 'encoder.encoder.4.0.bn2.bias', 'encoder.encoder.4.0.bn2.running_mean', 'encoder.encoder.4.0.bn2.running_var', 'encoder.encoder.4.0.bn2.num_batches_tracked', 'encoder.encoder.4.0.conv2.weight', 'encoder.encoder.4.0.conv2.bias', 'encoder.encoder.5.0.bn1.weight', 'encoder.encoder.5.0.bn1.bias', 'encoder.encoder.5.0.bn1.running_mean', 'encoder.encoder.5.0.bn1.running_var', 'encoder.encoder.5.0.bn1.num_batches_tracked', 'encoder.encoder.5.0.conv1.weight', 'encoder.encoder.5.0.conv1.bias', 'encoder.encoder.5.0.bn2.weight', 'encoder.encoder.5.0.bn2.bias', 'encoder.encoder.5.0.bn2.running_mean', 'encoder.encoder.5.0.bn2.running_var', 'encoder.encoder.5.0.bn2.num_batches_tracked', 'encoder.encoder.5.0.conv2.weight', 'encoder.encoder.5.0.conv2.bias', 'encoder.GAT_layer_S.att_weight', 'encoder.GAT_layer_S.att_proj.weight', 'encoder.GAT_layer_S.att_proj.bias', 'encoder.GAT_layer_S.proj_with_att.weight', 'encoder.GAT_layer_S.proj_with_att.bias', 'encoder.GAT_layer_S.proj_without_att.weight', 'encoder.GAT_layer_S.proj_without_att.bias', 'encoder.GAT_layer_S.bn.weight', 'encoder.GAT_layer_S.bn.bias', 'encoder.GAT_layer_S.bn.running_mean', 'encoder.GAT_layer_S.bn.running_var', 'encoder.GAT_layer_S.bn.num_batches_tracked', 'encoder.GAT_layer_T.att_weight', 'encoder.GAT_layer_T.att_proj.weight', 'encoder.GAT_layer_T.att_proj.bias', 'encoder.GAT_layer_T.proj_with_att.weight', 'encoder.GAT_layer_T.proj_with_att.bias', 'encoder.GAT_layer_T.proj_without_att.weight', 'encoder.GAT_layer_T.proj_without_att.bias', 'encoder.GAT_layer_T.bn.weight', 'encoder.GAT_layer_T.bn.bias', 'encoder.GAT_layer_T.bn.running_mean', 'encoder.GAT_layer_T.bn.running_var', 'encoder.GAT_layer_T.bn.num_batches_tracked', 'encoder.HtrgGAT_layer_ST11.att_weight11', 'encoder.HtrgGAT_layer_ST11.att_weight22', 'encoder.HtrgGAT_layer_ST11.att_weight12', 'encoder.HtrgGAT_layer_ST11.att_weightM', 'encoder.HtrgGAT_layer_ST11.proj_type1.weight', 'encoder.HtrgGAT_layer_ST11.proj_type1.bias', 'encoder.HtrgGAT_layer_ST11.proj_type2.weight', 'encoder.HtrgGAT_layer_ST11.proj_type2.bias', 'encoder.HtrgGAT_layer_ST11.att_proj.weight', 'encoder.HtrgGAT_layer_ST11.att_proj.bias', 'encoder.HtrgGAT_layer_ST11.att_projM.weight', 'encoder.HtrgGAT_layer_ST11.att_projM.bias', 'encoder.HtrgGAT_layer_ST11.proj_with_att.weight', 'encoder.HtrgGAT_layer_ST11.proj_with_att.bias', 'encoder.HtrgGAT_layer_ST11.proj_without_att.weight', 'encoder.HtrgGAT_layer_ST11.proj_without_att.bias', 'encoder.HtrgGAT_layer_ST11.proj_with_attM.weight', 'encoder.HtrgGAT_layer_ST11.proj_with_attM.bias', 'encoder.HtrgGAT_layer_ST11.proj_without_attM.weight', 'encoder.HtrgGAT_layer_ST11.proj_without_attM.bias', 'encoder.HtrgGAT_layer_ST11.bn.weight', 'encoder.HtrgGAT_layer_ST11.bn.bias', 'encoder.HtrgGAT_layer_ST11.bn.running_mean', 'encoder.HtrgGAT_layer_ST11.bn.running_var', 'encoder.HtrgGAT_layer_ST11.bn.num_batches_tracked', 'encoder.HtrgGAT_layer_ST12.att_weight11', 'encoder.HtrgGAT_layer_ST12.att_weight22', 'encoder.HtrgGAT_layer_ST12.att_weight12', 'encoder.HtrgGAT_layer_ST12.att_weightM', 'encoder.HtrgGAT_layer_ST12.proj_type1.weight', 'encoder.HtrgGAT_layer_ST12.proj_type1.bias', 'encoder.HtrgGAT_layer_ST12.proj_type2.weight', 'encoder.HtrgGAT_layer_ST12.proj_type2.bias', 'encoder.HtrgGAT_layer_ST12.att_proj.weight', 'encoder.HtrgGAT_layer_ST12.att_proj.bias', 'encoder.HtrgGAT_layer_ST12.att_projM.weight', 'encoder.HtrgGAT_layer_ST12.att_projM.bias', 'encoder.HtrgGAT_layer_ST12.proj_with_att.weight', 'encoder.HtrgGAT_layer_ST12.proj_with_att.bias', 'encoder.HtrgGAT_layer_ST12.proj_without_att.weight', 'encoder.HtrgGAT_layer_ST12.proj_without_att.bias', 'encoder.HtrgGAT_layer_ST12.proj_with_attM.weight', 'encoder.HtrgGAT_layer_ST12.proj_with_attM.bias', 'encoder.HtrgGAT_layer_ST12.proj_without_attM.weight', 'encoder.HtrgGAT_layer_ST12.proj_without_attM.bias', 'encoder.HtrgGAT_layer_ST12.bn.weight', 'encoder.HtrgGAT_layer_ST12.bn.bias', 'encoder.HtrgGAT_layer_ST12.bn.running_mean', 'encoder.HtrgGAT_layer_ST12.bn.running_var', 'encoder.HtrgGAT_layer_ST12.bn.num_batches_tracked', 'encoder.HtrgGAT_layer_ST21.att_weight11', 'encoder.HtrgGAT_layer_ST21.att_weight22', 'encoder.HtrgGAT_layer_ST21.att_weight12', 'encoder.HtrgGAT_layer_ST21.att_weightM', 'encoder.HtrgGAT_layer_ST21.proj_type1.weight', 'encoder.HtrgGAT_layer_ST21.proj_type1.bias', 'encoder.HtrgGAT_layer_ST21.proj_type2.weight', 'encoder.HtrgGAT_layer_ST21.proj_type2.bias', 'encoder.HtrgGAT_layer_ST21.att_proj.weight', 'encoder.HtrgGAT_layer_ST21.att_proj.bias', 'encoder.HtrgGAT_layer_ST21.att_projM.weight', 'encoder.HtrgGAT_layer_ST21.att_projM.bias', 'encoder.HtrgGAT_layer_ST21.proj_with_att.weight', 'encoder.HtrgGAT_layer_ST21.proj_with_att.bias', 'encoder.HtrgGAT_layer_ST21.proj_without_att.weight', 'encoder.HtrgGAT_layer_ST21.proj_without_att.bias', 'encoder.HtrgGAT_layer_ST21.proj_with_attM.weight', 'encoder.HtrgGAT_layer_ST21.proj_with_attM.bias', 'encoder.HtrgGAT_layer_ST21.proj_without_attM.weight', 'encoder.HtrgGAT_layer_ST21.proj_without_attM.bias', 'encoder.HtrgGAT_layer_ST21.bn.weight', 'encoder.HtrgGAT_layer_ST21.bn.bias', 'encoder.HtrgGAT_layer_ST21.bn.running_mean', 'encoder.HtrgGAT_layer_ST21.bn.running_var', 'encoder.HtrgGAT_layer_ST21.bn.num_batches_tracked', 'encoder.HtrgGAT_layer_ST22.att_weight11', 'encoder.HtrgGAT_layer_ST22.att_weight22', 'encoder.HtrgGAT_layer_ST22.att_weight12', 'encoder.HtrgGAT_layer_ST22.att_weightM', 'encoder.HtrgGAT_layer_ST22.proj_type1.weight', 'encoder.HtrgGAT_layer_ST22.proj_type1.bias', 'encoder.HtrgGAT_layer_ST22.proj_type2.weight', 'encoder.HtrgGAT_layer_ST22.proj_type2.bias', 'encoder.HtrgGAT_layer_ST22.att_proj.weight', 'encoder.HtrgGAT_layer_ST22.att_proj.bias', 'encoder.HtrgGAT_layer_ST22.att_projM.weight', 'encoder.HtrgGAT_layer_ST22.att_projM.bias', 'encoder.HtrgGAT_layer_ST22.proj_with_att.weight', 'encoder.HtrgGAT_layer_ST22.proj_with_att.bias', 'encoder.HtrgGAT_layer_ST22.proj_without_att.weight', 'encoder.HtrgGAT_layer_ST22.proj_without_att.bias', 'encoder.HtrgGAT_layer_ST22.proj_with_attM.weight', 'encoder.HtrgGAT_layer_ST22.proj_with_attM.bias', 'encoder.HtrgGAT_layer_ST22.proj_without_attM.weight', 'encoder.HtrgGAT_layer_ST22.proj_without_attM.bias', 'encoder.HtrgGAT_layer_ST22.bn.weight', 'encoder.HtrgGAT_layer_ST22.bn.bias', 'encoder.HtrgGAT_layer_ST22.bn.running_mean', 'encoder.HtrgGAT_layer_ST22.bn.running_var', 'encoder.HtrgGAT_layer_ST22.bn.num_batches_tracked', 'encoder.pool_S.proj.weight', 'encoder.pool_S.proj.bias', 'encoder.pool_T.proj.weight', 'encoder.pool_T.proj.bias', 'encoder.pool_hS1.proj.weight', 'encoder.pool_hS1.proj.bias', 'encoder.pool_hT1.proj.weight', 'encoder.pool_hT1.proj.bias', 'encoder.pool_hS2.proj.weight', 'encoder.pool_hS2.proj.bias', 'encoder.pool_hT2.proj.weight', 'encoder.pool_hT2.proj.bias', 'encoder.out_layer.weight', 'encoder.out_layer.bias', 'fc.weight', 'fc.bias']\n",
            "CLAD model loaded and ready.\n",
            "Encoder output shape: (2, 1024)\n",
            "Probed feature dim D = 1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Overfit a single batch to sanity-check gradients\n",
        "# Grab one batch\n",
        "# The content of this cell has been moved to cell LLtOZnD1rsQx to resolve the NameError."
      ],
      "metadata": {
        "id": "LzSDeeKf4WFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "from pathlib import Path\n",
        "\n",
        "def check_audio_integrity(root_dir):\n",
        "    root = Path(root_dir)\n",
        "    total_ok = 0\n",
        "    total_err = 0\n",
        "    for p in root.rglob(\"*.wav\"):\n",
        "        try:\n",
        "            # Load the waveform\n",
        "            metadata = torchaudio.info(str(p))\n",
        "            if metadata.sample_rate != 16000:\n",
        "                print(f\"âŒ Wrong SR: {p.name} at {metadata.sample_rate}Hz\")\n",
        "                total_err += 1\n",
        "            if metadata.num_channels != 1:\n",
        "                print(f\"âŒ Not Mono: {p.name} has {metadata.num_channels} channels\")\n",
        "                total_err += 1\n",
        "            if metadata.num_frames != 64600:\n",
        "                print(f\"âŒ Wrong Length: {p.name} has {metadata.num_frames} frames\")\n",
        "                total_err += 1\n",
        "            total_ok += 1\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Failed to load {p.name}: {e}\")\n",
        "            total_err += 1\n",
        "\n",
        "    print(f\"\\nSummary: {total_ok} files OK, {total_err} files failed checks.\")\n",
        "\n",
        "print(\"Checking Train Split:\")\n",
        "check_audio_integrity(\"/content/my_audio_split/train\")\n",
        "print(\"\\nChecking Validation Split:\")\n",
        "check_audio_integrity(\"/content/my_audio_split/val\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2TOKCVrLupa",
        "outputId": "d9e61c4c-8a6b-4d3f-bdd4-c6f687e63050"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking Train Split:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-477929235.py:11: UserWarning: torchaudio._backend.utils.info has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  metadata = torchaudio.info(str(p))\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:20: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:27: UserWarning: torchaudio._backend.common.AudioMetaData has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  return AudioMetaData(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary: 1240 files OK, 0 files failed checks.\n",
            "\n",
            "Checking Validation Split:\n",
            "\n",
            "Summary: 712 files OK, 0 files failed checks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (×§×•×“ ×˜×¢×™× ×ª ×”××•×“×œ ×•×”-DataLoader)\n",
        "\n",
        "# ×•×“× ×©×”××§×•×“×“ ×§×¤×•× ×œ×—×œ×•×˜×™×Ÿ\n",
        "frozen_count = sum(1 for p in encoder_q.parameters() if not p.requires_grad)\n",
        "total_count = sum(1 for p in encoder_q.parameters())\n",
        "if frozen_count != total_count:\n",
        "    print(f\"âš ï¸ ATTENTION: Only {frozen_count}/{total_count} parameters are frozen in encoder_q! Check your loop.\")\n",
        "else:\n",
        "    print(\"âœ… Encoder is fully frozen.\")\n",
        "\n",
        "# ... (×”××©×š ×”××™××•×Ÿ)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDLQm7TgMBOY",
        "outputId": "e58e56d9-c903-4680-a368-ab218cb99a20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ ATTENTION: Only 0/80 parameters are frozen in encoder_q! Check your loop.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1 =========================================\n",
        "# Fine-tuning: linear classifier on top of FROZEN encoder_q\n",
        "# (RawNet encoder_q expects input shape [B, T], not [B,1,T]!)\n",
        "# =========================================\n",
        "from pathlib import Path\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchaudio\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm # ×©×™××•×© ×‘-tqdm ×œ××¢×§×‘\n",
        "\n",
        "# 1. ×‘×“×™×§×ª ×¡×‘×™×‘×” (Environment Check)\n",
        "print(\"--- 1. ×‘×“×™×§×ª ×¡×‘×™×‘×” ×•××•×“×œ ---\")\n",
        "os.chdir('/content/CLAD')\n",
        "if not Path('Model.py').exists():\n",
        "    raise FileNotFoundError(\"ERROR: Model.py not found in /content/CLAD. Did the cloning step (#15) fail?\")\n",
        "\n",
        "from Model import MoCo_v2, RawNetEncoderBaseline\n",
        "\n",
        "# Step 1: Define the RawNet encoder configuration\n",
        "d_args = {\n",
        "    \"in_channels\": 1,\n",
        "    \"first_conv\": 251,\n",
        "    \"filts\": [128, [128, 128], [128, 256], [256, 256]],\n",
        "    \"nb_fc_node\": 1024,\n",
        "    \"gru_node\": 1024,\n",
        "    \"nb_gru_layer\": 3,\n",
        "    \"nb_classes\": 2\n",
        "}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Step 2: Create both encoders and MoCo_v2 model\n",
        "encoder_q = RawNetEncoderBaseline(d_args, device)\n",
        "encoder_k = RawNetEncoderBaseline(d_args, device)\n",
        "model = MoCo_v2(encoder_q=encoder_q, encoder_k=encoder_k, queue_feature_dim=1024, mlp=True, return_q=True)\n",
        "\n",
        "# Step 3: Load pretrained weights\n",
        "ckpt_path = Path(\"pretrained_models/CLAD_150_10_2310.pth.tar\")\n",
        "if not ckpt_path.exists():\n",
        "    raise FileNotFoundError(f\"Checkpoint not found: {ckpt_path}\")\n",
        "\n",
        "ckpt = torch.load(ckpt_path, map_location='cpu')\n",
        "state_dict = ckpt.get(\"state_dict\", ckpt)\n",
        "missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
        "print(\"CLAD model loaded and ready.\")\n",
        "\n",
        "\n",
        "# -------- Config --------\n",
        "TARGET_SR  = 16000\n",
        "TARGET_LEN = 64600\n",
        "LABELS     = {\"real\": 0, \"fake\": 1}\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS     = 8\n",
        "# LR ××ª×•×§×Ÿ\n",
        "LR         = 1e-2\n",
        "\n",
        "# -------- Dataset: returns [T] (mono 16k, fixed length) --------\n",
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, root_dir: str):\n",
        "        self.samples = []\n",
        "        root = Path(root_dir)\n",
        "        for cls in (\"real\", \"fake\"):\n",
        "            base = root / cls\n",
        "            if not base.exists():\n",
        "                raise FileNotFoundError(f\"Missing directory: {base}\")\n",
        "            for p in base.rglob(\"*.wav\"):\n",
        "                if p.is_file():\n",
        "                    self.samples.append((p, LABELS[cls]))\n",
        "        if len(self.samples) == 0:\n",
        "            raise ValueError(f\"No .wav files found under {root_dir}. Ensure split+preprocess ran correctly.\")\n",
        "        self._resamplers = {} # ×œ× × ×©×ª××© ×‘×•, ××‘×œ ××©××™×¨×™× ×œ×™×ª×¨ ×‘×˜×—×•×Ÿ\n",
        "\n",
        "    def _fix(self, path: Path) -> torch.Tensor:\n",
        "        # ×‘×’×œ×œ ×”-preprocess ×©×¨×¥ ×§×•×“×, ×§×‘×¦×™ ×”-.wav ×××•×¨×™× ×œ×”×™×•×ª ×›×‘×¨ 16k, mono ×•×‘××•×¨×š 64600.\n",
        "        # ×˜×•×¢× ×™× ××•×ª× ×›××•×ª ×©×”×.\n",
        "        wav, sr = torchaudio.load(str(path))  # [C,T]\n",
        "        wav = wav.float()\n",
        "\n",
        "        # â­ï¸ ×‘×“×™×§×” 2.1: ××™××•×ª × ×ª×•× ×™× ×¤× ×™××™ ×©×œ ×”-Dataset\n",
        "        if wav.dim() == 2 and wav.shape[0] != 1:\n",
        "             wav = wav.mean(dim=0, keepdim=True) # ×× ×œ× mono, × ×”×¤×•×š ×œ-mono\n",
        "        if sr != TARGET_SR:\n",
        "            print(f\"âš ï¸ Warning: SR mismatch on {path.name}. Actual {sr}Hz.\")\n",
        "\n",
        "        return wav.squeeze(0) # -> [T]\n",
        "\n",
        "    def __len__(self): return len(self.samples)\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.samples[idx]\n",
        "        return self._fix(path), label                 # ([T], label)\n",
        "\n",
        "# -------- DataLoaders --------\n",
        "train_ds = AudioDataset(\"/content/my_audio_split/train\")\n",
        "val_ds   = AudioDataset(\"/content/my_audio_split/val\")\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  drop_last=False)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
        "\n",
        "# -------- Freeze encoder --------\n",
        "encoder_q.to(device).eval()\n",
        "for p in encoder_q.parameters():\n",
        "    p.requires_grad = False\n",
        "encoder_q.eval().to(device)\n",
        "\n",
        "# --- 2. ×‘×“×™×§×ª ×˜×¢×™× ×ª × ×ª×•× ×™× ×•×”×¤×™×¦'×¨×™× (Feature Extraction) ---\n",
        "print(\"\\n--- 2. ×‘×“×™×§×ª ×¤×™×¦'×¨×™× (Feature Extraction) ---\")\n",
        "# ×. ××™××•×ª ×’×•×“×œ ×”-Batch ×•×¦×•×¨×ª ×”-WAV\n",
        "wavs0, labels0 = next(iter(train_loader))     # wavs0: [B, T]\n",
        "print(f\"2.1. Batch Shape: {tuple(wavs0.shape)} (Expected: [B, T])\")\n",
        "print(f\"2.2. Labels: {labels0[:5]} (Expected: [0, 1, 0, 1, ...])\")\n",
        "\n",
        "# ×‘. ×‘×“×™×§×ª ×—×™×œ×•×¥ ×¤×™×¦'×¨×™× (Encoder Forward)\n",
        "with torch.no_grad():\n",
        "    x0 = wavs0.to(device).float()               # [B, T]\n",
        "    feat0 = encoder_q(x0)                       # RawNet expects [B, T]\n",
        "\n",
        "    # Pool any extra time/freq dims\n",
        "    if feat0.dim() == 3:\n",
        "        feat0 = feat0.mean(dim=2)\n",
        "    elif feat0.dim() > 3:\n",
        "        feat0 = feat0.mean(dim=tuple(range(2, feat0.dim())))\n",
        "    D = feat0.shape[1]\n",
        "\n",
        "# ×’. ××™××•×ª ×’×•×“×œ ×”×¤×™×¦'×¨×™× ×•×”×¢×¨×›×™×\n",
        "print(f\"2.3. Feature Shape: {tuple(feat0.shape)} (Expected: [{BATCH_SIZE}, {D}])\")\n",
        "print(f\"2.4. Max Feature Value: {feat0.abs().max().item():.4f}\")\n",
        "print(f\"2.5. Feature Mean (Batch): {feat0.mean().item():.4f}\")\n",
        "if D != 1024:\n",
        "    print(f\"âš ï¸ WARNING: Probed feature dim D={D} is unexpected (Expected 1024)\")\n",
        "\n",
        "\n",
        "# --- 3. ×‘×“×™×§×ª Overfit (Linear Probe Sanity Check) ---\n",
        "print(\"\\n--- 3. ×‘×“×™×§×ª Overfit (×—×™×™×‘ ×œ×”×¦×œ×™×—) ---\")\n",
        "# × ×•×¨××œ×™×–×¦×™×” ×©×œ ×”×¤×™×¦'×¨×™× ×œ×¤× ×™ ×”-Probe\n",
        "f_norm = (feat0 - feat0.mean(dim=0, keepdim=True)) / (feat0.std(dim=0, keepdim=True) + 1e-5)\n",
        "\n",
        "probe = nn.Sequential(\n",
        "    torch.nn.Linear(D, 128),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(128, 2)\n",
        ").to(device)\n",
        "opt  = torch.optim.AdamW(probe.parameters(), lr=1e-2, weight_decay=0.0)\n",
        "crit = torch.nn.CrossEntropyLoss()\n",
        "y = labels0.to(device).long()\n",
        "\n",
        "for step in range(1000):\n",
        "    logits = probe(f_norm)\n",
        "    loss = crit(logits, y)\n",
        "    opt.zero_grad(); loss.backward(); opt.step()\n",
        "    if (step+1) % 500 == 0:\n",
        "        acc = (logits.argmax(1)==y).float().mean().item()\n",
        "        # ×× ×”-Overfit ×”×–×” ×¢×“×™×™×Ÿ ×œ× ×¢×•×‘×“, ×™×© ×‘×¢×™×” ×§×¨×™×˜×™×ª ×‘-RawNetEncoderBaseline/MoCo_v2\n",
        "        print(f\"  step {step+1}: loss {loss.item():.4f}, acc {acc:.3f}\")\n",
        "\n",
        "final_acc = (logits.argmax(1)==y).float().mean().item()\n",
        "print(f\"3.1. Final overfit-batch acc: {final_acc}\")\n",
        "if final_acc < 0.95:\n",
        "    print(\"âŒ CRITICAL ERROR: Batch overfit failed. Encoder output might be zero/garbage.\")\n",
        "\n",
        "\n",
        "# --- 4. ××™××•×Ÿ ×•×•×œ×™×“×¦×™×” (×”××™××•×Ÿ ×”×¨××©×™) ---\n",
        "print(\"\\n--- 4. ××™××•×Ÿ ×•×•×œ×™×“×¦×™×” (×¢× ×ª×™×§×•× ×™×) ---\")\n",
        "# ×”×’×“×¨×ª ×”-Classifier ×•×”-Optimizer ××—×“×©\n",
        "classifier = nn.Sequential(\n",
        "    nn.Linear(D, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(64, 2)\n",
        ").to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# ×©×™××•×© ×‘-LR ×”××ª×•×§×Ÿ\n",
        "optimizer = torch.optim.AdamW(classifier.parameters(), lr=LR, weight_decay=1e-4)\n",
        "\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    # ---- Train ----\n",
        "    classifier.train()\n",
        "    tr_loss = tr_correct = tr_total = 0.0\n",
        "\n",
        "    # ×”×©×ª××© ×‘-tqdm ×›×“×™ ×œ×¨××•×ª ×”×ª×§×“××•×ª\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS} Train\", leave=False)\n",
        "    for wavs, labels in pbar:\n",
        "        x = wavs.to(device).float()          # [B, T]\n",
        "        y = labels.to(device).long()         # 0=real, 1=fake\n",
        "\n",
        "        with torch.no_grad():\n",
        "            f = encoder_q(x)\n",
        "            if f.dim() == 3:\n",
        "                f = f.mean(dim=2)\n",
        "            elif f.dim() > 3:\n",
        "                f = f.mean(dim=tuple(range(2, f.dim())))\n",
        "\n",
        "        # â­ï¸ ×ª×™×§×•×Ÿ: × ×•×¨××œ×™×–×¦×™×” ×©×œ ×”×¤×™×¦'×¨×™× ×œ×¤× ×™ ×”-Classifier\n",
        "        f = (f - f.mean(dim=0, keepdim=True)) / (f.std(dim=0, keepdim=True) + 1e-5)\n",
        "\n",
        "        logits = classifier(f)\n",
        "        loss = criterion(logits, y)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        tr_loss   += loss.item() * x.size(0)\n",
        "        tr_correct += (logits.argmax(dim=1) == y).sum().item()\n",
        "        tr_total  += x.size(0)\n",
        "        pbar.set_postfix({'Acc': f'{tr_correct/tr_total:.3f}', 'Loss': f'{tr_loss/tr_total:.4f}'})\n",
        "\n",
        "    # ---- Val ----\n",
        "    classifier.eval()\n",
        "    va_loss, va_correct, va_total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "      for wavs, labels in val_loader:\n",
        "          x = wavs.to(device).float()\n",
        "          y = labels.to(device).long()\n",
        "          f = encoder_q(x)\n",
        "          if f.dim() == 3:\n",
        "              f = f.mean(dim=2)\n",
        "          elif f.dim() > 3:\n",
        "              f = f.mean(dim=tuple(range(2, f.dim())))\n",
        "\n",
        "          # â­ï¸ ×ª×™×§×•×Ÿ: × ×•×¨××œ×™×–×¦×™×” ×©×œ ×”×¤×™×¦'×¨×™× ×‘×•×•×œ×™×“×¦×™×”\n",
        "          f = (f - f.mean(dim=0, keepdim=True)) / (f.std(dim=0, keepdim=True) + 1e-5)\n",
        "\n",
        "          logits = classifier(f)\n",
        "          va_loss   += criterion(logits, y).item() * x.size(0)\n",
        "          va_correct += (logits.argmax(dim=1) == y).sum().item()\n",
        "          va_total  += x.size(0)\n",
        "\n",
        "    print(f\"Epoch {epoch}/{EPOCHS} | \"\n",
        "          f\"Train Loss: {tr_loss/tr_total:.4f}, Acc: {tr_correct/tr_total:.3f} | \"\n",
        "          f\"Val Loss: {va_loss/va_total:.4f}, Acc: {va_correct/va_total:.3f}\")"
      ],
      "metadata": {
        "id": "LLtOZnD1rsQx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "fb8ba791-2574-433b-d970-9155d1809e5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. ×‘×“×™×§×ª ×¡×‘×™×‘×” ×•××•×“×œ ---\n",
            "CLAD model loaded and ready.\n",
            "\n",
            "--- 2. ×‘×“×™×§×ª ×¤×™×¦'×¨×™× (Feature Extraction) ---\n",
            "2.1. Batch Shape: (16, 64600) (Expected: [B, T])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name '_CAFFE2_ATEN_FALLBACK' from 'torch._C._onnx' (unknown location)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4080181692.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0mwavs0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# wavs0: [B, T]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"2.1. Batch Shape: {tuple(wavs0.shape)} (Expected: [B, T])\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"2.2. Labels: {labels0[:5]} (Expected: [0, 1, 0, 1, ...])\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;31m# ×‘. ×‘×“×™×§×ª ×—×™×œ×•×¥ ×¤×™×¦'×¨×™× (Encoder Forward)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \"\"\"\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_unary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;31m# TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cuda_array_interface__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0mNote\u001b[0m \u001b[0mthat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munlike\u001b[0m \u001b[0mother\u001b[0m \u001b[0mautograd\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mhook\u001b[0m \u001b[0moperates\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0mthat\u001b[0m \u001b[0mrequires\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mhook\u001b[0m \u001b[0mcan\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mplace\u001b[0m \u001b[0mmodify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0;32mand\u001b[0m \u001b[0maccess\u001b[0m \u001b[0mits\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0margument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincluding\u001b[0m \u001b[0mits\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mThis\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_python_dispatch.py\u001b[0m in \u001b[0;36m_disable_current_modes\u001b[0;34m()\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mIt\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mdo\u001b[0m \u001b[0mso\u001b[0m \u001b[0mby\u001b[0m \u001b[0mgrabbing\u001b[0m \u001b[0meach\u001b[0m \u001b[0minner\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0mpassing\u001b[0m \u001b[0mthem\u001b[0m \u001b[0minto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mto\u001b[0m \u001b[0mget\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtransformed\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m     \u001b[0;32mand\u001b[0m \u001b[0mputting\u001b[0m \u001b[0meach\u001b[0m \u001b[0mtransformed\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0minto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfresh\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0msubclass\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mNote\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mwill\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0mensuring\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfresh\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_subclasses/schema_check_mode.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperator_schemas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnormalize_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pytree\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpytree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_dispatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTorchDispatchMode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/testing/_internal/jit_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBroadcastingList2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBroadcastingList3\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOperatorExportTypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_onnx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_C_onnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m from torch._C._onnx import (\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0m_CAFFE2_ATEN_FALLBACK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mOperatorExportTypes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name '_CAFFE2_ATEN_FALLBACK' from 'torch._C._onnx' (unknown location)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2 =========================================\n",
        "# Evaluate model on validation/test sets\n",
        "# =========================================\n",
        "from sklearn.metrics import classification_report\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def evaluate(loader, split_name=\"val\", model=None, classifier=None, device=None):\n",
        "    if model is None or classifier is None or device is None:\n",
        "        raise ValueError(\"model, classifier, and device must be provided to evaluate function.\")\n",
        "\n",
        "    # Ensure classifier is on the correct device\n",
        "    classifier.to(device)\n",
        "    classifier.eval()\n",
        "\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for wavs, labels in loader:\n",
        "            # Ensure data is on the correct device\n",
        "            wavs, labels = wavs.to(device), labels.to(device)\n",
        "\n",
        "            # Use the encoder from the loaded model\n",
        "            feats = model.encoder_q(wavs)\n",
        "            # Pool any extra time/freq dims so we have (B,D)\n",
        "            if feats.dim() == 3:\n",
        "                feats = feats.mean(dim=2)\n",
        "            elif feats.dim() > 3:\n",
        "                feats = feats.mean(dim=tuple(range(2, feats.dim())))\n",
        "\n",
        "            preds = classifier(feats)\n",
        "            all_preds.extend(torch.argmax(preds, dim=1).cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    print(f\"=== {split_name.upper()} RESULTS ===\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=[\"real\",\"fake\"]))\n",
        "\n",
        "# Run evaluation\n",
        "# Pass the necessary objects to the evaluate function\n",
        "evaluate(val_loader, \"val\", model=model, classifier=classifier, device=device)\n",
        "\n",
        "# Re-create test_loader as it might not be defined in the current runtime\n",
        "test_ds = AudioDataset(\"/content/my_audio_split/test\")\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
        "evaluate(test_loader, \"test\", model=model, classifier=classifier, device=device)"
      ],
      "metadata": {
        "id": "soJVwepYrs6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12\n",
        "import torch\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from pathlib import Path\n",
        "\n",
        "# Set device (important!)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Function to load audio as 16k mono\n",
        "def load_audio_16k_mono(path: Path):\n",
        "    \"\"\"Load an audio file as mono 16kHz.\"\"\"\n",
        "    waveform, sr = torchaudio.load(str(path))\n",
        "    if waveform.shape[0] > 1:\n",
        "        waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
        "    waveform = waveform.squeeze().numpy()\n",
        "    if sr != 16000:\n",
        "        resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)\n",
        "        waveform = resampler(torch.tensor(waveform).unsqueeze(0)).squeeze().numpy()\n",
        "    return waveform, 16000\n",
        "\n",
        "# Function to run prediction\n",
        "def predict_file(path: Path):\n",
        "    \"\"\"Run CLAD on one WAV file. Returns (pred_label, fake_conf, real_conf).\"\"\"\n",
        "    y, sr = load_audio_16k_mono(path)\n",
        "    x = torch.from_numpy(y).float().unsqueeze(0).unsqueeze(1).to(device)  # [B=1, C=1, T]\n",
        "    with torch.no_grad():\n",
        "        logits = model(x)  # expected shape [B, 2] for [real, fake]\n",
        "        probs  = F.softmax(logits, dim=1)[0].detach().cpu().numpy()\n",
        "    label = \"fake\" if int(np.argmax(probs)) == 1 else \"real\"\n",
        "    fake_conf = float(probs[1])\n",
        "    real_conf = float(probs[0])\n",
        "    return label, fake_conf, real_conf\n"
      ],
      "metadata": {
        "id": "p33_bM57LfTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#13\n",
        "# This cell scans your external real/fake folders, runs CLAD, and writes a CSV with results.\n",
        "# It never writes inside the CLAD repo.\n",
        "import torch\n",
        "from pathlib import Path\n",
        "import os\n",
        "# os.chdir('/content/CLAD') # No need to change directory here for prediction\n",
        "\n",
        "import glob\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Assuming 'model', 'classifier', and 'device' are defined in previous cells\n",
        "# (Specifically, 'model' from loading CLAD and 'classifier' from fine-tuning)\n",
        "if 'model' not in globals() or 'classifier' not in globals() or 'device' not in globals():\n",
        "     raise RuntimeError(\"CLAD model, classifier, or device not found. Please run the preceding cells first.\")\n",
        "\n",
        "# Ensure model and classifier are on the correct device and in eval mode\n",
        "model.to(device).eval()\n",
        "classifier.to(device).eval()\n",
        "\n",
        "# Function to load audio as 16k mono and preprocess\n",
        "def load_and_preprocess_audio(path: Path):\n",
        "    \"\"\"Load an audio file, resample to 16kHz mono, pad/trim to TARGET_LEN.\"\"\"\n",
        "    wav, sr = torchaudio.load(str(path))   # [C,T]\n",
        "    wav = wav.float()\n",
        "    if wav.shape[0] > 1:\n",
        "        wav = wav.mean(dim=0, keepdim=True)   # [1,T]\n",
        "    if sr != TARGET_SR:\n",
        "        res = torchaudio.transforms.Resample(orig_freq=sr, new_freq=TARGET_SR)\n",
        "        wav = res(wav)                         # [1,T']\n",
        "    T = wav.shape[-1]\n",
        "    if T < TARGET_LEN:\n",
        "        wav = F.pad(wav, (0, TARGET_LEN - T))\n",
        "    else:\n",
        "        wav = wav[..., :TARGET_LEN]\n",
        "    return wav.squeeze(0) # -> [T]\n",
        "\n",
        "\n",
        "# Function to run prediction\n",
        "def predict_file(path: Path, encoder, classifier, device):\n",
        "    \"\"\"Run CLAD encoder + classifier on one WAV file. Returns (pred_label, fake_conf, real_conf).\"\"\"\n",
        "    try:\n",
        "        wav = load_and_preprocess_audio(path) # [T]\n",
        "        x = wav.unsqueeze(0).to(device)       # [B=1, T]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Use only the encoder part of the MoCo model\n",
        "            feats = encoder(x) # RawNet expects [B, T]\n",
        "            # Pool any extra time/freq dims if necessary\n",
        "            if feats.dim() == 3:\n",
        "                feats = feats.mean(dim=2)\n",
        "            elif feats.dim() > 3:\n",
        "                 feats = feats.mean(dim=tuple(range(2, feats.dim())))\n",
        "\n",
        "            # Pass features through the classifier\n",
        "            logits = classifier(feats)        # [B=1, 2]\n",
        "            probs  = F.softmax(logits, dim=1)[0].detach().cpu().numpy()\n",
        "\n",
        "        label = \"fake\" if int(np.argmax(probs)) == 1 else \"real\"\n",
        "        fake_conf = float(probs[1])\n",
        "        real_conf = float(probs[0])\n",
        "        return label, fake_conf, real_conf, feats.squeeze(0).cpu().numpy() # Also return embedding\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {path}: {e}\")\n",
        "        return \"error\", 0.0, 0.0, None # Return None for embedding on error\n",
        "\n",
        "\n",
        "# Function to extract embedding (optional)\n",
        "def embed_file(path: Path, encoder, device):\n",
        "    \"\"\"Extract embedding from CLAD encoder for one WAV file.\"\"\"\n",
        "    try:\n",
        "        wav = load_and_preprocess_audio(path) # [T]\n",
        "        x = wav.unsqueeze(0).to(device)       # [B=1, T]\n",
        "        with torch.no_grad():\n",
        "            feats = encoder(x) # RawNet expects [B, T]\n",
        "            # Pool any extra time/freq dims if necessary\n",
        "            if feats.dim() == 3:\n",
        "                feats = feats.mean(dim=2)\n",
        "            elif feats.dim() > 3:\n",
        "                 feats = feats.mean(dim=tuple(range(2, feats.dim())))\n",
        "        return feats.squeeze(0).cpu().numpy()\n",
        "    except Exception as e:\n",
        "        print(f\"Error embedding file {path}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "REAL_DIR = Path(\"/content/my_audio/real\")\n",
        "FAKE_DIR = Path(\"/content/my_audio/fake\")\n",
        "OUT_DIR  = Path(\"/content/my_audio_results\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "real_files = sorted(REAL_DIR.rglob(\"*.wav\"))\n",
        "fake_files = sorted(FAKE_DIR.rglob(\"*.wav\"))\n",
        "\n",
        "print(f\"Found {len(real_files)} real and {len(fake_files)} fake WAVs.\")\n",
        "\n",
        "rows = []\n",
        "for f in real_files + fake_files:\n",
        "    p = Path(f)\n",
        "    # Pass encoder_q, classifier, and device to the prediction function\n",
        "    pred, fake_conf, real_conf, emb = predict_file(p, model.encoder_q, classifier, device)\n",
        "    rows.append({\n",
        "        \"file\": str(p),\n",
        "        \"pred\": pred,\n",
        "        \"fake_conf\": fake_conf,\n",
        "        \"real_conf\": real_conf,\n",
        "        \"embedding_dim\": (len(emb) if emb is not None else None),\n",
        "        \"embedding\": emb.tolist() if emb is not None else None # Convert numpy array to list for CSV\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "csv_path = OUT_DIR / \"clad_results.csv\"\n",
        "df.to_csv(csv_path, index=False)\n",
        "print(\"Saved CSV:\", csv_path)\n",
        "display(df.head())"
      ],
      "metadata": {
        "id": "Fd6lt4Wyh9lJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from matplotlib import pyplot as plt\n",
        "_df_0['index'].plot(kind='hist', bins=20, title='index')\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "76GRbyWP-0Yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#14\n",
        "# This cell is optional. It visualizes embeddings in 2D if they were extracted.\n",
        "# If embedding is None for all files (no encoder exposed), skip this cell.\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "emb_rows = [r for r in rows if r[\"embedding\"] is not None]\n",
        "if len(emb_rows) >= 2:\n",
        "    X = np.vstack([np.array(r[\"embedding\"], dtype=np.float32) for r in emb_rows])\n",
        "    y = np.array([r[\"pred\"] for r in emb_rows])\n",
        "\n",
        "    X2d = TSNE(n_components=2, random_state=0, perplexity=min(15, len(emb_rows)-1)).fit_transform(X)\n",
        "\n",
        "    plt.figure(figsize=(6,5))\n",
        "    for cls, marker in [(\"real\", \"o\"), (\"fake\", \"x\")]:\n",
        "        mask = (y == cls)\n",
        "        plt.scatter(X2d[mask,0], X2d[mask,1], label=cls, marker=marker, alpha=0.85)\n",
        "    plt.title(\"CLAD embeddings (t-SNE)\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No embeddings available (encoder not exposed or too few samples).\")"
      ],
      "metadata": {
        "id": "S5TtL4-qiBNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hSsZUxPxmkeF"
      }
    }
  ]
}